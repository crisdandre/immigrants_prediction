{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETAPA 4: MODELOS DE MACHINE LEARNING CON LOS AGREGADOS DE \"SEX\" Y \"AGE GROUP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook incluye los datos de agregados \"Both\" y \"All\" de las categorías \"Sex\" y \"Age group\", respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# modelos lineales\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import HuberRegressor \n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV, ElasticNet, ElasticNetCV\n",
    "\n",
    "# modelos de arboles\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "#!pip install xgboost\n",
    "#pip install pydot\n",
    "from xgboost import XGBRegressor\n",
    "#!pip install mapie\n",
    "from mapie.regression import MapieRegressor\n",
    "\n",
    "# otros\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "import pickle\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Preparar Datos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9360 entries, 0 to 9359\n",
      "Data columns (total 28 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   Year                               9360 non-null   int64  \n",
      " 1   Nationality code                   9360 non-null   object \n",
      " 2   Sex                                9360 non-null   object \n",
      " 3   Age group                          9360 non-null   object \n",
      " 4   Immigrant count                    9360 non-null   int64  \n",
      " 5   Unemployment %                     9360 non-null   float64\n",
      " 6   Political and Violence Percentile  9360 non-null   float64\n",
      " 7   Probability of dying young         9360 non-null   float64\n",
      " 8   Rule of Law Percentile             9360 non-null   float64\n",
      " 9   Salaried workers %                 9360 non-null   float64\n",
      " 10  GDP_growth                         9360 non-null   float64\n",
      " 11  Inflation_annual                   9360 non-null   float64\n",
      " 12  Liberal democracy index            9360 non-null   float64\n",
      " 13  Continent                          9360 non-null   object \n",
      " 14  Sub-region                         9360 non-null   object \n",
      " 15  Health equality                    9360 non-null   float64\n",
      " 16  Judicial accountability            9360 non-null   float64\n",
      " 17  One-sided violence_deaths          9360 non-null   int64  \n",
      " 18  Non-state_deaths                   9360 non-null   int64  \n",
      " 19  Intrastate_deaths                  9360 non-null   int64  \n",
      " 20  Interstate_deaths                  9360 non-null   int64  \n",
      " 21  Number of residents                9360 non-null   int64  \n",
      " 22  Political regime                   9360 non-null   int64  \n",
      " 23  Homicide Rate                      9024 non-null   float64\n",
      " 24  Number of Turist                   9360 non-null   int64  \n",
      " 25  Spanish language                   9360 non-null   int64  \n",
      " 26  Restricciones_pandemia             9360 non-null   int64  \n",
      " 27  Año post_pandemia                  9360 non-null   int64  \n",
      "dtypes: float64(11), int64(12), object(5)\n",
      "memory usage: 2.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Nationality code</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age group</th>\n",
       "      <th>Immigrant count</th>\n",
       "      <th>Unemployment %</th>\n",
       "      <th>Political and Violence Percentile</th>\n",
       "      <th>Probability of dying young</th>\n",
       "      <th>Rule of Law Percentile</th>\n",
       "      <th>Salaried workers %</th>\n",
       "      <th>...</th>\n",
       "      <th>Non-state_deaths</th>\n",
       "      <th>Intrastate_deaths</th>\n",
       "      <th>Interstate_deaths</th>\n",
       "      <th>Number of residents</th>\n",
       "      <th>Political regime</th>\n",
       "      <th>Homicide Rate</th>\n",
       "      <th>Number of Turist</th>\n",
       "      <th>Spanish language</th>\n",
       "      <th>Restricciones_pandemia</th>\n",
       "      <th>Año post_pandemia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>DZA</td>\n",
       "      <td>Both</td>\n",
       "      <td>0 - 14</td>\n",
       "      <td>759</td>\n",
       "      <td>11.33</td>\n",
       "      <td>14.90</td>\n",
       "      <td>3.7</td>\n",
       "      <td>24.52</td>\n",
       "      <td>67.41</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>345</td>\n",
       "      <td>0</td>\n",
       "      <td>51922</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>44400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>PER</td>\n",
       "      <td>Males</td>\n",
       "      <td>35 - 44</td>\n",
       "      <td>2938</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>60185</td>\n",
       "      <td>7</td>\n",
       "      <td>5.27</td>\n",
       "      <td>44400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>PER</td>\n",
       "      <td>Males</td>\n",
       "      <td>45 - 54</td>\n",
       "      <td>1128</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>60185</td>\n",
       "      <td>7</td>\n",
       "      <td>5.27</td>\n",
       "      <td>44400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>PER</td>\n",
       "      <td>Males</td>\n",
       "      <td>55 - 64</td>\n",
       "      <td>265</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>60185</td>\n",
       "      <td>7</td>\n",
       "      <td>5.27</td>\n",
       "      <td>44400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>PER</td>\n",
       "      <td>Males</td>\n",
       "      <td>65+</td>\n",
       "      <td>156</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>60185</td>\n",
       "      <td>7</td>\n",
       "      <td>5.27</td>\n",
       "      <td>44400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9355</th>\n",
       "      <td>2022</td>\n",
       "      <td>PAK</td>\n",
       "      <td>Males</td>\n",
       "      <td>55 - 64</td>\n",
       "      <td>330</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>670</td>\n",
       "      <td>0</td>\n",
       "      <td>68821</td>\n",
       "      <td>6</td>\n",
       "      <td>4.21</td>\n",
       "      <td>59310000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9356</th>\n",
       "      <td>2022</td>\n",
       "      <td>PAK</td>\n",
       "      <td>Females</td>\n",
       "      <td>55 - 64</td>\n",
       "      <td>146</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>670</td>\n",
       "      <td>0</td>\n",
       "      <td>31675</td>\n",
       "      <td>6</td>\n",
       "      <td>4.21</td>\n",
       "      <td>59310000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9357</th>\n",
       "      <td>2022</td>\n",
       "      <td>PAK</td>\n",
       "      <td>Both</td>\n",
       "      <td>65+</td>\n",
       "      <td>169</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>670</td>\n",
       "      <td>0</td>\n",
       "      <td>100496</td>\n",
       "      <td>6</td>\n",
       "      <td>4.21</td>\n",
       "      <td>59310000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9358</th>\n",
       "      <td>2022</td>\n",
       "      <td>PAK</td>\n",
       "      <td>Males</td>\n",
       "      <td>65+</td>\n",
       "      <td>99</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>670</td>\n",
       "      <td>0</td>\n",
       "      <td>68821</td>\n",
       "      <td>6</td>\n",
       "      <td>4.21</td>\n",
       "      <td>59310000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9359</th>\n",
       "      <td>2022</td>\n",
       "      <td>PAK</td>\n",
       "      <td>Females</td>\n",
       "      <td>65+</td>\n",
       "      <td>70</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>670</td>\n",
       "      <td>0</td>\n",
       "      <td>31675</td>\n",
       "      <td>6</td>\n",
       "      <td>4.21</td>\n",
       "      <td>59310000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9360 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year Nationality code      Sex Age group  Immigrant count  \\\n",
       "0     2008              DZA     Both    0 - 14              759   \n",
       "1     2008              PER    Males   35 - 44             2938   \n",
       "2     2008              PER    Males   45 - 54             1128   \n",
       "3     2008              PER    Males   55 - 64              265   \n",
       "4     2008              PER    Males       65+              156   \n",
       "...    ...              ...      ...       ...              ...   \n",
       "9355  2022              PAK    Males   55 - 64              330   \n",
       "9356  2022              PAK  Females   55 - 64              146   \n",
       "9357  2022              PAK     Both       65+              169   \n",
       "9358  2022              PAK    Males       65+               99   \n",
       "9359  2022              PAK  Females       65+               70   \n",
       "\n",
       "      Unemployment %  Political and Violence Percentile  \\\n",
       "0              11.33                              14.90   \n",
       "1               4.03                              17.31   \n",
       "2               4.03                              17.31   \n",
       "3               4.03                              17.31   \n",
       "4               4.03                              17.31   \n",
       "...              ...                                ...   \n",
       "9355            5.60                               6.60   \n",
       "9356            5.60                               6.60   \n",
       "9357            5.60                               6.60   \n",
       "9358            5.60                               6.60   \n",
       "9359            5.60                               6.60   \n",
       "\n",
       "      Probability of dying young  Rule of Law Percentile  Salaried workers %  \\\n",
       "0                            3.7                   24.52               67.41   \n",
       "1                            5.1                   25.96               44.47   \n",
       "2                            5.1                   25.96               44.47   \n",
       "3                            5.1                   25.96               44.47   \n",
       "4                            5.1                   25.96               44.47   \n",
       "...                          ...                     ...                 ...   \n",
       "9355                         5.8                   25.00               42.14   \n",
       "9356                         5.8                   25.00               42.14   \n",
       "9357                         5.8                   25.00               42.14   \n",
       "9358                         5.8                   25.00               42.14   \n",
       "9359                         5.8                   25.00               42.14   \n",
       "\n",
       "      ...  Non-state_deaths  Intrastate_deaths  Interstate_deaths  \\\n",
       "0     ...                 0                345                  0   \n",
       "1     ...                 0                 40                  0   \n",
       "2     ...                 0                 40                  0   \n",
       "3     ...                 0                 40                  0   \n",
       "4     ...                 0                 40                  0   \n",
       "...   ...               ...                ...                ...   \n",
       "9355  ...                 0                670                  0   \n",
       "9356  ...                 0                670                  0   \n",
       "9357  ...                 0                670                  0   \n",
       "9358  ...                 0                670                  0   \n",
       "9359  ...                 0                670                  0   \n",
       "\n",
       "     Number of residents Political regime  Homicide Rate  Number of Turist  \\\n",
       "0                  51922                3           0.95          44400000   \n",
       "1                  60185                7           5.27          44400000   \n",
       "2                  60185                7           5.27          44400000   \n",
       "3                  60185                7           5.27          44400000   \n",
       "4                  60185                7           5.27          44400000   \n",
       "...                  ...              ...            ...               ...   \n",
       "9355               68821                6           4.21          59310000   \n",
       "9356               31675                6           4.21          59310000   \n",
       "9357              100496                6           4.21          59310000   \n",
       "9358               68821                6           4.21          59310000   \n",
       "9359               31675                6           4.21          59310000   \n",
       "\n",
       "      Spanish language  Restricciones_pandemia  Año post_pandemia  \n",
       "0                    0                       0                  0  \n",
       "1                    1                       0                  0  \n",
       "2                    1                       0                  0  \n",
       "3                    1                       0                  0  \n",
       "4                    1                       0                  0  \n",
       "...                ...                     ...                ...  \n",
       "9355                 0                       0                  1  \n",
       "9356                 0                       0                  1  \n",
       "9357                 0                       0                  1  \n",
       "9358                 0                       0                  1  \n",
       "9359                 0                       0                  1  \n",
       "\n",
       "[9360 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar el dataset\n",
    "df = pd.read_csv(\"../13 - Exports (preprocesamiento)/inmigrantes_merge.csv\")\n",
    "\n",
    "df.info()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, evaluremos modelos que no aceptan datos nulos y, posteriormente los modelos de árboles que sí los aceptan. Luego compararemos las distintas métricas juntándolas en dataframes para una mejor comparación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Modelos Que No Aceptan Datos Nulos*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de proceder, debemos remover a Senegal de la lista de de paises ya que tenemos datos nulos para la variable Tasa de Homidicidios, de manera que no haya conflicto con los modelos que evaluaremos. Además, haremos de la varaible \"Year\" una variable ordinal y el resto de variables categóricas a variables dummy (los regímenes políticos ya están en formato ordinal).\n",
    "\n",
    "En el caso de \"Year\", simplemente restaremos 2007 a la columna entera, y para el resto de las variables objeto usaremos la funcion *.get_dummies()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9000 entries, 0 to 9359\n",
      "Data columns (total 70 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   Year                                      9000 non-null   int64  \n",
      " 1   Immigrant count                           9000 non-null   int64  \n",
      " 2   Unemployment %                            9000 non-null   float64\n",
      " 3   Political and Violence Percentile         9000 non-null   float64\n",
      " 4   Probability of dying young                9000 non-null   float64\n",
      " 5   Rule of Law Percentile                    9000 non-null   float64\n",
      " 6   Salaried workers %                        9000 non-null   float64\n",
      " 7   GDP_growth                                9000 non-null   float64\n",
      " 8   Inflation_annual                          9000 non-null   float64\n",
      " 9   Liberal democracy index                   9000 non-null   float64\n",
      " 10  Health equality                           9000 non-null   float64\n",
      " 11  Judicial accountability                   9000 non-null   float64\n",
      " 12  One-sided violence_deaths                 9000 non-null   int64  \n",
      " 13  Non-state_deaths                          9000 non-null   int64  \n",
      " 14  Intrastate_deaths                         9000 non-null   int64  \n",
      " 15  Interstate_deaths                         9000 non-null   int64  \n",
      " 16  Number of residents                       9000 non-null   int64  \n",
      " 17  Political regime                          9000 non-null   int64  \n",
      " 18  Homicide Rate                             9000 non-null   float64\n",
      " 19  Number of Turist                          9000 non-null   int64  \n",
      " 20  Spanish language                          9000 non-null   int64  \n",
      " 21  Restricciones_pandemia                    9000 non-null   int64  \n",
      " 22  Año post_pandemia                         9000 non-null   int64  \n",
      " 23  Nationality code_ARG                      9000 non-null   int32  \n",
      " 24  Nationality code_BGR                      9000 non-null   int32  \n",
      " 25  Nationality code_BRA                      9000 non-null   int32  \n",
      " 26  Nationality code_CHN                      9000 non-null   int32  \n",
      " 27  Nationality code_COL                      9000 non-null   int32  \n",
      " 28  Nationality code_CUB                      9000 non-null   int32  \n",
      " 29  Nationality code_DEU                      9000 non-null   int32  \n",
      " 30  Nationality code_DOM                      9000 non-null   int32  \n",
      " 31  Nationality code_DZA                      9000 non-null   int32  \n",
      " 32  Nationality code_ECU                      9000 non-null   int32  \n",
      " 33  Nationality code_FRA                      9000 non-null   int32  \n",
      " 34  Nationality code_GBR                      9000 non-null   int32  \n",
      " 35  Nationality code_HND                      9000 non-null   int32  \n",
      " 36  Nationality code_ITA                      9000 non-null   int32  \n",
      " 37  Nationality code_MAR                      9000 non-null   int32  \n",
      " 38  Nationality code_NIC                      9000 non-null   int32  \n",
      " 39  Nationality code_PAK                      9000 non-null   int32  \n",
      " 40  Nationality code_PER                      9000 non-null   int32  \n",
      " 41  Nationality code_PRT                      9000 non-null   int32  \n",
      " 42  Nationality code_PRY                      9000 non-null   int32  \n",
      " 43  Nationality code_ROU                      9000 non-null   int32  \n",
      " 44  Nationality code_RUS                      9000 non-null   int32  \n",
      " 45  Nationality code_UKR                      9000 non-null   int32  \n",
      " 46  Nationality code_USA                      9000 non-null   int32  \n",
      " 47  Nationality code_VEN                      9000 non-null   int32  \n",
      " 48  Sex_Both                                  9000 non-null   int32  \n",
      " 49  Sex_Females                               9000 non-null   int32  \n",
      " 50  Sex_Males                                 9000 non-null   int32  \n",
      " 51  Age group_0 - 14                          9000 non-null   int32  \n",
      " 52  Age group_15 - 24                         9000 non-null   int32  \n",
      " 53  Age group_25 - 34                         9000 non-null   int32  \n",
      " 54  Age group_35 - 44                         9000 non-null   int32  \n",
      " 55  Age group_45 - 54                         9000 non-null   int32  \n",
      " 56  Age group_55 - 64                         9000 non-null   int32  \n",
      " 57  Age group_65+                             9000 non-null   int32  \n",
      " 58  Age group_All                             9000 non-null   int32  \n",
      " 59  Continent_Africa                          9000 non-null   int32  \n",
      " 60  Continent_America                         9000 non-null   int32  \n",
      " 61  Continent_Asia                            9000 non-null   int32  \n",
      " 62  Continent_Europe                          9000 non-null   int32  \n",
      " 63  Sub-region_Africa                         9000 non-null   int32  \n",
      " 64  Sub-region_Asia                           9000 non-null   int32  \n",
      " 65  Sub-region_Central America and Caribbean  9000 non-null   int32  \n",
      " 66  Sub-region_European Union                 9000 non-null   int32  \n",
      " 67  Sub-region_North America                  9000 non-null   int32  \n",
      " 68  Sub-region_Rest of Europe                 9000 non-null   int32  \n",
      " 69  Sub-region_South America                  9000 non-null   int32  \n",
      "dtypes: float64(11), int32(47), int64(12)\n",
      "memory usage: 3.3 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Immigrant count</th>\n",
       "      <th>Unemployment %</th>\n",
       "      <th>Political and Violence Percentile</th>\n",
       "      <th>Probability of dying young</th>\n",
       "      <th>Rule of Law Percentile</th>\n",
       "      <th>Salaried workers %</th>\n",
       "      <th>GDP_growth</th>\n",
       "      <th>Inflation_annual</th>\n",
       "      <th>Liberal democracy index</th>\n",
       "      <th>...</th>\n",
       "      <th>Continent_America</th>\n",
       "      <th>Continent_Asia</th>\n",
       "      <th>Continent_Europe</th>\n",
       "      <th>Sub-region_Africa</th>\n",
       "      <th>Sub-region_Asia</th>\n",
       "      <th>Sub-region_Central America and Caribbean</th>\n",
       "      <th>Sub-region_European Union</th>\n",
       "      <th>Sub-region_North America</th>\n",
       "      <th>Sub-region_Rest of Europe</th>\n",
       "      <th>Sub-region_South America</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>759</td>\n",
       "      <td>11.33</td>\n",
       "      <td>14.90</td>\n",
       "      <td>3.7</td>\n",
       "      <td>24.52</td>\n",
       "      <td>67.41</td>\n",
       "      <td>2.40</td>\n",
       "      <td>15.31</td>\n",
       "      <td>0.164</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2938</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.649</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1128</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.649</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.649</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.649</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9355</th>\n",
       "      <td>15</td>\n",
       "      <td>330</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>4.71</td>\n",
       "      <td>13.96</td>\n",
       "      <td>0.234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9356</th>\n",
       "      <td>15</td>\n",
       "      <td>146</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>4.71</td>\n",
       "      <td>13.96</td>\n",
       "      <td>0.234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9357</th>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>4.71</td>\n",
       "      <td>13.96</td>\n",
       "      <td>0.234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9358</th>\n",
       "      <td>15</td>\n",
       "      <td>99</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>4.71</td>\n",
       "      <td>13.96</td>\n",
       "      <td>0.234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9359</th>\n",
       "      <td>15</td>\n",
       "      <td>70</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>4.71</td>\n",
       "      <td>13.96</td>\n",
       "      <td>0.234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  Immigrant count  Unemployment %  \\\n",
       "0        1              759           11.33   \n",
       "1        1             2938            4.03   \n",
       "2        1             1128            4.03   \n",
       "3        1              265            4.03   \n",
       "4        1              156            4.03   \n",
       "...    ...              ...             ...   \n",
       "9355    15              330            5.60   \n",
       "9356    15              146            5.60   \n",
       "9357    15              169            5.60   \n",
       "9358    15               99            5.60   \n",
       "9359    15               70            5.60   \n",
       "\n",
       "      Political and Violence Percentile  Probability of dying young  \\\n",
       "0                                 14.90                         3.7   \n",
       "1                                 17.31                         5.1   \n",
       "2                                 17.31                         5.1   \n",
       "3                                 17.31                         5.1   \n",
       "4                                 17.31                         5.1   \n",
       "...                                 ...                         ...   \n",
       "9355                               6.60                         5.8   \n",
       "9356                               6.60                         5.8   \n",
       "9357                               6.60                         5.8   \n",
       "9358                               6.60                         5.8   \n",
       "9359                               6.60                         5.8   \n",
       "\n",
       "      Rule of Law Percentile  Salaried workers %  GDP_growth  \\\n",
       "0                      24.52               67.41        2.40   \n",
       "1                      25.96               44.47        9.13   \n",
       "2                      25.96               44.47        9.13   \n",
       "3                      25.96               44.47        9.13   \n",
       "4                      25.96               44.47        9.13   \n",
       "...                      ...                 ...         ...   \n",
       "9355                   25.00               42.14        4.71   \n",
       "9356                   25.00               42.14        4.71   \n",
       "9357                   25.00               42.14        4.71   \n",
       "9358                   25.00               42.14        4.71   \n",
       "9359                   25.00               42.14        4.71   \n",
       "\n",
       "      Inflation_annual  Liberal democracy index  ...  Continent_America  \\\n",
       "0                15.31                    0.164  ...                  0   \n",
       "1                 1.10                    0.649  ...                  1   \n",
       "2                 1.10                    0.649  ...                  1   \n",
       "3                 1.10                    0.649  ...                  1   \n",
       "4                 1.10                    0.649  ...                  1   \n",
       "...                ...                      ...  ...                ...   \n",
       "9355             13.96                    0.234  ...                  0   \n",
       "9356             13.96                    0.234  ...                  0   \n",
       "9357             13.96                    0.234  ...                  0   \n",
       "9358             13.96                    0.234  ...                  0   \n",
       "9359             13.96                    0.234  ...                  0   \n",
       "\n",
       "      Continent_Asia  Continent_Europe  Sub-region_Africa  Sub-region_Asia  \\\n",
       "0                  0                 0                  1                0   \n",
       "1                  0                 0                  0                0   \n",
       "2                  0                 0                  0                0   \n",
       "3                  0                 0                  0                0   \n",
       "4                  0                 0                  0                0   \n",
       "...              ...               ...                ...              ...   \n",
       "9355               1                 0                  0                1   \n",
       "9356               1                 0                  0                1   \n",
       "9357               1                 0                  0                1   \n",
       "9358               1                 0                  0                1   \n",
       "9359               1                 0                  0                1   \n",
       "\n",
       "      Sub-region_Central America and Caribbean  Sub-region_European Union  \\\n",
       "0                                            0                          0   \n",
       "1                                            0                          0   \n",
       "2                                            0                          0   \n",
       "3                                            0                          0   \n",
       "4                                            0                          0   \n",
       "...                                        ...                        ...   \n",
       "9355                                         0                          0   \n",
       "9356                                         0                          0   \n",
       "9357                                         0                          0   \n",
       "9358                                         0                          0   \n",
       "9359                                         0                          0   \n",
       "\n",
       "      Sub-region_North America  Sub-region_Rest of Europe  \\\n",
       "0                            0                          0   \n",
       "1                            0                          0   \n",
       "2                            0                          0   \n",
       "3                            0                          0   \n",
       "4                            0                          0   \n",
       "...                        ...                        ...   \n",
       "9355                         0                          0   \n",
       "9356                         0                          0   \n",
       "9357                         0                          0   \n",
       "9358                         0                          0   \n",
       "9359                         0                          0   \n",
       "\n",
       "      Sub-region_South America  \n",
       "0                            0  \n",
       "1                            1  \n",
       "2                            1  \n",
       "3                            1  \n",
       "4                            1  \n",
       "...                        ...  \n",
       "9355                         0  \n",
       "9356                         0  \n",
       "9357                         0  \n",
       "9358                         0  \n",
       "9359                         0  \n",
       "\n",
       "[9000 rows x 70 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hacer copia del df removiendo Senegal que presenta datos nulos para tasa de homicidios\n",
    "df_nonull = df[df['Nationality code'] != 'SEN'].copy()\n",
    "\n",
    "# Transformar Year a variable ordinal de 1 (2008) a 15 (2022)\n",
    "df_nonull['Year'] = df_nonull['Year'] - 2007\n",
    "\n",
    "# Generar variables dummies a partir de nuestras variables categóricas \"object\" (no ordinales)\n",
    "df_nonull = pd.get_dummies(df_nonull)\n",
    "\n",
    "# Convertir las variables dummies booleanas en \"int\"\n",
    "col_bool = df_nonull.select_dtypes(include = ['bool']).columns\n",
    "df_nonull[col_bool] = df_nonull[col_bool].astype(int)\n",
    "\n",
    "# Verificar cambio\n",
    "df_nonull.info()\n",
    "df_nonull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separemos el conjunto train/test y escalemos los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar variables input y variable target \"Immigrant count\" de df_null (dataframe sin atos nulos)\n",
    "X = df_nonull.drop(\"Immigrant count\", axis = 1) # variables predictoras\n",
    "y = df_nonull[\"Immigrant count\"]  # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 58) # separar datos en conjunto train y test en un 75% / 25%\n",
    "scaler_nonull = MinMaxScaler() # definir scaler de datos \n",
    "X_train = scaler_nonull.fit_transform(X_train) # escalar los datos de entrenamiento\n",
    "X_test = scaler_nonull.transform(X_test) # transformar los datos de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora realizamos una primera evaluación de cada modelo y su rendimiento, para luego compararlos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresion Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 train: 0.445\n",
      "RMSE - train: 4128.0\n",
      "MAE - train: 1773.0\n",
      "MAPE - train: 6.5\n",
      "\n",
      "R2 test: 0.507\n",
      "RMSE - test: 3853.0\n",
      "MAE - test: 1818.0\n",
      "MAPE - test: 4.65\n"
     ]
    }
   ],
   "source": [
    "model_lineal = LinearRegression() # definicion del modelo \n",
    "\n",
    "model_lineal.fit(X_train, y_train) # ajuste del modelo \n",
    "\n",
    "# Aplicar modelo sobre los datos de traint y test para predecir el target\n",
    "y_train_pred_lineal = model_lineal.predict(X_train)\n",
    "y_test_pred_lineal = model_lineal.predict(X_test)\n",
    "\n",
    "# Calcular métricas en conjunto train\n",
    "r2_train_lineal = np.round(r2_score(y_train, y_train_pred_lineal), 3)\n",
    "rmse_train_lineal = np.round(np.sqrt(mean_squared_error(y_train, y_train_pred_lineal)), 0)\n",
    "mae_train_lineal = np.round(mean_absolute_error(y_train, y_train_pred_lineal), 0)\n",
    "mape_train_lineal = np.round(mean_absolute_percentage_error(y_train, y_train_pred_lineal), 2)\n",
    "\n",
    "# Calcular métricas en conjunto test\n",
    "r2_test_lineal = np.round(r2_score(y_test, y_test_pred_lineal), 3)\n",
    "rmse_test_lineal = np.round(np.sqrt(mean_squared_error(y_test, y_test_pred_lineal)), 0)\n",
    "mae_test_lineal = np.round(mean_absolute_error(y_test, y_test_pred_lineal), 0)\n",
    "mape_test_lineal = np.round(mean_absolute_percentage_error(y_test, y_test_pred_lineal), 2)\n",
    "\n",
    "# Mostrar métricas\n",
    "print(\"R2 train:\", r2_train_lineal)\n",
    "print(\"RMSE - train:\", rmse_train_lineal)\n",
    "print(\"MAE - train:\", mae_train_lineal)\n",
    "print(\"MAPE - train:\", mape_train_lineal)\n",
    "print(\"\")\n",
    "print(\"R2 test:\", r2_test_lineal)\n",
    "print(\"RMSE - test:\", rmse_test_lineal)\n",
    "print(\"MAE - test:\", mae_test_lineal)\n",
    "print(\"MAPE - test:\", mape_test_lineal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>modelo_lineal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Year</td>\n",
       "      <td>-3551.677629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unemployment %</td>\n",
       "      <td>4168.233046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Political and Violence Percentile</td>\n",
       "      <td>3093.667953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Probability of dying young</td>\n",
       "      <td>9362.225225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rule of Law Percentile</td>\n",
       "      <td>-10403.449818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Salaried workers %</td>\n",
       "      <td>-2363.380181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GDP_growth</td>\n",
       "      <td>-1647.285606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Inflation_annual</td>\n",
       "      <td>1010.011995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Liberal democracy index</td>\n",
       "      <td>3987.376400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Health equality</td>\n",
       "      <td>550.863204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Variable  modelo_lineal\n",
       "0                               Year   -3551.677629\n",
       "1                     Unemployment %    4168.233046\n",
       "2  Political and Violence Percentile    3093.667953\n",
       "3         Probability of dying young    9362.225225\n",
       "4             Rule of Law Percentile  -10403.449818\n",
       "5                 Salaried workers %   -2363.380181\n",
       "6                         GDP_growth   -1647.285606\n",
       "7                   Inflation_annual    1010.011995\n",
       "8            Liberal democracy index    3987.376400\n",
       "9                    Health equality     550.863204"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observar Coeficientes de cada variable para cada modelo en un dataframe\n",
    "coefficients_lineal = pd.DataFrame({'Variable':df_nonull.drop([\"Immigrant count\"], axis=1, inplace=False).columns})\n",
    "coefficients_lineal['modelo_lineal']= model_lineal.coef_\n",
    "\n",
    "# Mostrar coeficientes\n",
    "coefficients_lineal.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresion lineal - Huber (ventaja: bajo efecto de outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 train: 0.249\n",
      "RMSE - train: 4800.0\n",
      "MAE - train: 1306.0\n",
      "MAPE - train: 1.39\n",
      "\n",
      "R2 test: 0.277\n",
      "RMSE - test: 4668.0\n",
      "MAE - test: 1372.0\n",
      "MAPE - test: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "model_huber = HuberRegressor(epsilon=1.15, alpha = 0.05) # definicion del modelo \n",
    "\n",
    "model_huber.fit(X_train, y_train) # ajuste del modelo \n",
    "\n",
    "# Aplicar modelo sobre los datos de traint y test para predecir el target\n",
    "y_train_pred_huber = model_huber.predict(X_train)\n",
    "y_test_pred_huber = model_huber.predict(X_test)\n",
    "\n",
    "# Calcular métricas en conjunto train\n",
    "r2_train_huber = np.round(r2_score(y_train, y_train_pred_huber), 3)\n",
    "rmse_train_huber = np.round(np.sqrt(mean_squared_error(y_train, y_train_pred_huber)), 0)\n",
    "mae_train_huber = np.round(mean_absolute_error(y_train, y_train_pred_huber), 0)\n",
    "mape_train_huber = np.round(mean_absolute_percentage_error(y_train, y_train_pred_huber), 2)\n",
    "\n",
    "# Calcular métricas en conjunto test\n",
    "r2_test_huber = np.round(r2_score(y_test, y_test_pred_huber), 3)\n",
    "rmse_test_huber = np.round(np.sqrt(mean_squared_error(y_test, y_test_pred_huber)), 0)\n",
    "mae_test_huber = np.round(mean_absolute_error(y_test, y_test_pred_huber), 0)\n",
    "mape_test_huber = np.round(mean_absolute_percentage_error(y_test, y_test_pred_huber), 2)\n",
    "\n",
    "# Mostrar métricas\n",
    "print(\"R2 train:\", r2_train_huber)\n",
    "print(\"RMSE - train:\", rmse_train_huber)\n",
    "print(\"MAE - train:\", mae_train_huber)\n",
    "print(\"MAPE - train:\", mape_train_huber)\n",
    "print(\"\")\n",
    "print(\"R2 test:\", r2_test_huber)\n",
    "print(\"RMSE - test:\", rmse_test_huber)\n",
    "print(\"MAE - test:\", mae_test_huber)\n",
    "print(\"MAPE - test:\", mape_test_huber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>modelo_lineal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Year</td>\n",
       "      <td>39.867744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unemployment %</td>\n",
       "      <td>298.585706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Political and Violence Percentile</td>\n",
       "      <td>-119.777828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Probability of dying young</td>\n",
       "      <td>441.239407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rule of Law Percentile</td>\n",
       "      <td>-141.951313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Salaried workers %</td>\n",
       "      <td>-495.752277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GDP_growth</td>\n",
       "      <td>-350.461215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Inflation_annual</td>\n",
       "      <td>520.854837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Liberal democracy index</td>\n",
       "      <td>304.233007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Health equality</td>\n",
       "      <td>-350.545236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Variable  modelo_lineal\n",
       "0                               Year      39.867744\n",
       "1                     Unemployment %     298.585706\n",
       "2  Political and Violence Percentile    -119.777828\n",
       "3         Probability of dying young     441.239407\n",
       "4             Rule of Law Percentile    -141.951313\n",
       "5                 Salaried workers %    -495.752277\n",
       "6                         GDP_growth    -350.461215\n",
       "7                   Inflation_annual     520.854837\n",
       "8            Liberal democracy index     304.233007\n",
       "9                    Health equality    -350.545236"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observar Coeficientes de cada variable para cada modelo en un dataframe\n",
    "coefficients_huber = pd.DataFrame({'Variable':df_nonull.drop([\"Immigrant count\"], axis=1, inplace=False).columns})\n",
    "coefficients_huber['modelo_lineal']= model_huber.coef_\n",
    "\n",
    "# Mostrar coeficientes\n",
    "coefficients_huber.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresion lineal - RANSAC (ventaja: bueno para grandes outliers en \"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 train: 0.033\n",
      "RMSE - train: 5449.0\n",
      "MAE - train: 1653.0\n",
      "MAPE - train: 1.6\n",
      "\n",
      "R2 test: 0.035\n",
      "RMSE - test: 5394.0\n",
      "MAE - test: 1745.0\n",
      "MAPE - test: 0.87\n"
     ]
    }
   ],
   "source": [
    "model_ransac = RANSACRegressor(min_samples = 15) # definicion del modelo \n",
    "\n",
    "model_ransac.fit(X_train, y_train) # ajuste del modelo \n",
    "\n",
    "# Aplicar modelo sobre los datos de traint y test para predecir el target\n",
    "y_train_pred_ransac = model_ransac.predict(X_train)\n",
    "y_test_pred_ransac = model_ransac.predict(X_test)\n",
    "\n",
    "# Calcular métricas en conjunto train\n",
    "r2_train_ransac = np.round(r2_score(y_train, y_train_pred_ransac), 3)\n",
    "rmse_train_ransac = np.round(np.sqrt(mean_squared_error(y_train, y_train_pred_ransac)), 0)\n",
    "mae_train_ransac = np.round(mean_absolute_error(y_train, y_train_pred_ransac), 0)\n",
    "mape_train_ransac = np.round(mean_absolute_percentage_error(y_train, y_train_pred_ransac), 2)\n",
    "\n",
    "# Calcular métricas en conjunto test\n",
    "r2_test_ransac = np.round(r2_score(y_test, y_test_pred_ransac), 3)\n",
    "rmse_test_ransac = np.round(np.sqrt(mean_squared_error(y_test, y_test_pred_ransac)), 0)\n",
    "mae_test_ransac = np.round(mean_absolute_error(y_test, y_test_pred_ransac), 0)\n",
    "mape_test_ransac = np.round(mean_absolute_percentage_error(y_test, y_test_pred_ransac), 2)\n",
    "\n",
    "# Mostrar métricas\n",
    "print(\"R2 train:\", r2_train_ransac)\n",
    "print(\"RMSE - train:\", rmse_train_ransac)\n",
    "print(\"MAE - train:\", mae_train_ransac)\n",
    "print(\"MAPE - train:\", mape_train_ransac)\n",
    "print(\"\")\n",
    "print(\"R2 test:\", r2_test_ransac)\n",
    "print(\"RMSE - test:\", rmse_test_ransac)\n",
    "print(\"MAE - test:\", mae_test_ransac)\n",
    "print(\"MAPE - test:\", mape_test_ransac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresion lineal - TheilSen (ventaja: bueno para outliers pequeños tanto en \"X\" como en \"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 train: 0.372\n",
      "RMSE - train: 4389.0\n",
      "MAE - train: 1575.0\n",
      "MAPE - train: 4.76\n",
      "\n",
      "R2 test: 0.473\n",
      "RMSE - test: 3985.0\n",
      "MAE - test: 1557.0\n",
      "MAPE - test: 3.4\n"
     ]
    }
   ],
   "source": [
    "model_theilsen = TheilSenRegressor() # definicion del modelo \n",
    "\n",
    "model_theilsen.fit(X_train, y_train) # ajuste del modelo \n",
    "\n",
    "# Aplicar modelo sobre los datos de traint y test para predecir el target\n",
    "y_train_pred_theilsen = model_theilsen.predict(X_train)\n",
    "y_test_pred_theilsen = model_theilsen.predict(X_test)\n",
    "\n",
    "# Calcular métricas en conjunto train\n",
    "r2_train_theilsen = np.round(r2_score(y_train, y_train_pred_theilsen), 3)\n",
    "rmse_train_theilsen = np.round(np.sqrt(mean_squared_error(y_train, y_train_pred_theilsen)), 0)\n",
    "mae_train_theilsen = np.round(mean_absolute_error(y_train, y_train_pred_theilsen), 0)\n",
    "mape_train_theilsen = np.round(mean_absolute_percentage_error(y_train, y_train_pred_theilsen), 2)\n",
    "\n",
    "# Calcular métricas en conjunto test\n",
    "r2_test_theilsen = np.round(r2_score(y_test, y_test_pred_theilsen), 3)\n",
    "rmse_test_theilsen = np.round(np.sqrt(mean_squared_error(y_test, y_test_pred_theilsen)), 0)\n",
    "mae_test_theilsen = np.round(mean_absolute_error(y_test, y_test_pred_theilsen), 0)\n",
    "mape_test_theilsen = np.round(mean_absolute_percentage_error(y_test, y_test_pred_theilsen), 2)\n",
    "\n",
    "# Mostrar métricas\n",
    "print(\"R2 train:\", r2_train_theilsen)\n",
    "print(\"RMSE - train:\", rmse_train_theilsen)\n",
    "print(\"MAE - train:\", mae_train_theilsen)\n",
    "print(\"MAPE - train:\", mape_train_theilsen)\n",
    "print(\"\")\n",
    "print(\"R2 test:\", r2_test_theilsen)\n",
    "print(\"RMSE - test:\", rmse_test_theilsen)\n",
    "print(\"MAE - test:\", mae_test_theilsen)\n",
    "print(\"MAPE - test:\", mape_test_theilsen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelos lineales regularizados (Ridge, Lasso, E-Net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Buscar Alfa Optimo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alfa Optimo Ridge: 1.0\n",
      "Alfa Optimo Lasso: 0.92773669106235\n",
      "Alfa Optimo E-Net: 1.7304206862222227\n"
     ]
    }
   ],
   "source": [
    "# Definir modelo Ridge y para Evaluar el valor del \"alpha\" óptimo\n",
    "ridgecv = RidgeCV()\n",
    "ridgecv.fit(X_train, y_train)\n",
    "print(\"Alfa Optimo Ridge:\", ridgecv.alpha_)\n",
    "\n",
    "# Definir modelo Lasso y para Evaluar el valor del \"alpha\" óptimo\n",
    "lassocv = LassoCV()\n",
    "lassocv.fit(X_train, y_train)\n",
    "print(\"Alfa Optimo Lasso:\", lassocv.alpha_)\n",
    "\n",
    "# Definir modelo E-Net y para Evaluar el valor del \"alpha\" óptimo\n",
    "enetcv = ElasticNetCV()\n",
    "enetcv.fit(X_train, y_train)\n",
    "print(\"Alfa Optimo E-Net:\", enetcv.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingresamos el valor de alpha en una variable\n",
    "alpha_opt_ridge = ridgecv.alpha_\n",
    "\n",
    "# Ingresamos el valor de alpha en una variable\n",
    "alpha_opt_lasso = lassocv.alpha_\n",
    "\n",
    "# Ingresamos el valor de alpha en una variable\n",
    "alpha_opt_enet = enetcv.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrenar modelo con Alfa optimo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir modelo Ridge con nuestro valor optimo de alpha, entrenar y predecir\n",
    "modelo_ridge = Ridge(alpha = alpha_opt_ridge)\n",
    "y_test_ridge = modelo_ridge.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "# Definir modelo Lasso con nuestro valor optimo de alpha, entrenar y predecir\n",
    "modelo_lasso = Lasso(alpha = alpha_opt_lasso)\n",
    "y_test_lasso = modelo_lasso.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "# Definir modelo E-Net con nuestro valor optimo de alpha, entrenar y predecir\n",
    "modelo_enet = ElasticNet(alpha = alpha_opt_enet)\n",
    "y_test_enet = modelo_enet.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>modelo_ridge</th>\n",
       "      <th>modelo_lasso</th>\n",
       "      <th>modelo_net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Year</td>\n",
       "      <td>-3147.756559</td>\n",
       "      <td>-3099.376147</td>\n",
       "      <td>211.210996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unemployment %</td>\n",
       "      <td>3380.453482</td>\n",
       "      <td>2904.497608</td>\n",
       "      <td>60.050911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Political and Violence Percentile</td>\n",
       "      <td>2538.179203</td>\n",
       "      <td>2426.272784</td>\n",
       "      <td>-56.472574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Probability of dying young</td>\n",
       "      <td>6928.625842</td>\n",
       "      <td>6581.308239</td>\n",
       "      <td>40.462542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rule of Law Percentile</td>\n",
       "      <td>-9096.036039</td>\n",
       "      <td>-8292.332375</td>\n",
       "      <td>10.561849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Sub-region_Central America and Caribbean</td>\n",
       "      <td>89.346574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-125.055870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Sub-region_European Union</td>\n",
       "      <td>366.765265</td>\n",
       "      <td>221.596086</td>\n",
       "      <td>16.642410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Sub-region_North America</td>\n",
       "      <td>761.530654</td>\n",
       "      <td>44.891180</td>\n",
       "      <td>-47.132018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Sub-region_Rest of Europe</td>\n",
       "      <td>-59.658470</td>\n",
       "      <td>-16.608889</td>\n",
       "      <td>-9.359894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Sub-region_South America</td>\n",
       "      <td>-739.081924</td>\n",
       "      <td>-695.882966</td>\n",
       "      <td>102.765102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Variable  modelo_ridge  modelo_lasso  \\\n",
       "0                                       Year  -3147.756559  -3099.376147   \n",
       "1                             Unemployment %   3380.453482   2904.497608   \n",
       "2          Political and Violence Percentile   2538.179203   2426.272784   \n",
       "3                 Probability of dying young   6928.625842   6581.308239   \n",
       "4                     Rule of Law Percentile  -9096.036039  -8292.332375   \n",
       "..                                       ...           ...           ...   \n",
       "64  Sub-region_Central America and Caribbean     89.346574      0.000000   \n",
       "65                 Sub-region_European Union    366.765265    221.596086   \n",
       "66                  Sub-region_North America    761.530654     44.891180   \n",
       "67                 Sub-region_Rest of Europe    -59.658470    -16.608889   \n",
       "68                  Sub-region_South America   -739.081924   -695.882966   \n",
       "\n",
       "    modelo_net  \n",
       "0   211.210996  \n",
       "1    60.050911  \n",
       "2   -56.472574  \n",
       "3    40.462542  \n",
       "4    10.561849  \n",
       "..         ...  \n",
       "64 -125.055870  \n",
       "65   16.642410  \n",
       "66  -47.132018  \n",
       "67   -9.359894  \n",
       "68  102.765102  \n",
       "\n",
       "[69 rows x 4 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observar Coeficientes de cada variable para cada modelo en un dataframe\n",
    "coefficients = pd.DataFrame({'Variable':df_nonull.drop([\"Immigrant count\"], axis=1, inplace=False).columns})\n",
    "coefficients['modelo_ridge']= modelo_ridge.coef_\n",
    "coefficients['modelo_lasso']= modelo_lasso.coef_\n",
    "coefficients['modelo_net']= modelo_enet.coef_\n",
    "\n",
    "# Mostrar coeficientes\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluar Métricas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 test - Ridge: 0.507\n",
      "RMSE test - Ridge: 3855.0\n",
      "MAE test - Ridge: 1800.0\n",
      "MAPE test - Ridge: 4.56\n"
     ]
    }
   ],
   "source": [
    "# Métricas en test - Ridge\n",
    "r2_test_ridge = np.round(r2_score(y_test, y_test_ridge), 3)\n",
    "rmse_test_ridge = np.round(np.sqrt(mean_squared_error(y_test, y_test_ridge)), 0)\n",
    "mae_test_ridge = np.round(mean_absolute_error(y_test, y_test_ridge), 0)\n",
    "mape_test_ridge = np.round(mean_absolute_percentage_error(y_test, y_test_ridge), 2)\n",
    "\n",
    "# Mostrar métricas - Ridge\n",
    "print(\"R2 test - Ridge:\", r2_test_ridge)\n",
    "print(\"RMSE test - Ridge:\", rmse_test_ridge)\n",
    "print(\"MAE test - Ridge:\", mae_test_ridge)\n",
    "print(\"MAPE test - Ridge:\", mape_test_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 test - Lasso: 0.506\n",
      "RMSE test - Lasso: 3859.0\n",
      "MAE test - Lasso: 1797.0\n",
      "MAPE test - Lasso: 4.52\n"
     ]
    }
   ],
   "source": [
    "# Métricas en test - Lasso\n",
    "r2_test_lasso = np.round(r2_score(y_test, y_test_lasso), 3)\n",
    "rmse_test_lasso = np.round(np.sqrt(mean_squared_error(y_test, y_test_lasso)), 0)\n",
    "mae_test_lasso = np.round(mean_absolute_error(y_test, y_test_lasso), 0)\n",
    "mape_test_lasso = np.round(mean_absolute_percentage_error(y_test, y_test_lasso), 2)\n",
    "\n",
    "# Mostrar métricas - Lasso\n",
    "print(\"R2 test - Lasso:\", r2_test_lasso)\n",
    "print(\"RMSE test - Lasso:\", rmse_test_lasso)\n",
    "print(\"MAE test - Lasso:\", mae_test_lasso)\n",
    "print(\"MAPE test - Lasso:\", mape_test_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 test - E-Net: 0.103\n",
      "RMSE test - E-Net: 5199.0\n",
      "MAE test - E-Net: 2293.0\n",
      "MAPE test - E-Net: 6.1\n"
     ]
    }
   ],
   "source": [
    "# Métricas en test - E-Net\n",
    "r2_test_enet = np.round(r2_score(y_test, y_test_enet), 3)\n",
    "rmse_test_enet = np.round(np.sqrt(mean_squared_error(y_test, y_test_enet)), 0)\n",
    "mae_test_enet = np.round(mean_absolute_error(y_test, y_test_enet), 0)\n",
    "mape_test_enet = np.round(mean_absolute_percentage_error(y_test, y_test_enet), 2)\n",
    "\n",
    "# Mostrar métricas - E-Net\n",
    "print(\"R2 test - E-Net:\", r2_test_enet)\n",
    "print(\"RMSE test - E-Net:\", rmse_test_enet)\n",
    "print(\"MAE test - E-Net:\", mae_test_enet)\n",
    "print(\"MAPE test - E-Net:\", mape_test_enet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desicion Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'squared_error', 'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 20}\n"
     ]
    }
   ],
   "source": [
    "# Definir diccionario de valores para parámetros \n",
    "params = {'max_depth': range(6,8), \n",
    "          'min_samples_leaf' : [1, 3, 4], \n",
    "          'min_samples_split': [20, 30], \n",
    "          \"criterion\" : [\"squared_error\", \"absolute_error\", \"poisson\"] \n",
    "          } \n",
    "\n",
    "# Definir modelo y aplicar combinaciones de parametros según el diccinario \n",
    "tree = DecisionTreeRegressor() \n",
    "tree_cv = GridSearchCV(tree, params, cv = 3, refit = True, scoring = \"neg_mean_squared_error\")\n",
    "\n",
    "# Entrenar modelo con cada combinación de parámetro \n",
    "tree_cv.fit(X_train, y_train) \n",
    "\n",
    "# Montrar los valores de los parámetros \n",
    "print(tree_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 - train: 0.838\n",
      "RMSE - train: 2228.0\n",
      "MAE - train: 903.0\n",
      "MAPE - train: 1.84\n",
      "\n",
      "R2 - test: 0.712\n",
      "RMSE - test: 2947.0\n",
      "MAE - test: 1125.0\n",
      "MAPE - test: 1.46\n"
     ]
    }
   ],
   "source": [
    "# Definir modelo con los mejores valores de parámetros \n",
    "tree_best =  DecisionTreeRegressor(max_depth = 8, \n",
    "                                   min_samples_leaf = 2,\n",
    "                                   min_samples_split = 15, \n",
    "                                   criterion = tree_cv.best_params_['criterion']) \n",
    "\n",
    "# Entrenar con el conjunto de entrenamiento \n",
    "tree_best.fit(X_train, y_train) \n",
    "\n",
    "# Aplicar modelo sobre los datos de traint y test para predecir el target\n",
    "y_test_pred_tree = tree_best.predict(X_test) \n",
    "y_train_pred_tree = tree_best.predict(X_train) \n",
    "\n",
    "# Calcular métricas en conjunto train\n",
    "r2_train_tree = np.round(r2_score(y_train, y_train_pred_tree), 3)\n",
    "rmse_train_tree = np.round(np.sqrt(mean_squared_error(y_train, y_train_pred_tree)), 0)\n",
    "mae_train_tree = np.round(mean_absolute_error(y_train, y_train_pred_tree), 0)\n",
    "mape_train_tree = np.round(mean_absolute_percentage_error(y_train, y_train_pred_tree), 2)\n",
    "\n",
    "# Calcular métricas en conjunto test\n",
    "r2_test_tree = np.round(r2_score(y_test, y_test_pred_tree), 3)\n",
    "rmse_test_tree = np.round(np.sqrt(mean_squared_error(y_test, y_test_pred_tree)), 0)\n",
    "mae_test_tree = np.round(mean_absolute_error(y_test, y_test_pred_tree), 0)\n",
    "mape_test_tree = np.round(mean_absolute_percentage_error(y_test, y_test_pred_tree), 2)\n",
    "\n",
    "# Mostrar métricas\n",
    "print(\"R2 - train:\", r2_train_tree)\n",
    "print(\"RMSE - train:\", rmse_train_tree)\n",
    "print(\"MAE - train:\", mae_train_tree)\n",
    "print(\"MAPE - train:\", mape_train_tree)\n",
    "print(\"\")\n",
    "print(\"R2 - test:\", r2_test_tree)\n",
    "print(\"RMSE - test:\", rmse_test_tree)\n",
    "print(\"MAE - test:\", mae_test_tree)\n",
    "print(\"MAPE - test:\", mape_test_tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(criterion=&#x27;poisson&#x27;, max_depth=8, min_samples_leaf=2,\n",
       "                      min_samples_split=30)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(criterion=&#x27;poisson&#x27;, max_depth=8, min_samples_leaf=2,\n",
       "                      min_samples_split=30)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(criterion='poisson', max_depth=8, min_samples_leaf=2,\n",
       "                      min_samples_split=30)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir diccionario de valores para parámetros \n",
    "params = {'n_estimators': [100], \n",
    "\t      'criterion' : ['squared_error', 'friedman_mse', 'poisson'],\n",
    "          \"min_samples_split\": [30, 50, 70], \n",
    "          'min_samples_leaf' : [2, 3, 5],\n",
    "          \"max_depth\": [7, 8],\n",
    "          }\n",
    "\n",
    "# Definir modelo y aplicar combinaciones de parametros según el diccinario \n",
    "rf = RandomForestRegressor() \n",
    "rf_cv = GridSearchCV(rf, params, cv=3, scoring='neg_mean_squared_error').fit(X_train, y_train)\n",
    "\n",
    "# Motrar mejores valores para parámeros\n",
    "rf_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 - train: 0.801\n",
      "RMSE - train: 2474.0\n",
      "MAE - train: 752.0\n",
      "MAPE - train: 0.85\n",
      "\n",
      "R2 - test: 0.744\n",
      "RMSE - test: 2775.0\n",
      "MAE - test: 910.0\n",
      "MAPE - test: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Definir modelo con los mejores valores de parámetros (Nota: usar los mejores, pero hacer modificaciones para comparar metricas)\n",
    "rf_best = RandomForestRegressor(n_estimators = 100, \n",
    "                           max_depth = 8, \n",
    "                           criterion = 'poisson', \n",
    "                           min_samples_split = 20, \n",
    "                           min_samples_leaf = 2,  \n",
    "                           )\n",
    "\n",
    "# Entrenar con el conjunto de entrenamiento \n",
    "rf_best.fit(X_train, y_train) \n",
    "\n",
    "# Aplicar modelo sobre los datos de traint y test para predecir el target\n",
    "y_train_pred_rf = rf_best.predict(X_train)\n",
    "y_test_pred_rf = rf_best.predict(X_test)\n",
    "\n",
    "# Calcular métricas en conjunto train\n",
    "r2_train_rf = np.round(r2_score(y_train, y_train_pred_rf), 3)\n",
    "rmse_train_rf = np.round(np.sqrt(mean_squared_error(y_train, y_train_pred_rf)), 0)\n",
    "mae_train_rf = np.round(mean_absolute_error(y_train, y_train_pred_rf), 0)\n",
    "mape_train_rf = np.round(mean_absolute_percentage_error(y_train, y_train_pred_rf), 2)\n",
    "\n",
    "# Calcular métricas en conjunto test\n",
    "r2_test_rf = np.round(r2_score(y_test, y_test_pred_rf), 3)\n",
    "rmse_test_rf = np.round(np.sqrt(mean_squared_error(y_test, y_test_pred_rf)), 0)\n",
    "mae_test_rf = np.round(mean_absolute_error(y_test, y_test_pred_rf), 0)\n",
    "mape_test_rf = np.round(mean_absolute_percentage_error(y_test, y_test_pred_rf), 2)\n",
    "\n",
    "# Mostrar métricas\n",
    "print(\"R2 - train:\", r2_train_rf)\n",
    "print(\"RMSE - train:\", rmse_train_rf)\n",
    "print(\"MAE - train:\", mae_train_rf)\n",
    "print(\"MAPE - train:\", mape_train_rf)\n",
    "print(\"\")\n",
    "print(\"R2 - test:\", r2_test_rf)\n",
    "print(\"RMSE - test:\", rmse_test_rf)\n",
    "print(\"MAE - test:\", mae_test_rf)\n",
    "print(\"MAPE - test:\", mape_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importancia relativa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Age group_All</td>\n",
       "      <td>0.467901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Number of residents</td>\n",
       "      <td>0.264668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Year</td>\n",
       "      <td>0.035849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Age group_25 - 34</td>\n",
       "      <td>0.029191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Number of Turist</td>\n",
       "      <td>0.022800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unemployment %</td>\n",
       "      <td>0.022205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Año post_pandemia</td>\n",
       "      <td>0.017490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Age group_65+</td>\n",
       "      <td>0.017098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Probability of dying young</td>\n",
       "      <td>0.013276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Age group_55 - 64</td>\n",
       "      <td>0.012061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Homicide Rate</td>\n",
       "      <td>0.010455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Inflation_annual</td>\n",
       "      <td>0.008543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Age group_15 - 24</td>\n",
       "      <td>0.008338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GDP_growth</td>\n",
       "      <td>0.008241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Health equality</td>\n",
       "      <td>0.007962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      variable  importancia relativa\n",
       "57               Age group_All              0.467901\n",
       "15         Number of residents              0.264668\n",
       "0                         Year              0.035849\n",
       "52           Age group_25 - 34              0.029191\n",
       "18            Number of Turist              0.022800\n",
       "1               Unemployment %              0.022205\n",
       "21           Año post_pandemia              0.017490\n",
       "56               Age group_65+              0.017098\n",
       "3   Probability of dying young              0.013276\n",
       "55           Age group_55 - 64              0.012061\n",
       "17               Homicide Rate              0.010455\n",
       "7             Inflation_annual              0.008543\n",
       "51           Age group_15 - 24              0.008338\n",
       "6                   GDP_growth              0.008241\n",
       "9              Health equality              0.007962"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimación de importancia relativa de variables en el modelo\n",
    "imp_rel_rf = rf_best.feature_importances_\n",
    "importancias = pd.DataFrame({\"variable\": X.columns, \"importancia relativa\": imp_rel_rf}) \\\n",
    ".sort_values(by='importancia relativa', ascending = False)\n",
    "importancias[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 11, 'weights': 'distance'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir diccionario de valores para parámetros \n",
    "params = {'n_neighbors': range(1,20),\n",
    "          'weights' : ['uniform', 'distance'],\n",
    "          }\n",
    "\n",
    "# Definir modelo y aplicar combinaciones de parametros según el diccinario entrenando el conjunto train\n",
    "knn = KNeighborsRegressor()\n",
    "knn_cv = GridSearchCV(knn, params, cv=3, scoring='neg_mean_squared_error').fit(X_train,y_train)\n",
    "\n",
    "knn_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 - train: 0.63\n",
      "RMSE - train: 3369.0\n",
      "MAE - train: 1019.0\n",
      "MAPE - train: 1.21\n",
      "\n",
      "R2 - test: 0.633\n",
      "RMSE - test: 3325.0\n",
      "MAE - test: 1136.0\n",
      "MAPE - test: 1.52\n"
     ]
    }
   ],
   "source": [
    "knn_best =  KNeighborsRegressor(n_neighbors = 11, weights = 'uniform', leaf_size=30, p = 1)\n",
    "\n",
    "knn_best.fit(X_train, y_train)\n",
    "\n",
    "# Obtener predicciones con conjunto de entrenamiento y prueba\n",
    "y_train_pred_knn = knn_best.predict(X_train)  \n",
    "y_test_pred_knn = knn_best.predict(X_test)  \n",
    "\n",
    "# Calcular métricas en conjunto train\n",
    "r2_train_knn = np.round(r2_score(y_train, y_train_pred_knn), 3)\n",
    "rmse_train_knn = np.round(np.sqrt(mean_squared_error(y_train, y_train_pred_knn)), 0)\n",
    "mae_train_knn = np.round(mean_absolute_error(y_train, y_train_pred_knn), 0)\n",
    "mape_train_knn = np.round(mean_absolute_percentage_error(y_train, y_train_pred_knn), 2)\n",
    "\n",
    "# Calcular métricas en conjunto train\n",
    "r2_test_knn = np.round(r2_score(y_test, y_test_pred_knn), 3)\n",
    "rmse_test_knn = np.round(np.sqrt(mean_squared_error(y_test, y_test_pred_knn)), 0)\n",
    "mae_test_knn = np.round(mean_absolute_error(y_test, y_test_pred_knn), 0)\n",
    "mape_test_knn = np.round(mean_absolute_percentage_error(y_test, y_test_pred_knn), 2)\n",
    "\n",
    "# Print metrics\n",
    "print(\"R2 - train:\", r2_train_knn)\n",
    "print(\"RMSE - train:\", rmse_train_knn)\n",
    "print(\"MAE - train:\", mae_train_knn)\n",
    "print(\"MAPE - train:\", mape_train_knn)\n",
    "print(\"\")\n",
    "print(\"R2 - test:\", r2_test_knn)\n",
    "print(\"RMSE - test:\", rmse_test_knn)\n",
    "print(\"MAE - test:\", mae_test_knn)\n",
    "print(\"MAPE - test:\", mape_test_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'tol': 0.0015}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir diccionario de valores para parámetros \n",
    "params = {'kernel': ['rbf', 'linear'],\n",
    "          'gamma': ['scale', 'auto'],\n",
    "          'C' : [1.0, 0.85, 0.75] ,\n",
    "          'max_iter': [-1, 100],\n",
    "          \"tol\" : [0.001, 0.002, 0.0015, 0.1, 0.2]\n",
    "          }\n",
    "\n",
    "# Definir modelo y aplicar combinaciones de parametros según el diccinario \n",
    "svr = SVR()\n",
    "svr_cv = GridSearchCV(svr, params, cv = 3, refit = True, scoring = 'neg_mean_squared_error') # elegir scoring deseano (r2, mae, mse, mape...)\n",
    "\n",
    "# Entrenar modelo con cada combinación de parámetro \n",
    "svr_cv.fit(X_train, y_train)\n",
    "\n",
    "# Motrar mejores valores para parámeros\n",
    "svr_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 - train: 0.026\n",
      "RMSE - train: 5469.0\n",
      "MAE - train: 1659.0\n",
      "MAPE - train: 1.04\n",
      "\n",
      "R2 - test: 0.022\n",
      "RMSE - test: 5430.0\n",
      "MAE - test: 1758.0\n",
      "MAPE - test: 1.01\n"
     ]
    }
   ],
   "source": [
    "# Definir modelo con mejors parámetros\n",
    "svr_best = SVR(kernel = 'linear', \n",
    "               gamma = 'scale', \n",
    "               C = 1.0, \n",
    "               max_iter = -1, \n",
    "               tol = 0.0015\n",
    "               )\n",
    "\n",
    "# Enrenar con el conjunto de entrenamiento \n",
    "svr_best.fit(X_train, y_train) \n",
    "\n",
    "# Obtener predicciones con conjunto de entrenamiento y prueba\n",
    "y_train_pred_svr = svr_best.predict(X_train)  \n",
    "y_test_pred_svr = svr_best.predict(X_test)  \n",
    "\n",
    "# Calcular métricas en conjunto train\n",
    "r2_train_svr = np.round(r2_score(y_train, y_train_pred_svr), 3)\n",
    "rmse_train_svr = np.round(np.sqrt(mean_squared_error(y_train, y_train_pred_svr)), 0)\n",
    "mae_train_svr = np.round(mean_absolute_error(y_train, y_train_pred_svr), 0)\n",
    "mape_train_svr = np.round(mean_absolute_percentage_error(y_train, y_train_pred_svr), 2)\n",
    "\n",
    "# Calcular métricas en conjunto test\n",
    "r2_test_svr = np.round(r2_score(y_test, y_test_pred_svr), 3)\n",
    "rmse_test_svr = np.round(np.sqrt(mean_squared_error(y_test, y_test_pred_svr)), 0)\n",
    "mae_test_svr = np.round(mean_absolute_error(y_test, y_test_pred_svr), 0)\n",
    "mape_test_svr = np.round(mean_absolute_percentage_error(y_test, y_test_pred_svr), 2)\n",
    "\n",
    "# Mostrar métricas\n",
    "print(\"R2 - train:\", r2_train_svr)\n",
    "print(\"RMSE - train:\", rmse_train_svr)\n",
    "print(\"MAE - train:\", mae_train_svr)\n",
    "print(\"MAPE - train:\", mape_train_svr)\n",
    "print(\"\")\n",
    "print(\"R2 - test:\", r2_test_svr)\n",
    "print(\"RMSE - test:\", rmse_test_svr)\n",
    "print(\"MAE - test:\", mae_test_svr)\n",
    "print(\"MAPE - test:\", mape_test_svr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Neuronal Básica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtengamos primero un número de referencia en cuanto a el número de neuronas a usar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.575836902790225\n",
      "46.666666666666664\n"
     ]
    }
   ],
   "source": [
    "# Dos métodos para estimar numero de neuronas a usar\n",
    "print(np.sqrt(len(X.columns)*2))\n",
    "print(2/3 * len(X.columns) + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "54 fits failed out of a total of 486.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 749, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 471, in _fit\n",
      "    self._fit_stochastic(\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 655, in _fit_stochastic\n",
      "    self._update_no_improvement_count(early_stopping, X_val, y_val)\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 704, in _update_no_improvement_count\n",
      "    self.validation_scores_.append(self._score(X_val, y_val))\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 1610, in _score\n",
      "    return r2_score(y, y_pred)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [-1610738.58788195 -2658897.03858887  -778580.55850745 -1553084.17864298\n",
      " -2660283.27543785  -589736.19813803  -964552.17830727 -2661500.08308687\n",
      "  -733482.21337216 -1919649.45393209 -2657919.45763676  -638533.63121662\n",
      " -1543235.66227738 -2659045.83194876  -464325.5713223  -1040233.85377898\n",
      " -2657883.12829484  -508876.47663748 -2072238.88844136 -2671595.00810324\n",
      " -1009666.62781299 -1585806.49618084 -2659199.39853183  -518223.75234515\n",
      " -1122911.99042008 -2659749.67635449  -668332.92167156 -1623006.04573909\n",
      " -2658188.16601107  -790893.85388681 -1552384.80669537 -2659776.11370283\n",
      "  -673313.12924971 -1080740.37798938 -2659661.84717345  -544223.9882438\n",
      " -1898621.68697788 -2661744.91614569  -867629.31236857 -1573387.47867665\n",
      " -2661091.10581951  -461936.97086385 -1461326.75016488 -2659797.06718651\n",
      "  -656299.06234651 -2116995.98639824 -2661771.36215214  -560937.68848\n",
      " -1589625.73194087 -2670854.55335043 -1144004.51389655 -1358788.58033139\n",
      " -2669274.89112357  -547061.55375489 -1618221.17507473               nan\n",
      " -1377742.44856937 -1503066.0608073                nan -1378395.4405845\n",
      " -1541031.57589546               nan -1404775.55066805 -1821082.70692914\n",
      "               nan -1378029.07069179 -1524799.13788441               nan\n",
      " -1379834.44993213 -1549322.2991066                nan -1398364.04835354\n",
      " -2019576.20491459               nan -1378270.45571351 -1567685.84849158\n",
      "               nan -1379520.12403022 -1467479.66647616               nan\n",
      " -1382450.19631906 -1616017.74979686               nan -1379952.14169032\n",
      " -1533125.17145325               nan -1378946.7239756  -1542644.97898924\n",
      "               nan -1376250.23973002 -1813304.45435722               nan\n",
      " -1379694.31295439 -1522984.90823056               nan -1379800.19867864\n",
      " -1525285.87550623               nan -1380034.21560132 -2018271.34204615\n",
      "               nan -1378004.6449985  -1566440.32832724               nan\n",
      " -1378899.90096165 -1463646.76380172               nan -1378453.18171967\n",
      " -3380025.06069114 -2666236.44513228 -2390768.61858107 -2740537.01072422\n",
      " -2664336.16860457 -2553590.84758687 -3380639.32077109 -2656965.09820935\n",
      " -2660162.54861785 -3499424.45300258 -2664668.82423133 -2657217.54540474\n",
      " -3042433.33806116 -2660881.03255847 -1675778.24837036 -3502298.80411526\n",
      " -2659152.37141299 -1817790.86882264 -3558319.35619584 -2665651.16112632\n",
      " -2395477.2348695  -3194273.79232378 -2671855.04737516 -1910121.32227097\n",
      " -3559791.46203055 -2655691.79931062 -2080019.94493478 -3380408.96097579\n",
      " -2657773.68211178 -2658331.60076169 -2743283.95922528 -2659357.04687276\n",
      " -1927751.54207436 -3380480.35495435 -2660449.56504419 -2659988.95044547\n",
      " -3500105.24873669 -2664015.85956532 -2600474.28152823 -3044041.89373774\n",
      " -2663814.20190626 -1751851.98786905 -3501744.41511077 -2670604.33944891\n",
      " -2051082.54081444 -3557637.83856411 -2677597.05357461 -2506390.49155083\n",
      " -3194169.76309231 -2660161.35961981 -1880131.31843176 -3560837.93934285\n",
      " -2662351.23721292 -2113880.34835436]\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 0.01,\n",
       " 'batch_size': 50,\n",
       " 'early_stopping': True,\n",
       " 'hidden_layer_sizes': 44,\n",
       " 'max_iter': 200,\n",
       " 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir diccionario de valores para parámetros \n",
    "params = {'max_iter': [200],\n",
    "          'hidden_layer_sizes':[11, 44, (44, 11)],\n",
    "          'batch_size': [30, 50, 70],\n",
    "          'activation': ['relu', 'identity', 'tanh'],\n",
    "          'alpha': [0.1, 0.01],\n",
    "          'early_stopping' : [True],\n",
    "          'solver' : ['adam', 'sgd', 'lbfgs']}\n",
    "\n",
    "# Definir modelo y aplicar combinaciones de parametros según el diccinario \n",
    "rn = MLPRegressor()\n",
    "rn_cv = GridSearchCV(rn, param_grid = params, cv = 3, scoring='neg_mean_squared_error', verbose=True, n_jobs = -1)\n",
    "\n",
    "# Entrenar modelo con cada combinación de parámetro \n",
    "rn_cv.fit(X_train, y_train)\n",
    "\n",
    "# Motrar mejores valores para parámeros\n",
    "rn_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 - train: 0.976\n",
      "RMSE - train: 866.0\n",
      "MAE - train: 522.0\n",
      "MAPE - train: 0.78\n",
      "\n",
      "R2 - test: 0.94\n",
      "RMSE - test: 1343.0\n",
      "MAE - test: 629.0\n",
      "MAPE - test: 0.62\n"
     ]
    }
   ],
   "source": [
    "# hacer un RN con los mejores parametros obtenidos y entrenar\n",
    "rn_best = MLPRegressor(activation = 'relu',\n",
    "                            alpha = 0.01, \n",
    "                           batch_size= 50, \n",
    "                            early_stopping = True, \n",
    "                           hidden_layer_sizes = 60, \n",
    "                            max_iter = 200, \n",
    "                           solver = 'lbfgs',\n",
    "                            )\n",
    "\n",
    "# Entrenar con el conjunto de entrenamiento \n",
    "rn_best.fit(X_train, y_train)\n",
    "\n",
    "# Aplicar modelo sobre los datos de traint y test para predecir el target\n",
    "y_test_pred_rn = rn_best.predict(X_test) \n",
    "y_train_pred_rn = rn_best.predict(X_train) \n",
    "\n",
    "# Calculo de metricas en train\n",
    "r2_train_rn = np.round(r2_score(y_train, y_train_pred_rn), 3)\n",
    "rmse_train_rn = np.round(np.sqrt(mean_squared_error(y_train, y_train_pred_rn)), 0)\n",
    "mae_train_rn = np.round(mean_absolute_error(y_train, y_train_pred_rn), 0)\n",
    "mape_train_rn = np.round(mean_absolute_percentage_error(y_train, y_train_pred_rn), 2)\n",
    "\n",
    "# Calculo de metricas en test\n",
    "r2_test_rn = np.round(r2_score(y_test, y_test_pred_rn), 3)\n",
    "rmse_test_rn = np.round(np.sqrt(mean_squared_error(y_test, y_test_pred_rn)), 0) \n",
    "mae_test_rn = np.round(mean_absolute_error(y_test, y_test_pred_rn), 0)\n",
    "mape_test_rn = np.round(mean_absolute_percentage_error(y_test, y_test_pred_rn), 2)  \n",
    "\n",
    "# Mostrar métricas\n",
    "print(\"R2 - train:\", r2_train_rn)\n",
    "print(\"RMSE - train:\", rmse_train_rn)\n",
    "print(\"MAE - train:\", mae_train_rn)\n",
    "print(\"MAPE - train:\", mape_train_rn)\n",
    "print(\"\")\n",
    "print(\"R2 - test:\", r2_test_rn)\n",
    "print(\"RMSE - test:\", rmse_test_rn)\n",
    "print(\"MAE - test:\", mae_test_rn)\n",
    "print(\"MAPE - test:\", mape_test_rn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Modelos Que Aceptan Datos Nulos*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora evalueremos los datos con dos modelos que aceptan datos nulos (Hist Gradient Boosting y XGBoost), por lo que haremos una copia del conjunto de datos con todos los países y, al igual que antes, haremos de la variable \"Year\" una variable ordinal y el resto de variable categóricas a variables *dummy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9360 entries, 0 to 9359\n",
      "Data columns (total 71 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   Year                                      9360 non-null   int64  \n",
      " 1   Immigrant count                           9360 non-null   int64  \n",
      " 2   Unemployment %                            9360 non-null   float64\n",
      " 3   Political and Violence Percentile         9360 non-null   float64\n",
      " 4   Probability of dying young                9360 non-null   float64\n",
      " 5   Rule of Law Percentile                    9360 non-null   float64\n",
      " 6   Salaried workers %                        9360 non-null   float64\n",
      " 7   GDP_growth                                9360 non-null   float64\n",
      " 8   Inflation_annual                          9360 non-null   float64\n",
      " 9   Liberal democracy index                   9360 non-null   float64\n",
      " 10  Health equality                           9360 non-null   float64\n",
      " 11  Judicial accountability                   9360 non-null   float64\n",
      " 12  One-sided violence_deaths                 9360 non-null   int64  \n",
      " 13  Non-state_deaths                          9360 non-null   int64  \n",
      " 14  Intrastate_deaths                         9360 non-null   int64  \n",
      " 15  Interstate_deaths                         9360 non-null   int64  \n",
      " 16  Number of residents                       9360 non-null   int64  \n",
      " 17  Political regime                          9360 non-null   int64  \n",
      " 18  Homicide Rate                             9024 non-null   float64\n",
      " 19  Number of Turist                          9360 non-null   int64  \n",
      " 20  Spanish language                          9360 non-null   int64  \n",
      " 21  Restricciones_pandemia                    9360 non-null   int64  \n",
      " 22  Año post_pandemia                         9360 non-null   int64  \n",
      " 23  Nationality code_ARG                      9360 non-null   int32  \n",
      " 24  Nationality code_BGR                      9360 non-null   int32  \n",
      " 25  Nationality code_BRA                      9360 non-null   int32  \n",
      " 26  Nationality code_CHN                      9360 non-null   int32  \n",
      " 27  Nationality code_COL                      9360 non-null   int32  \n",
      " 28  Nationality code_CUB                      9360 non-null   int32  \n",
      " 29  Nationality code_DEU                      9360 non-null   int32  \n",
      " 30  Nationality code_DOM                      9360 non-null   int32  \n",
      " 31  Nationality code_DZA                      9360 non-null   int32  \n",
      " 32  Nationality code_ECU                      9360 non-null   int32  \n",
      " 33  Nationality code_FRA                      9360 non-null   int32  \n",
      " 34  Nationality code_GBR                      9360 non-null   int32  \n",
      " 35  Nationality code_HND                      9360 non-null   int32  \n",
      " 36  Nationality code_ITA                      9360 non-null   int32  \n",
      " 37  Nationality code_MAR                      9360 non-null   int32  \n",
      " 38  Nationality code_NIC                      9360 non-null   int32  \n",
      " 39  Nationality code_PAK                      9360 non-null   int32  \n",
      " 40  Nationality code_PER                      9360 non-null   int32  \n",
      " 41  Nationality code_PRT                      9360 non-null   int32  \n",
      " 42  Nationality code_PRY                      9360 non-null   int32  \n",
      " 43  Nationality code_ROU                      9360 non-null   int32  \n",
      " 44  Nationality code_RUS                      9360 non-null   int32  \n",
      " 45  Nationality code_SEN                      9360 non-null   int32  \n",
      " 46  Nationality code_UKR                      9360 non-null   int32  \n",
      " 47  Nationality code_USA                      9360 non-null   int32  \n",
      " 48  Nationality code_VEN                      9360 non-null   int32  \n",
      " 49  Sex_Both                                  9360 non-null   int32  \n",
      " 50  Sex_Females                               9360 non-null   int32  \n",
      " 51  Sex_Males                                 9360 non-null   int32  \n",
      " 52  Age group_0 - 14                          9360 non-null   int32  \n",
      " 53  Age group_15 - 24                         9360 non-null   int32  \n",
      " 54  Age group_25 - 34                         9360 non-null   int32  \n",
      " 55  Age group_35 - 44                         9360 non-null   int32  \n",
      " 56  Age group_45 - 54                         9360 non-null   int32  \n",
      " 57  Age group_55 - 64                         9360 non-null   int32  \n",
      " 58  Age group_65+                             9360 non-null   int32  \n",
      " 59  Age group_All                             9360 non-null   int32  \n",
      " 60  Continent_Africa                          9360 non-null   int32  \n",
      " 61  Continent_America                         9360 non-null   int32  \n",
      " 62  Continent_Asia                            9360 non-null   int32  \n",
      " 63  Continent_Europe                          9360 non-null   int32  \n",
      " 64  Sub-region_Africa                         9360 non-null   int32  \n",
      " 65  Sub-region_Asia                           9360 non-null   int32  \n",
      " 66  Sub-region_Central America and Caribbean  9360 non-null   int32  \n",
      " 67  Sub-region_European Union                 9360 non-null   int32  \n",
      " 68  Sub-region_North America                  9360 non-null   int32  \n",
      " 69  Sub-region_Rest of Europe                 9360 non-null   int32  \n",
      " 70  Sub-region_South America                  9360 non-null   int32  \n",
      "dtypes: float64(11), int32(48), int64(12)\n",
      "memory usage: 3.4 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Immigrant count</th>\n",
       "      <th>Unemployment %</th>\n",
       "      <th>Political and Violence Percentile</th>\n",
       "      <th>Probability of dying young</th>\n",
       "      <th>Rule of Law Percentile</th>\n",
       "      <th>Salaried workers %</th>\n",
       "      <th>GDP_growth</th>\n",
       "      <th>Inflation_annual</th>\n",
       "      <th>Liberal democracy index</th>\n",
       "      <th>...</th>\n",
       "      <th>Continent_America</th>\n",
       "      <th>Continent_Asia</th>\n",
       "      <th>Continent_Europe</th>\n",
       "      <th>Sub-region_Africa</th>\n",
       "      <th>Sub-region_Asia</th>\n",
       "      <th>Sub-region_Central America and Caribbean</th>\n",
       "      <th>Sub-region_European Union</th>\n",
       "      <th>Sub-region_North America</th>\n",
       "      <th>Sub-region_Rest of Europe</th>\n",
       "      <th>Sub-region_South America</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>759</td>\n",
       "      <td>11.33</td>\n",
       "      <td>14.90</td>\n",
       "      <td>3.7</td>\n",
       "      <td>24.52</td>\n",
       "      <td>67.41</td>\n",
       "      <td>2.40</td>\n",
       "      <td>15.31</td>\n",
       "      <td>0.164</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2938</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.649</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1128</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.649</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.649</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.649</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9355</th>\n",
       "      <td>15</td>\n",
       "      <td>330</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>4.71</td>\n",
       "      <td>13.96</td>\n",
       "      <td>0.234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9356</th>\n",
       "      <td>15</td>\n",
       "      <td>146</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>4.71</td>\n",
       "      <td>13.96</td>\n",
       "      <td>0.234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9357</th>\n",
       "      <td>15</td>\n",
       "      <td>169</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>4.71</td>\n",
       "      <td>13.96</td>\n",
       "      <td>0.234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9358</th>\n",
       "      <td>15</td>\n",
       "      <td>99</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>4.71</td>\n",
       "      <td>13.96</td>\n",
       "      <td>0.234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9359</th>\n",
       "      <td>15</td>\n",
       "      <td>70</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>4.71</td>\n",
       "      <td>13.96</td>\n",
       "      <td>0.234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9360 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  Immigrant count  Unemployment %  \\\n",
       "0        1              759           11.33   \n",
       "1        1             2938            4.03   \n",
       "2        1             1128            4.03   \n",
       "3        1              265            4.03   \n",
       "4        1              156            4.03   \n",
       "...    ...              ...             ...   \n",
       "9355    15              330            5.60   \n",
       "9356    15              146            5.60   \n",
       "9357    15              169            5.60   \n",
       "9358    15               99            5.60   \n",
       "9359    15               70            5.60   \n",
       "\n",
       "      Political and Violence Percentile  Probability of dying young  \\\n",
       "0                                 14.90                         3.7   \n",
       "1                                 17.31                         5.1   \n",
       "2                                 17.31                         5.1   \n",
       "3                                 17.31                         5.1   \n",
       "4                                 17.31                         5.1   \n",
       "...                                 ...                         ...   \n",
       "9355                               6.60                         5.8   \n",
       "9356                               6.60                         5.8   \n",
       "9357                               6.60                         5.8   \n",
       "9358                               6.60                         5.8   \n",
       "9359                               6.60                         5.8   \n",
       "\n",
       "      Rule of Law Percentile  Salaried workers %  GDP_growth  \\\n",
       "0                      24.52               67.41        2.40   \n",
       "1                      25.96               44.47        9.13   \n",
       "2                      25.96               44.47        9.13   \n",
       "3                      25.96               44.47        9.13   \n",
       "4                      25.96               44.47        9.13   \n",
       "...                      ...                 ...         ...   \n",
       "9355                   25.00               42.14        4.71   \n",
       "9356                   25.00               42.14        4.71   \n",
       "9357                   25.00               42.14        4.71   \n",
       "9358                   25.00               42.14        4.71   \n",
       "9359                   25.00               42.14        4.71   \n",
       "\n",
       "      Inflation_annual  Liberal democracy index  ...  Continent_America  \\\n",
       "0                15.31                    0.164  ...                  0   \n",
       "1                 1.10                    0.649  ...                  1   \n",
       "2                 1.10                    0.649  ...                  1   \n",
       "3                 1.10                    0.649  ...                  1   \n",
       "4                 1.10                    0.649  ...                  1   \n",
       "...                ...                      ...  ...                ...   \n",
       "9355             13.96                    0.234  ...                  0   \n",
       "9356             13.96                    0.234  ...                  0   \n",
       "9357             13.96                    0.234  ...                  0   \n",
       "9358             13.96                    0.234  ...                  0   \n",
       "9359             13.96                    0.234  ...                  0   \n",
       "\n",
       "      Continent_Asia  Continent_Europe  Sub-region_Africa  Sub-region_Asia  \\\n",
       "0                  0                 0                  1                0   \n",
       "1                  0                 0                  0                0   \n",
       "2                  0                 0                  0                0   \n",
       "3                  0                 0                  0                0   \n",
       "4                  0                 0                  0                0   \n",
       "...              ...               ...                ...              ...   \n",
       "9355               1                 0                  0                1   \n",
       "9356               1                 0                  0                1   \n",
       "9357               1                 0                  0                1   \n",
       "9358               1                 0                  0                1   \n",
       "9359               1                 0                  0                1   \n",
       "\n",
       "      Sub-region_Central America and Caribbean  Sub-region_European Union  \\\n",
       "0                                            0                          0   \n",
       "1                                            0                          0   \n",
       "2                                            0                          0   \n",
       "3                                            0                          0   \n",
       "4                                            0                          0   \n",
       "...                                        ...                        ...   \n",
       "9355                                         0                          0   \n",
       "9356                                         0                          0   \n",
       "9357                                         0                          0   \n",
       "9358                                         0                          0   \n",
       "9359                                         0                          0   \n",
       "\n",
       "      Sub-region_North America  Sub-region_Rest of Europe  \\\n",
       "0                            0                          0   \n",
       "1                            0                          0   \n",
       "2                            0                          0   \n",
       "3                            0                          0   \n",
       "4                            0                          0   \n",
       "...                        ...                        ...   \n",
       "9355                         0                          0   \n",
       "9356                         0                          0   \n",
       "9357                         0                          0   \n",
       "9358                         0                          0   \n",
       "9359                         0                          0   \n",
       "\n",
       "      Sub-region_South America  \n",
       "0                            0  \n",
       "1                            1  \n",
       "2                            1  \n",
       "3                            1  \n",
       "4                            1  \n",
       "...                        ...  \n",
       "9355                         0  \n",
       "9356                         0  \n",
       "9357                         0  \n",
       "9358                         0  \n",
       "9359                         0  \n",
       "\n",
       "[9360 rows x 71 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hacer copia del df_noagg\n",
    "df_copy = df.copy()\n",
    "\n",
    "# Transformar Year a variable ordinal de 1 (2008) a 15 (2022)\n",
    "df_copy['Year'] = df_copy['Year'] - 2007\n",
    "\n",
    "# Generar variables dummies a partir de nuestras variables categóricas \"object\" (no ordinales)\n",
    "df_copy = pd.get_dummies(df_copy)\n",
    "\n",
    "# Convertir las variables dummies booleanas en \"int\"\n",
    "col_bool = df_copy.select_dtypes(include = ['bool']).columns\n",
    "df_copy[col_bool] = df_copy[col_bool].astype(int)\n",
    "\n",
    "# Verificar cambio\n",
    "df_copy.info()\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separemos el conjunto train/test y escalemos los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar variables input y variable target \"Immigrant count\" de df_copy\n",
    "X = df_copy.drop(\"Immigrant count\", axis = 1) # variables predictoras\n",
    "y = df_copy[\"Immigrant count\"]  # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 58) # separar datos en conjunto train y test en un 75% / 25%\n",
    "scaler_agg = MinMaxScaler() # definir scaler de datos \n",
    "X_train = scaler_agg.fit_transform(X_train) # escalar los datos de entrenamiento\n",
    "X_test = scaler_agg.transform(X_test) # # escalar los datos de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hist Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "108 fits failed out of a total of 324.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "108 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py\", line 353, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of HistGradientBoostingRegressor must be a str among {'quantile', 'squared_error', 'absolute_error', 'poisson'} or an instance of 'sklearn._loss.loss.BaseLoss'. Got 'gamma' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [ -5254158.8937066   -4390963.00554829  -3985693.17818779\n",
      "  -5168145.8171197   -4299578.48543939  -3894190.96239888\n",
      "                nan                nan                nan\n",
      "                nan                nan                nan\n",
      " -34185088.36565981 -21225849.9553362   -4488720.48824894\n",
      " -33579811.66007066 -21076162.05724657  -5161241.90553651\n",
      " -10369886.50031281 -10966510.50017865 -11529539.10337436\n",
      " -10582192.03169888 -10972074.08833781 -11534323.95698428\n",
      "                nan                nan                nan\n",
      "                nan                nan                nan\n",
      "  -9256528.30140574  -9362759.3062009   -9165684.36981735\n",
      "  -9244602.83143982  -9322770.57564213  -9234372.22849301\n",
      "  -4895173.12757906  -4256081.30635853  -3914437.78752085\n",
      "  -4732582.09665527  -4282199.29241672  -4004954.46495573\n",
      "                nan                nan                nan\n",
      "                nan                nan                nan\n",
      " -34551355.08046547 -30866518.43605746  -4648890.37457023\n",
      " -33855256.95459896 -30190465.98594813  -5161206.48317103\n",
      " -10722189.10087235 -11020440.74411567 -11546702.89044576\n",
      " -10825837.61068233 -11096246.40355499 -11534539.75868252\n",
      "                nan                nan                nan\n",
      "                nan                nan                nan\n",
      "  -9257943.08513038  -9365658.02557595  -9160726.74766324\n",
      "  -9235677.31087947  -9327338.92542152  -9236197.88181915\n",
      "  -4916293.24322191  -4196095.51518371  -3954172.58539311\n",
      "  -5008145.29647914  -4169848.82621236  -3810224.61092249\n",
      "                nan                nan                nan\n",
      "                nan                nan                nan\n",
      " -34544053.6168785  -31389259.49707364  -4656204.01024773\n",
      " -33812639.38029661 -30199726.68965024  -5151099.17850898\n",
      " -10832446.86178133 -11151700.27563695 -11674132.71523669\n",
      " -11018473.50224838 -11206973.16110575 -11664560.25425392\n",
      "                nan                nan                nan\n",
      "                nan                nan                nan\n",
      "  -9252818.10109129  -9367072.06018922  -9165439.7459473\n",
      "  -9231952.56253368  -9326318.60904643  -9235321.19045814]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HistGradientBoostingRegressor(l2_regularization=0.3, max_depth=8, max_iter=120,\n",
       "                              min_samples_leaf=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingRegressor(l2_regularization=0.3, max_depth=8, max_iter=120,\n",
       "                              min_samples_leaf=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "HistGradientBoostingRegressor(l2_regularization=0.3, max_depth=8, max_iter=120,\n",
       "                              min_samples_leaf=5)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir diccionario de valores para parámetros \n",
    "params = {'max_iter': [120], \n",
    "\t      'loss' : ['squared_error', 'gamma', 'poisson'],\n",
    "          \"learning_rate\": [0.1, 0.01], \n",
    "          'min_samples_leaf' : [2, 3, 5],\n",
    "          \"max_depth\": [7, 8],\n",
    "          'l2_regularization' : [0.0, 0.1, 0.3]\n",
    "          }\n",
    "\n",
    "# Definir modelo y aplicar combinaciones de parametros según el diccinario \n",
    "hgb = HistGradientBoostingRegressor() \n",
    "hgb_cv = GridSearchCV(hgb, params, cv=3, scoring='neg_mean_squared_error').fit(X_train, y_train)\n",
    "\n",
    "hgb_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 - train: 0.988\n",
      "RMSE - train: 604.0\n",
      "MAE - train: 294.0\n",
      "MAPE - train: 0.41\n",
      "\n",
      "R2 - test: 0.942\n",
      "RMSE - test: 1319.0\n",
      "MAE - test: 432.0\n",
      "MAPE - test: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Definir modelo con los mejores valores de parámetros (Nota: usar los mejores, pero hacer modificaciones para comparar metricas)\n",
    "hgb_best = HistGradientBoostingRegressor(\n",
    "                           max_iter = 100, \n",
    "                           max_depth = 8,\n",
    "                           loss = 'poisson', \n",
    "                           learning_rate = 0.08, \n",
    "                           min_samples_leaf = 36,\n",
    "                           max_leaf_nodes = 30,\n",
    "                           )\n",
    "\n",
    "# Entrenar con el conjunto de entrenamiento \n",
    "hgb_best.fit(X_train, y_train) \n",
    "\n",
    "# Aplicar modelo sobre los datos de traint y test para predecir el target\n",
    "y_train_pred_hgb = hgb_best.predict(X_train)\n",
    "y_test_pred_hgb = hgb_best.predict(X_test)\n",
    "\n",
    "# Calculo de metricas en train\n",
    "r2_train_hgb = np.round(r2_score(y_train, y_train_pred_hgb), 3)\n",
    "rmse_train_hgb = np.round(np.sqrt(mean_squared_error(y_train, y_train_pred_hgb)), 0)\n",
    "mae_train_hgb = np.round(mean_absolute_error(y_train, y_train_pred_hgb), 0)\n",
    "mape_train_hgb = np.round(mean_absolute_percentage_error(y_train, y_train_pred_hgb), 2)\n",
    "\n",
    "# Calculo de metricas en train\n",
    "r2_test_hgb = np.round(r2_score(y_test, y_test_pred_hgb), 3)\n",
    "rmse_test_hgb = np.round(np.sqrt(mean_squared_error(y_test, y_test_pred_hgb)), 0)\n",
    "mae_test_hgb = np.round(mean_absolute_error(y_test, y_test_pred_hgb), 0)\n",
    "mape_test_hgb = np.round(mean_absolute_percentage_error(y_test, y_test_pred_hgb), 2)\n",
    "\n",
    "# Mostrar métricas\n",
    "print(\"R2 - train:\", r2_train_hgb)\n",
    "print(\"RMSE - train:\", rmse_train_hgb)\n",
    "print(\"MAE - train:\", mae_train_hgb)\n",
    "print(\"MAPE - train:\", mape_train_hgb)\n",
    "print('')\n",
    "print(\"R2 - test:\", r2_test_hgb)\n",
    "print(\"RMSE - test:\", rmse_test_hgb)\n",
    "print(\"MAE - test:\", mae_test_hgb)\n",
    "print(\"MAPE - test:\", mape_test_hgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_mean</th>\n",
       "      <th>importance_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Age group_All</td>\n",
       "      <td>1.043920</td>\n",
       "      <td>0.064473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Number of residents</td>\n",
       "      <td>0.598518</td>\n",
       "      <td>0.067383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Year</td>\n",
       "      <td>0.182678</td>\n",
       "      <td>0.017346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Number of Turist</td>\n",
       "      <td>0.158322</td>\n",
       "      <td>0.024787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Sex_Both</td>\n",
       "      <td>0.086540</td>\n",
       "      <td>0.021279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unemployment %</td>\n",
       "      <td>0.081296</td>\n",
       "      <td>0.009323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Age group_65+</td>\n",
       "      <td>0.058854</td>\n",
       "      <td>0.007528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Salaried workers %</td>\n",
       "      <td>0.044103</td>\n",
       "      <td>0.004677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Age group_55 - 64</td>\n",
       "      <td>0.043676</td>\n",
       "      <td>0.010874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Health equality</td>\n",
       "      <td>0.026059</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Inflation_annual</td>\n",
       "      <td>0.025066</td>\n",
       "      <td>0.002316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Judicial accountability</td>\n",
       "      <td>0.015119</td>\n",
       "      <td>0.001826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Age group_45 - 54</td>\n",
       "      <td>0.014857</td>\n",
       "      <td>0.002266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Age group_25 - 34</td>\n",
       "      <td>0.014759</td>\n",
       "      <td>0.000662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Homicide Rate</td>\n",
       "      <td>0.013470</td>\n",
       "      <td>0.002562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature  importance_mean  importance_std\n",
       "58            Age group_All         1.043920        0.064473\n",
       "15      Number of residents         0.598518        0.067383\n",
       "0                      Year         0.182678        0.017346\n",
       "18         Number of Turist         0.158322        0.024787\n",
       "48                 Sex_Both         0.086540        0.021279\n",
       "1            Unemployment %         0.081296        0.009323\n",
       "57            Age group_65+         0.058854        0.007528\n",
       "5        Salaried workers %         0.044103        0.004677\n",
       "56        Age group_55 - 64         0.043676        0.010874\n",
       "9           Health equality         0.026059        0.004393\n",
       "7          Inflation_annual         0.025066        0.002316\n",
       "10  Judicial accountability         0.015119        0.001826\n",
       "55        Age group_45 - 54         0.014857        0.002266\n",
       "53        Age group_25 - 34         0.014759        0.000662\n",
       "17            Homicide Rate         0.013470        0.002562"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importancia por permutaciones\n",
    "importancias_permu = permutation_importance(hgb_best, X_train, y_train, n_repeats=10, random_state=58)\n",
    "\n",
    "# Importancias en dataframe\n",
    "importances_hgb = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance_mean': importancias_permu.importances_mean,\n",
    "    'importance_std': importancias_permu.importances_std\n",
    "}).sort_values(by='importance_mean', ascending=False)\n",
    "\n",
    "importances_hgb.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar tablas comparativas de metricas\n",
    "importances_hgb.to_csv(\"../16 - Exports Modelos/agregados/feature_importance_hgb.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:29:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:29:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:29:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:07] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:07] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:09] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:09] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:14] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:15] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:15] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:16] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:16] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:19] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'booster': 'dart',\n",
       " 'eval_metric': 'rmse',\n",
       " 'learning_rate': 0.3,\n",
       " 'max_depth': 7,\n",
       " 'n_estimators': 200,\n",
       " 'objective': 'reg:squarederror'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir diccionario de valores para parámetros \n",
    "params = {'objective' : ['reg:squarederror', 'reg:squaredlogerror']\n",
    "          'eval_metric' : ['rmse'],   # rmsle disminuye efecto de outliers\n",
    "          'booster' : [\"gbtree\", \"gblinear\", \"dart\"], # gbtree (default) y dart estan basados en arboles\n",
    "          'n_estimators': [200],\n",
    "          'max_depth': [7, 9], # dependiendo de la dimensionalidad de los datos, usar valores de profundidad menor\n",
    "          \"learning_rate\" : [0.1, 0.3, 0.05]\n",
    "          }\n",
    "\n",
    "# Definir modelo y aplicar combinaciones de parametros según el diccinario \n",
    "xgb = XGBRegressor()\n",
    "xgb_cv = GridSearchCV(xgb, params, cv=3, scoring = 'neg_mean_squared_error') # elegir scoring deseano (r2, mae, mse, mape...)\n",
    "\n",
    "# Entrenar modelo con cada combinación de parámetro \n",
    "xgb_cv.fit(X_train,y_train)\n",
    "\n",
    "# Motrar mejores valores para parámeros\n",
    "xgb_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 - train: 0.983\n",
      "RMSE - train: 707.0\n",
      "MAE - train: 302.0\n",
      "MAPE - train: 0.77\n",
      "\n",
      "R2 - test: 0.884\n",
      "RMSE - test: 1871.0\n",
      "MAE - test: 572.0\n",
      "MAPE - test: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Definir modelo con los mejores valores de parámetros (Nota: usar los mejores, pero hacer modificaciones al comparar metricas)\n",
    "xgb_best = XGBRegressor(objective = 'reg:squarederror', \n",
    "                        eval_metric = 'rmse',\n",
    "                        booster = 'dart',\n",
    "                        n_estimators = 200,\n",
    "                        max_depth = 7,\n",
    "                        learning_rate = 0.3,\n",
    "                        min_child_weight = 30\n",
    "                    )\n",
    "\n",
    "# Entrenar modelo con el conjunto de entrenamiento \n",
    "xgb_best.fit(X_train, y_train)\n",
    "\n",
    "# Aplicar modelo sobre los datos de traint y test para predecir el target\n",
    "y_train_pred_xgb = xgb_best.predict(X_train) \n",
    "y_test_pred_xgb = xgb_best.predict(X_test) \n",
    "\n",
    "\n",
    "# Calculate metrics for train set\n",
    "r2_train_xgb = np.round(r2_score(y_train, y_train_pred_xgb), 3)\n",
    "rmse_train_xgb = np.round(np.sqrt(mean_squared_error(y_train, y_train_pred_xgb)), 0)\n",
    "mae_train_xgb = np.round(mean_absolute_error(y_train, y_train_pred_xgb), 0)\n",
    "mape_train_xgb = np.round(mean_absolute_percentage_error(y_train, y_train_pred_xgb), 2)\n",
    "\n",
    "# Calculate metrics for test set\n",
    "r2_test_xgb = np.round(r2_score(y_test, y_test_pred_xgb), 3)\n",
    "rmse_test_xgb = np.round(np.sqrt(mean_squared_error(y_test, y_test_pred_xgb)), 0)\n",
    "mae_test_xgb = np.round(mean_absolute_error(y_test, y_test_pred_xgb), 0)\n",
    "mape_test_xgb = np.round(mean_absolute_percentage_error(y_test, y_test_pred_xgb), 2)\n",
    "\n",
    "# Print metrics\n",
    "print(\"R2 - train:\", r2_train_xgb)\n",
    "print(\"RMSE - train:\", rmse_train_xgb)\n",
    "print(\"MAE - train:\", mae_train_xgb)\n",
    "print(\"MAPE - train:\", mape_train_xgb)\n",
    "print(\"\")\n",
    "print(\"R2 - test:\", r2_test_xgb)\n",
    "print(\"RMSE - test:\", rmse_test_xgb)\n",
    "print(\"MAE - test:\", mae_test_xgb)\n",
    "print(\"MAPE - test:\", mape_test_xgb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Comparar Modelos*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juntemos los resultados todos los modelos en un dataframe por tipo de métrica, ordenando por el mejor valor en el conjunto test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>R² train</th>\n",
       "      <th>R² test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HGB</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Red Neuronal</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lineal</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lineal - Ridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lineal - Lasso</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lineal - Theilsen</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lineal - Huber</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lineal - E-Net</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lineal - RANSAC</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Modelo  R² train  R² test\n",
       "12                HGB     0.988    0.942\n",
       "11       Red Neuronal     0.976    0.940\n",
       "13            XGBoost     0.983    0.884\n",
       "8       Random Forest     0.801    0.744\n",
       "7       Decision Tree     0.838    0.712\n",
       "9                 KNN     0.630    0.633\n",
       "0              Lineal     0.445    0.507\n",
       "4      Lineal - Ridge       NaN    0.507\n",
       "5      Lineal - Lasso       NaN    0.506\n",
       "3   Lineal - Theilsen     0.372    0.473\n",
       "1      Lineal - Huber     0.249    0.277\n",
       "6      Lineal - E-Net       NaN    0.103\n",
       "2     Lineal - RANSAC     0.033    0.035\n",
       "10                SVR     0.026    0.022"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Juntar en un dataframe los datos\n",
    "modelos_r2 = pd.DataFrame({\n",
    "    'Modelo' : ['Lineal', 'Lineal - Huber', 'Lineal - RANSAC', 'Lineal - Theilsen', 'Lineal - Ridge', 'Lineal - Lasso', 'Lineal - E-Net', 'Decision Tree', 'Random Forest', 'KNN', 'SVR', 'Red Neuronal', 'HGB', 'XGBoost'],\n",
    "    'R² train' : [r2_train_lineal, r2_train_huber, r2_train_ransac, r2_train_theilsen, np.nan, np.nan, np.nan, r2_train_tree, r2_train_rf, r2_train_knn, r2_train_svr, r2_train_rn, r2_train_hgb, r2_train_xgb],\n",
    "    'R² test' : [r2_test_lineal, r2_test_huber, r2_test_ransac, r2_test_theilsen, r2_test_ridge, r2_test_lasso, r2_test_enet, r2_test_tree, r2_test_rf, r2_test_knn, r2_test_svr, r2_test_rn, r2_test_hgb, r2_test_xgb],\n",
    "})\n",
    "\n",
    "# Ordenar de forma descendente por R² test\n",
    "modelos_r2.sort_values(by = 'R² test', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>RSME train</th>\n",
       "      <th>RSME test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HGB</td>\n",
       "      <td>604.0</td>\n",
       "      <td>1319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Red Neuronal</td>\n",
       "      <td>866.0</td>\n",
       "      <td>1343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>707.0</td>\n",
       "      <td>1871.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2474.0</td>\n",
       "      <td>2775.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>2228.0</td>\n",
       "      <td>2947.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNN</td>\n",
       "      <td>3369.0</td>\n",
       "      <td>3325.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lineal</td>\n",
       "      <td>4128.0</td>\n",
       "      <td>3853.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lineal - Ridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3855.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lineal - Lasso</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3859.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lineal - Theilsen</td>\n",
       "      <td>4389.0</td>\n",
       "      <td>3985.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lineal - Huber</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>4668.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lineal - E-Net</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lineal - RANSAC</td>\n",
       "      <td>5449.0</td>\n",
       "      <td>5394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVR</td>\n",
       "      <td>5469.0</td>\n",
       "      <td>5430.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Modelo  RSME train  RSME test\n",
       "12                HGB       604.0     1319.0\n",
       "11       Red Neuronal       866.0     1343.0\n",
       "13            XGBoost       707.0     1871.0\n",
       "8       Random Forest      2474.0     2775.0\n",
       "7       Decision Tree      2228.0     2947.0\n",
       "9                 KNN      3369.0     3325.0\n",
       "0              Lineal      4128.0     3853.0\n",
       "4      Lineal - Ridge         NaN     3855.0\n",
       "5      Lineal - Lasso         NaN     3859.0\n",
       "3   Lineal - Theilsen      4389.0     3985.0\n",
       "1      Lineal - Huber      4800.0     4668.0\n",
       "6      Lineal - E-Net         NaN     5199.0\n",
       "2     Lineal - RANSAC      5449.0     5394.0\n",
       "10                SVR      5469.0     5430.0"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Juntar en un dataframe los datos\n",
    "modelos_rsme = pd.DataFrame({\n",
    "    'Modelo' : ['Lineal', 'Lineal - Huber', 'Lineal - RANSAC', 'Lineal - Theilsen', 'Lineal - Ridge', 'Lineal - Lasso', 'Lineal - E-Net', 'Decision Tree', 'Random Forest', 'KNN','SVR', 'Red Neuronal', 'HGB', 'XGBoost'],\n",
    "    'RSME train' : [rmse_train_lineal, rmse_train_huber, rmse_train_ransac, rmse_train_theilsen, np.nan, np.nan, np.nan, rmse_train_tree, rmse_train_rf, rmse_train_knn, rmse_train_svr, rmse_train_rn, rmse_train_hgb, rmse_train_xgb],\n",
    "    'RSME test' : [rmse_test_lineal, rmse_test_huber, rmse_test_ransac, rmse_test_theilsen, rmse_test_ridge, rmse_test_lasso, rmse_test_enet, rmse_test_tree, rmse_test_rf, rmse_test_knn, rmse_test_svr, rmse_test_rn, rmse_test_hgb, rmse_test_xgb],\n",
    "    })\n",
    "\n",
    "# Ordenar de forma ascendente por RSME test\n",
    "modelos_rsme.sort_values(by = 'RSME test', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>MAE train</th>\n",
       "      <th>MAE test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HGB</td>\n",
       "      <td>294.0</td>\n",
       "      <td>432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>302.0</td>\n",
       "      <td>572.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Red Neuronal</td>\n",
       "      <td>522.0</td>\n",
       "      <td>629.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>752.0</td>\n",
       "      <td>910.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>903.0</td>\n",
       "      <td>1125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNN</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lineal - Huber</td>\n",
       "      <td>1306.0</td>\n",
       "      <td>1372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lineal - Theilsen</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>1557.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lineal - RANSAC</td>\n",
       "      <td>1653.0</td>\n",
       "      <td>1745.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVR</td>\n",
       "      <td>1659.0</td>\n",
       "      <td>1758.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lineal - Lasso</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1797.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lineal - Ridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lineal</td>\n",
       "      <td>1773.0</td>\n",
       "      <td>1818.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lineal - E-Net</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2293.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Modelo  MAE train  MAE test\n",
       "12                HGB      294.0     432.0\n",
       "13            XGBoost      302.0     572.0\n",
       "11       Red Neuronal      522.0     629.0\n",
       "8       Random Forest      752.0     910.0\n",
       "7       Decision Tree      903.0    1125.0\n",
       "9                 KNN     1019.0    1136.0\n",
       "1      Lineal - Huber     1306.0    1372.0\n",
       "3   Lineal - Theilsen     1575.0    1557.0\n",
       "2     Lineal - RANSAC     1653.0    1745.0\n",
       "10                SVR     1659.0    1758.0\n",
       "5      Lineal - Lasso        NaN    1797.0\n",
       "4      Lineal - Ridge        NaN    1800.0\n",
       "0              Lineal     1773.0    1818.0\n",
       "6      Lineal - E-Net        NaN    2293.0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Juntar en un dataframe los datos\n",
    "modelos_mae = pd.DataFrame({\n",
    "    'Modelo' : ['Lineal', 'Lineal - Huber', 'Lineal - RANSAC', 'Lineal - Theilsen', 'Lineal - Ridge', 'Lineal - Lasso', 'Lineal - E-Net', 'Decision Tree', 'Random Forest', 'KNN', 'SVR', 'Red Neuronal', 'HGB', 'XGBoost'],\n",
    "    'MAE train' : [mae_train_lineal, mae_train_huber, mae_train_ransac, mae_train_theilsen, np.nan, np.nan, np.nan, mae_train_tree, mae_train_rf, mae_train_knn, mae_train_svr, mae_train_rn, mae_train_hgb, mae_train_xgb],\n",
    "    'MAE test' : [mae_test_lineal, mae_test_huber, mae_test_ransac, mae_test_theilsen, mae_test_ridge, mae_test_lasso, mae_test_enet, mae_test_tree, mae_test_rf, mae_test_knn, mae_test_svr, mae_test_rn, mae_test_hgb, mae_test_xgb],\n",
    "})\n",
    "\n",
    "# Ordenar de forma descendente por MAE test\n",
    "modelos_mae.sort_values(by = 'MAE test', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>MAPE train</th>\n",
       "      <th>MAPE test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HGB</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Red Neuronal</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lineal - RANSAC</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lineal - Huber</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVR</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNN</td>\n",
       "      <td>1.21</td>\n",
       "      <td>1.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lineal - Theilsen</td>\n",
       "      <td>4.76</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lineal - Lasso</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lineal - Ridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lineal</td>\n",
       "      <td>6.50</td>\n",
       "      <td>4.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lineal - E-Net</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Modelo  MAPE train  MAPE test\n",
       "12                HGB        0.41       0.50\n",
       "11       Red Neuronal        0.78       0.62\n",
       "8       Random Forest        0.85       0.81\n",
       "2     Lineal - RANSAC        1.60       0.87\n",
       "1      Lineal - Huber        1.39       0.94\n",
       "13            XGBoost        0.77       0.99\n",
       "10                SVR        1.04       1.01\n",
       "7       Decision Tree        1.84       1.46\n",
       "9                 KNN        1.21       1.52\n",
       "3   Lineal - Theilsen        4.76       3.40\n",
       "5      Lineal - Lasso         NaN       4.52\n",
       "4      Lineal - Ridge         NaN       4.56\n",
       "0              Lineal        6.50       4.65\n",
       "6      Lineal - E-Net         NaN       6.10"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Juntar en un dataframe los datos\n",
    "modelos_mape = pd.DataFrame({\n",
    "    'Modelo' : ['Lineal', 'Lineal - Huber', 'Lineal - RANSAC', 'Lineal - Theilsen', 'Lineal - Ridge', 'Lineal - Lasso', 'Lineal - E-Net', 'Decision Tree', 'Random Forest', 'KNN', 'SVR', 'Red Neuronal', 'HGB', 'XGBoost'],\n",
    "    'MAPE train' : [mape_train_lineal, mape_train_huber, mape_train_ransac, mape_train_theilsen, np.nan, np.nan, np.nan, mape_train_tree, mape_train_rf, mape_train_knn, mape_train_svr, mape_train_rn, mape_train_hgb, mape_train_xgb],\n",
    "    'MAPE test' : [mape_test_lineal, mape_test_huber, mape_test_ransac, mape_test_theilsen, mape_test_ridge, mape_test_lasso, mape_test_enet, mape_test_tree, mape_test_rf, mape_test_knn, mape_test_svr, mape_test_rn, mape_test_hgb, mape_test_xgb],\n",
    "})\n",
    "\n",
    "# Ordenar de forma ascendente por MAPE test\n",
    "modelos_mape.sort_values(by = 'MAPE test', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar tablas comparativas de metricas\n",
    "modelos_r2.to_csv(\"../16 - Exports Modelos/agregados/metrics_r2_agg.csv\", index = False)\n",
    "modelos_rsme.to_csv(\"../16 - Exports Modelos/agregados/metrics_rsme_agg.csv\", index = False)\n",
    "modelos_mae.to_csv(\"../16 - Exports Modelos/agregados/metrics_mae_agg.csv\", index = False)\n",
    "modelos_mape.to_csv(\"../16 - Exports Modelos/agregados/metrics_mape_agg.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo a nuestra exploración inicial de modelos, HGB es el que da mejor resultados, seguido de la red neuronal (RN) de una capa. \n",
    "\n",
    "Estudiemos ahora el efecto de normalizar los datos sobre el modelo RN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Transformar Datos para modelo de Redes Neuronales*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando que en etapas previas observamos las variables inputs no presentan una distribución normal y que uno de los modelos con mejores métricas, además del HGB, fue el de RN de una capa, agregaremos unos pasos de transformación para normalizar los datos (target y target/inputs) para analizar una posible mejoría de las métricas en es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para calcular R² ajustado\n",
    "def adjusted_r2(r2, n, p):\n",
    "    return 1 - (1 - r2) * ((n - 1) / (n - p - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalizar (ajustar a Gaussiana) sólo la variable target (\"Immigrant count\")**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 - train: 0.975\n",
      "Adjusted R2 - train: 0.975\n",
      "RMSE - train: 875.0\n",
      "MAE - train: 284.0\n",
      "MAPE - train: 0.14\n",
      "\n",
      "R2 - test: 0.965\n",
      "Adjusted R2 - train: 0.964\n",
      "RMSE - test: 1023.0\n",
      "MAE - test: 359.0\n",
      "MAPE - test: 0.17\n"
     ]
    }
   ],
   "source": [
    "# hacer copia del df removiendo Senegal que presenta datos nulos para tasa de homicidios\n",
    "df_nonull = df[df['Nationality code'] != 'SEN'].copy()\n",
    "\n",
    "# Transformar Year a variable ordinal de 1 (2008) a 15 (2022)\n",
    "df_nonull['Year'] = df_nonull['Year'] - 2007\n",
    "\n",
    "# Generar variables dummies a partir de nuestras variables categóricas \"object\" (no ordinales)\n",
    "df_nonull = pd.get_dummies(df_nonull)\n",
    "\n",
    "# Convertir las variables dummies booleanas en \"int\"\n",
    "col_bool = df_nonull.select_dtypes(include=['bool']).columns\n",
    "df_nonull[col_bool] = df_nonull[col_bool].astype(int)\n",
    "\n",
    "# Separar variables input y variable target \"Immigrant count\" de df_null (dataframe sin datos nulos)\n",
    "X = df_nonull.drop(\"Immigrant count\", axis=1)  # variables predictoras\n",
    "y = df_nonull[\"Immigrant count\"]  # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=58)  # separar datos en conjunto train y test en un 75% / 25%\n",
    "scaler_nonull = MinMaxScaler()  # definir scaler de datos\n",
    "X_train = scaler_nonull.fit_transform(X_train)  # escalar los datos de entrenamiento\n",
    "X_test = scaler_nonull.transform(X_test)  # transformar los datos de prueba\n",
    "\n",
    "# Aplicar PowerTransformer a variable target\n",
    "pt = PowerTransformer(method='box-cox')\n",
    "y_train_trans = pt.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_trans = pt.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Definir modelo con los mejores valores de parámetros (Nota: usar los mejores, pero hacer modificaciones para comparar metricas)\n",
    "rn_best_trans1 = MLPRegressor(activation='relu',\n",
    "                              alpha=0.01, \n",
    "                              batch_size=50, \n",
    "                              early_stopping=True, \n",
    "                              hidden_layer_sizes=(60), \n",
    "                              max_iter=200, \n",
    "                              solver='lbfgs')\n",
    "\n",
    "# Entrenar con el conjunto de entrenamiento \n",
    "rn_best_trans1.fit(X_train, y_train_trans)\n",
    "\n",
    "# Aplicar modelo sobre los datos de train y test para predecir el target \n",
    "y_train_pred_trans = rn_best_trans1.predict(X_train) \n",
    "y_test_pred_trans = rn_best_trans1.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "y_train_pred = pt.inverse_transform(y_train_pred_trans.reshape(-1, 1)).flatten()\n",
    "y_test_pred = pt.inverse_transform(y_test_pred_trans.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculo de metricas en train \n",
    "r2_train_rn_trans1 = np.round(r2_score(y_train, y_train_pred), 3) \n",
    "rmse_train_rn_trans1 = np.round(np.sqrt(mean_squared_error(y_train, y_train_pred)), 0) \n",
    "mae_train_rn_trans1 = np.round(mean_absolute_error(y_train, y_train_pred), 0) \n",
    "mape_train_rn_trans1 = np.round(mean_absolute_percentage_error(y_train, y_train_pred), 2)\n",
    "\n",
    "# Calculo de metricas en test\n",
    "r2_test_rn_trans1 = np.round(r2_score(y_test, y_test_pred), 3) \n",
    "rmse_test_rn_trans1 = np.round(np.sqrt(mean_squared_error(y_test, y_test_pred)), 0) \n",
    "mae_test_rn_trans1 = np.round(mean_absolute_error(y_test, y_test_pred), 0) \n",
    "mape_test_rn_trans1 = np.round(mean_absolute_percentage_error(y_test, y_test_pred), 2)\n",
    "\n",
    "# Calcular R² Ajustado\n",
    "adj_r2_train_rn_trans1 = adjusted_r2(r2_train_rn_trans1, len(y_train), X_train.shape[1])\n",
    "adj_r2_test_rn_trans1 = adjusted_r2(r2_test_rn_trans1, len(y_test), X_test.shape[1])\n",
    "\n",
    "# Mostrar métricas\n",
    "print(\"R2 - train:\", r2_train_rn_trans1)\n",
    "print(\"Adjusted R2 - train:\", np.round(adj_r2_train_rn_trans1, 3))\n",
    "print(\"RMSE - train:\", rmse_train_rn_trans1)\n",
    "print(\"MAE - train:\", mae_train_rn_trans1)\n",
    "print(\"MAPE - train:\", mape_train_rn_trans1)\n",
    "print('')\n",
    "print(\"R2 - test:\", r2_test_rn_trans1)\n",
    "print(\"Adjusted R2 - train:\", np.round(adj_r2_test_rn_trans1, 3))\n",
    "print(\"RMSE - test:\", rmse_test_rn_trans1)\n",
    "print(\"MAE - test:\", mae_test_rn_trans1)\n",
    "print(\"MAPE - test:\", mape_test_rn_trans1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalizar (ajustar a Gaussiana) variables inputs y variable target (sin scaler)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 - train: 0.988\n",
      "Adjusted R2 - train: 0.988\n",
      "RMSE - train: 613.0\n",
      "MAE - train: 211.0\n",
      "MAPE - train: 0.11\n",
      "\n",
      "R2 - test: 0.976\n",
      "Adjusted R2 - test: 0.975\n",
      "RMSE - test: 853.0\n",
      "MAE - test: 293.0\n",
      "MAPE - test: 0.14\n"
     ]
    }
   ],
   "source": [
    "# hacer copia del df removiendo Senegal que presenta datos nulos para tasa de homicidios\n",
    "df_nonull = df[df['Nationality code'] != 'SEN'].copy()\n",
    "\n",
    "# Transformar Year a variable ordinal de 1 (2008) a 15 (2022)\n",
    "df_nonull['Year'] = df_nonull['Year'] - 2007\n",
    "\n",
    "# Generar variables dummies a partir de nuestras variables categóricas \"object\" (no ordinales)\n",
    "df_nonull = pd.get_dummies(df_nonull)\n",
    "\n",
    "# Convertir las variables dummies booleanas en \"int\"\n",
    "col_bool = df_nonull.select_dtypes(include=['bool']).columns\n",
    "df_nonull[col_bool] = df_nonull[col_bool].astype(int)\n",
    "\n",
    "# Separar variables input y variable target \"Immigrant count\" de df_null (dataframe sin datos nulos)\n",
    "X = df_nonull.drop(\"Immigrant count\", axis=1)  # variables predictoras\n",
    "y = df_nonull[\"Immigrant count\"]  # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=58)  # separar datos en conjunto train y test en un 75% / 25%\n",
    "\n",
    "# Aplicar PowerTransformer a variables input\n",
    "pt_X = PowerTransformer(method='yeo-johnson')\n",
    "X_train_trans = pt_X.fit_transform(X_train)\n",
    "X_test_trans = pt_X.transform(X_test)\n",
    "\n",
    "# Aplicar PowerTransformer a variable target\n",
    "pt_y = PowerTransformer(method='box-cox')\n",
    "y_train_trans = pt_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_trans = pt_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Definir modelo con los mejores valores de parámetros\n",
    "rn_best_trans2 = MLPRegressor(activation='relu',\n",
    "                              alpha=0.01, \n",
    "                              batch_size=50, \n",
    "                              early_stopping=True, \n",
    "                              hidden_layer_sizes=(60), \n",
    "                              max_iter=200, \n",
    "                              solver='lbfgs')\n",
    "\n",
    "# # Entrenar con el conjunto de entrenamiento \n",
    "rn_best_trans2.fit(X_train_trans, y_train_trans)\n",
    "\n",
    "# Aplicar modelo sobre los datos de train y test para predecir el target \n",
    "y_train_pred_trans = rn_best_trans2.predict(X_train_trans) \n",
    "y_test_pred_trans = rn_best_trans2.predict(X_test_trans)\n",
    "\n",
    "# Transformacion inversa de predicciones\n",
    "y_train_pred = pt_y.inverse_transform(y_train_pred_trans.reshape(-1, 1)).flatten()\n",
    "y_test_pred = pt_y.inverse_transform(y_test_pred_trans.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculo de metricas en train \n",
    "r2_train_rn_trans2 = np.round(r2_score(y_train, y_train_pred), 3) \n",
    "rmse_train_rn_trans2 = np.round(np.sqrt(mean_squared_error(y_train, y_train_pred)), 0) \n",
    "mae_train_rn_trans2 = np.round(mean_absolute_error(y_train, y_train_pred), 0) \n",
    "mape_train_rn_trans2 = np.round(mean_absolute_percentage_error(y_train, y_train_pred), 2)\n",
    "\n",
    "# Calculo de metricas en test\n",
    "r2_test_rn_trans2 = np.round(r2_score(y_test, y_test_pred), 3) \n",
    "rmse_test_rn_trans2 = np.round(np.sqrt(mean_squared_error(y_test, y_test_pred)), 0) \n",
    "mae_test_rn_trans2 = np.round(mean_absolute_error(y_test, y_test_pred), 0) \n",
    "mape_test_rn_trans2 = np.round(mean_absolute_percentage_error(y_test, y_test_pred), 2)\n",
    "\n",
    "# Calcular Adjusted R²\n",
    "adj_r2_train_rn_trans2 = adjusted_r2(r2_train_rn, len(y_train), X_train.shape[1])\n",
    "adj_r2_test_rn_trans2 = adjusted_r2(r2_test_rn, len(y_test), X_test.shape[1])\n",
    "\n",
    "# Mostrar métricas\n",
    "print(\"R2 - train:\", r2_train_rn_trans2)\n",
    "print(\"Adjusted R2 - train:\", np.round(adj_r2_train_rn_trans2, 3))\n",
    "print(\"RMSE - train:\", rmse_train_rn_trans2)\n",
    "print(\"MAE - train:\", mae_train_rn_trans2)\n",
    "print(\"MAPE - train:\", mape_train_rn_trans2)\n",
    "print('')\n",
    "print(\"R2 - test:\", r2_test_rn_trans2)\n",
    "print(\"Adjusted R2 - test:\", np.round(adj_r2_test_rn_trans2, 3))\n",
    "print(\"RMSE - test:\", rmse_test_rn_trans2)\n",
    "print(\"MAE - test:\", mae_test_rn_trans2)\n",
    "print(\"MAPE - test:\", mape_test_rn_trans2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Métricas</th>\n",
       "      <th>RN + target normalizado</th>\n",
       "      <th>RN + inputs/target normalizado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R² test</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R² adjusted test</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RMSE test</td>\n",
       "      <td>1023.000</td>\n",
       "      <td>853.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAE test</td>\n",
       "      <td>359.000</td>\n",
       "      <td>293.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAPE test</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Métricas  RN + target normalizado  RN + inputs/target normalizado\n",
       "0           R² test                    0.965                           0.976\n",
       "1  R² adjusted test                    0.964                           0.975\n",
       "2         RMSE test                 1023.000                         853.000\n",
       "3          MAE test                  359.000                         293.000\n",
       "4         MAPE test                    0.170                           0.140"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Juntar metricas en un dataframe los datos\n",
    "modelos_rn_trans = pd.DataFrame({\n",
    "    'Métricas' : ['R² test', 'R² adjusted test', 'RMSE test', 'MAE test', 'MAPE test'],\n",
    "    'RN + target normalizado' : [r2_test_rn_trans1, np.round(adj_r2_test_rn_trans1, 3), rmse_test_rn_trans1, mae_test_rn_trans1, mape_test_rn_trans1],\n",
    "    'RN + inputs/target normalizado' : [r2_test_rn_trans2, np.round(adj_r2_test_rn_trans2, 3), rmse_test_rn_trans2, mae_test_rn_trans2, mape_test_rn_trans2],\n",
    "})\n",
    "\n",
    "modelos_rn_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar tablas comparativas de metricas\n",
    "modelos_rn_trans.to_csv(\"../16 - Exports Modelos/agregados/rn_trans_metrics.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la normalización de inputs y target mejoró considerablemente los resultados del modelo de red neuronal de una capa, siendo ahora el modelo con mejor rendiemiento de todos los evaluados hasta el momento. \n",
    "\n",
    "Seleccinaremos este modelo como el mejor para el conjunto de datos con agregados y pasaremos a realizar prediciones a futuro para compararlas luego con el modelo sin agregados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../16 - Exports Modelos/agregados/power_transformer_y.pkl']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar mejor modelo\n",
    "with open('../16 - Exports Modelos/agregados/rn_trans_agg.pkl', 'wb') as file:\n",
    "    pickle.dump(rn_best_trans2, file)\n",
    "\n",
    "# Guardar PowerTransformer de inputs\n",
    "joblib.dump(pt_X, '../16 - Exports Modelos/agregados/power_transformer_X.pkl')\n",
    "\n",
    "# Guardar PowerTransformerpara target\n",
    "joblib.dump(pt_y, '../16 - Exports Modelos/agregados/power_transformer_y.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Predicciones con el mejor modelo seleccionado*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora obtengamos las predicicones para todo el conjunto de datos incluyendo dos años adicionales (2023 y 2024) para dos nacionalidades con imigracion alta y media: Colombia y Brasil. Nuetsro onjetivo es comparar los resultados de este modelo con agregadas \"Both\" y \"All\" de sexo y grupo de edad, frente al mejor modelo obtenido sin estos agregados.\n",
    "\n",
    "*Nota: Los datos de los años 2023 y 2024 fueron preparados investigando los valores de variables inputs o planteando escenarios con base a la tendencia de los valores en años previos.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importar los datos acomodados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9456 entries, 0 to 9455\n",
      "Data columns (total 28 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   Year                               9456 non-null   int64  \n",
      " 1   Nationality code                   9456 non-null   object \n",
      " 2   Sex                                9456 non-null   object \n",
      " 3   Age group                          9456 non-null   object \n",
      " 4   Immigrant count                    9360 non-null   float64\n",
      " 5   Unemployment %                     9456 non-null   float64\n",
      " 6   Political and Violence Percentile  9456 non-null   float64\n",
      " 7   Probability of dying young         9456 non-null   float64\n",
      " 8   Rule of Law Percentile             9456 non-null   float64\n",
      " 9   Salaried workers %                 9456 non-null   float64\n",
      " 10  GDP_growth                         9456 non-null   float64\n",
      " 11  Inflation_annual                   9456 non-null   float64\n",
      " 12  Liberal democracy index            9456 non-null   float64\n",
      " 13  Continent                          9456 non-null   object \n",
      " 14  Sub-region                         9456 non-null   object \n",
      " 15  Health equality                    9456 non-null   float64\n",
      " 16  Judicial accountability            9456 non-null   float64\n",
      " 17  One-sided violence_deaths          9456 non-null   int64  \n",
      " 18  Non-state_deaths                   9456 non-null   int64  \n",
      " 19  Intrastate_deaths                  9456 non-null   int64  \n",
      " 20  Interstate_deaths                  9456 non-null   int64  \n",
      " 21  Number of residents                9456 non-null   int64  \n",
      " 22  Political regime                   9456 non-null   int64  \n",
      " 23  Homicide Rate                      9120 non-null   float64\n",
      " 24  Number of Turist                   9456 non-null   int64  \n",
      " 25  Spanish language                   9456 non-null   int64  \n",
      " 26  Restricciones_pandemia             9456 non-null   int64  \n",
      " 27  Año post_pandemia                  9456 non-null   int64  \n",
      "dtypes: float64(12), int64(11), object(5)\n",
      "memory usage: 2.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Nationality code</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age group</th>\n",
       "      <th>Immigrant count</th>\n",
       "      <th>Unemployment %</th>\n",
       "      <th>Political and Violence Percentile</th>\n",
       "      <th>Probability of dying young</th>\n",
       "      <th>Rule of Law Percentile</th>\n",
       "      <th>Salaried workers %</th>\n",
       "      <th>...</th>\n",
       "      <th>Non-state_deaths</th>\n",
       "      <th>Intrastate_deaths</th>\n",
       "      <th>Interstate_deaths</th>\n",
       "      <th>Number of residents</th>\n",
       "      <th>Political regime</th>\n",
       "      <th>Homicide Rate</th>\n",
       "      <th>Number of Turist</th>\n",
       "      <th>Spanish language</th>\n",
       "      <th>Restricciones_pandemia</th>\n",
       "      <th>Año post_pandemia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>DZA</td>\n",
       "      <td>Both</td>\n",
       "      <td>0 - 14</td>\n",
       "      <td>759.0</td>\n",
       "      <td>11.33</td>\n",
       "      <td>14.90</td>\n",
       "      <td>3.7</td>\n",
       "      <td>24.52</td>\n",
       "      <td>67.41</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>345</td>\n",
       "      <td>0</td>\n",
       "      <td>51922</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>44400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>PER</td>\n",
       "      <td>Males</td>\n",
       "      <td>35 - 44</td>\n",
       "      <td>2938.0</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>60185</td>\n",
       "      <td>7</td>\n",
       "      <td>5.27</td>\n",
       "      <td>44400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>PER</td>\n",
       "      <td>Males</td>\n",
       "      <td>45 - 54</td>\n",
       "      <td>1128.0</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>60185</td>\n",
       "      <td>7</td>\n",
       "      <td>5.27</td>\n",
       "      <td>44400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>PER</td>\n",
       "      <td>Males</td>\n",
       "      <td>55 - 64</td>\n",
       "      <td>265.0</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>60185</td>\n",
       "      <td>7</td>\n",
       "      <td>5.27</td>\n",
       "      <td>44400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>PER</td>\n",
       "      <td>Males</td>\n",
       "      <td>65+</td>\n",
       "      <td>156.0</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>60185</td>\n",
       "      <td>7</td>\n",
       "      <td>5.27</td>\n",
       "      <td>44400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9451</th>\n",
       "      <td>2024</td>\n",
       "      <td>BRA</td>\n",
       "      <td>Males</td>\n",
       "      <td>35 - 44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.00</td>\n",
       "      <td>34.00</td>\n",
       "      <td>7.7</td>\n",
       "      <td>45.40</td>\n",
       "      <td>68.04</td>\n",
       "      <td>...</td>\n",
       "      <td>2100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92400</td>\n",
       "      <td>6</td>\n",
       "      <td>21.40</td>\n",
       "      <td>70500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9452</th>\n",
       "      <td>2024</td>\n",
       "      <td>BRA</td>\n",
       "      <td>Males</td>\n",
       "      <td>45 - 54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.00</td>\n",
       "      <td>34.00</td>\n",
       "      <td>7.7</td>\n",
       "      <td>45.40</td>\n",
       "      <td>68.04</td>\n",
       "      <td>...</td>\n",
       "      <td>2100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92400</td>\n",
       "      <td>6</td>\n",
       "      <td>21.40</td>\n",
       "      <td>70500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9453</th>\n",
       "      <td>2024</td>\n",
       "      <td>BRA</td>\n",
       "      <td>Males</td>\n",
       "      <td>55 - 64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.00</td>\n",
       "      <td>34.00</td>\n",
       "      <td>7.7</td>\n",
       "      <td>45.40</td>\n",
       "      <td>68.04</td>\n",
       "      <td>...</td>\n",
       "      <td>2100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92400</td>\n",
       "      <td>6</td>\n",
       "      <td>21.40</td>\n",
       "      <td>70500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9454</th>\n",
       "      <td>2024</td>\n",
       "      <td>BRA</td>\n",
       "      <td>Males</td>\n",
       "      <td>65+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.00</td>\n",
       "      <td>34.00</td>\n",
       "      <td>7.7</td>\n",
       "      <td>45.40</td>\n",
       "      <td>68.04</td>\n",
       "      <td>...</td>\n",
       "      <td>2100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92400</td>\n",
       "      <td>6</td>\n",
       "      <td>21.40</td>\n",
       "      <td>70500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9455</th>\n",
       "      <td>2024</td>\n",
       "      <td>BRA</td>\n",
       "      <td>Males</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.00</td>\n",
       "      <td>34.00</td>\n",
       "      <td>7.7</td>\n",
       "      <td>45.40</td>\n",
       "      <td>68.04</td>\n",
       "      <td>...</td>\n",
       "      <td>2100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92400</td>\n",
       "      <td>6</td>\n",
       "      <td>21.40</td>\n",
       "      <td>70500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9456 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year Nationality code    Sex Age group  Immigrant count  Unemployment %  \\\n",
       "0     2008              DZA   Both    0 - 14            759.0           11.33   \n",
       "1     2008              PER  Males   35 - 44           2938.0            4.03   \n",
       "2     2008              PER  Males   45 - 54           1128.0            4.03   \n",
       "3     2008              PER  Males   55 - 64            265.0            4.03   \n",
       "4     2008              PER  Males       65+            156.0            4.03   \n",
       "...    ...              ...    ...       ...              ...             ...   \n",
       "9451  2024              BRA  Males   35 - 44              NaN            7.00   \n",
       "9452  2024              BRA  Males   45 - 54              NaN            7.00   \n",
       "9453  2024              BRA  Males   55 - 64              NaN            7.00   \n",
       "9454  2024              BRA  Males       65+              NaN            7.00   \n",
       "9455  2024              BRA  Males       All              NaN            7.00   \n",
       "\n",
       "      Political and Violence Percentile  Probability of dying young  \\\n",
       "0                                 14.90                         3.7   \n",
       "1                                 17.31                         5.1   \n",
       "2                                 17.31                         5.1   \n",
       "3                                 17.31                         5.1   \n",
       "4                                 17.31                         5.1   \n",
       "...                                 ...                         ...   \n",
       "9451                              34.00                         7.7   \n",
       "9452                              34.00                         7.7   \n",
       "9453                              34.00                         7.7   \n",
       "9454                              34.00                         7.7   \n",
       "9455                              34.00                         7.7   \n",
       "\n",
       "      Rule of Law Percentile  Salaried workers %  ...  Non-state_deaths  \\\n",
       "0                      24.52               67.41  ...                 0   \n",
       "1                      25.96               44.47  ...                 0   \n",
       "2                      25.96               44.47  ...                 0   \n",
       "3                      25.96               44.47  ...                 0   \n",
       "4                      25.96               44.47  ...                 0   \n",
       "...                      ...                 ...  ...               ...   \n",
       "9451                   45.40               68.04  ...              2100   \n",
       "9452                   45.40               68.04  ...              2100   \n",
       "9453                   45.40               68.04  ...              2100   \n",
       "9454                   45.40               68.04  ...              2100   \n",
       "9455                   45.40               68.04  ...              2100   \n",
       "\n",
       "      Intrastate_deaths  Interstate_deaths Number of residents  \\\n",
       "0                   345                  0               51922   \n",
       "1                    40                  0               60185   \n",
       "2                    40                  0               60185   \n",
       "3                    40                  0               60185   \n",
       "4                    40                  0               60185   \n",
       "...                 ...                ...                 ...   \n",
       "9451                  0                  0               92400   \n",
       "9452                  0                  0               92400   \n",
       "9453                  0                  0               92400   \n",
       "9454                  0                  0               92400   \n",
       "9455                  0                  0               92400   \n",
       "\n",
       "     Political regime  Homicide Rate  Number of Turist  Spanish language  \\\n",
       "0                   3           0.95          44400000                 0   \n",
       "1                   7           5.27          44400000                 1   \n",
       "2                   7           5.27          44400000                 1   \n",
       "3                   7           5.27          44400000                 1   \n",
       "4                   7           5.27          44400000                 1   \n",
       "...               ...            ...               ...               ...   \n",
       "9451                6          21.40          70500000                 0   \n",
       "9452                6          21.40          70500000                 0   \n",
       "9453                6          21.40          70500000                 0   \n",
       "9454                6          21.40          70500000                 0   \n",
       "9455                6          21.40          70500000                 0   \n",
       "\n",
       "      Restricciones_pandemia  Año post_pandemia  \n",
       "0                          0                  0  \n",
       "1                          0                  0  \n",
       "2                          0                  0  \n",
       "3                          0                  0  \n",
       "4                          0                  0  \n",
       "...                      ...                ...  \n",
       "9451                       0                  0  \n",
       "9452                       0                  0  \n",
       "9453                       0                  0  \n",
       "9454                       0                  0  \n",
       "9455                       0                  0  \n",
       "\n",
       "[9456 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar el dataset\n",
    "df_predicciones = pd.read_csv(\"../17 - Prediciones/datos a predecir.csv\")\n",
    "\n",
    "df_predicciones.info()\n",
    "df_predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9096 entries, 0 to 9455\n",
      "Data columns (total 70 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   Year                                      9096 non-null   int64  \n",
      " 1   Immigrant count                           9000 non-null   float64\n",
      " 2   Unemployment %                            9096 non-null   float64\n",
      " 3   Political and Violence Percentile         9096 non-null   float64\n",
      " 4   Probability of dying young                9096 non-null   float64\n",
      " 5   Rule of Law Percentile                    9096 non-null   float64\n",
      " 6   Salaried workers %                        9096 non-null   float64\n",
      " 7   GDP_growth                                9096 non-null   float64\n",
      " 8   Inflation_annual                          9096 non-null   float64\n",
      " 9   Liberal democracy index                   9096 non-null   float64\n",
      " 10  Health equality                           9096 non-null   float64\n",
      " 11  Judicial accountability                   9096 non-null   float64\n",
      " 12  One-sided violence_deaths                 9096 non-null   int64  \n",
      " 13  Non-state_deaths                          9096 non-null   int64  \n",
      " 14  Intrastate_deaths                         9096 non-null   int64  \n",
      " 15  Interstate_deaths                         9096 non-null   int64  \n",
      " 16  Number of residents                       9096 non-null   int64  \n",
      " 17  Political regime                          9096 non-null   int64  \n",
      " 18  Homicide Rate                             9096 non-null   float64\n",
      " 19  Number of Turist                          9096 non-null   int64  \n",
      " 20  Spanish language                          9096 non-null   int64  \n",
      " 21  Restricciones_pandemia                    9096 non-null   int64  \n",
      " 22  Año post_pandemia                         9096 non-null   int64  \n",
      " 23  Nationality code_ARG                      9096 non-null   int32  \n",
      " 24  Nationality code_BGR                      9096 non-null   int32  \n",
      " 25  Nationality code_BRA                      9096 non-null   int32  \n",
      " 26  Nationality code_CHN                      9096 non-null   int32  \n",
      " 27  Nationality code_COL                      9096 non-null   int32  \n",
      " 28  Nationality code_CUB                      9096 non-null   int32  \n",
      " 29  Nationality code_DEU                      9096 non-null   int32  \n",
      " 30  Nationality code_DOM                      9096 non-null   int32  \n",
      " 31  Nationality code_DZA                      9096 non-null   int32  \n",
      " 32  Nationality code_ECU                      9096 non-null   int32  \n",
      " 33  Nationality code_FRA                      9096 non-null   int32  \n",
      " 34  Nationality code_GBR                      9096 non-null   int32  \n",
      " 35  Nationality code_HND                      9096 non-null   int32  \n",
      " 36  Nationality code_ITA                      9096 non-null   int32  \n",
      " 37  Nationality code_MAR                      9096 non-null   int32  \n",
      " 38  Nationality code_NIC                      9096 non-null   int32  \n",
      " 39  Nationality code_PAK                      9096 non-null   int32  \n",
      " 40  Nationality code_PER                      9096 non-null   int32  \n",
      " 41  Nationality code_PRT                      9096 non-null   int32  \n",
      " 42  Nationality code_PRY                      9096 non-null   int32  \n",
      " 43  Nationality code_ROU                      9096 non-null   int32  \n",
      " 44  Nationality code_RUS                      9096 non-null   int32  \n",
      " 45  Nationality code_UKR                      9096 non-null   int32  \n",
      " 46  Nationality code_USA                      9096 non-null   int32  \n",
      " 47  Nationality code_VEN                      9096 non-null   int32  \n",
      " 48  Sex_Both                                  9096 non-null   int32  \n",
      " 49  Sex_Females                               9096 non-null   int32  \n",
      " 50  Sex_Males                                 9096 non-null   int32  \n",
      " 51  Age group_0 - 14                          9096 non-null   int32  \n",
      " 52  Age group_15 - 24                         9096 non-null   int32  \n",
      " 53  Age group_25 - 34                         9096 non-null   int32  \n",
      " 54  Age group_35 - 44                         9096 non-null   int32  \n",
      " 55  Age group_45 - 54                         9096 non-null   int32  \n",
      " 56  Age group_55 - 64                         9096 non-null   int32  \n",
      " 57  Age group_65+                             9096 non-null   int32  \n",
      " 58  Age group_All                             9096 non-null   int32  \n",
      " 59  Continent_Africa                          9096 non-null   int32  \n",
      " 60  Continent_America                         9096 non-null   int32  \n",
      " 61  Continent_Asia                            9096 non-null   int32  \n",
      " 62  Continent_Europe                          9096 non-null   int32  \n",
      " 63  Sub-region_Africa                         9096 non-null   int32  \n",
      " 64  Sub-region_Asia                           9096 non-null   int32  \n",
      " 65  Sub-region_Central America and Caribbean  9096 non-null   int32  \n",
      " 66  Sub-region_European Union                 9096 non-null   int32  \n",
      " 67  Sub-region_North America                  9096 non-null   int32  \n",
      " 68  Sub-region_Rest of Europe                 9096 non-null   int32  \n",
      " 69  Sub-region_South America                  9096 non-null   int32  \n",
      "dtypes: float64(12), int32(47), int64(11)\n",
      "memory usage: 3.3 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Immigrant count</th>\n",
       "      <th>Unemployment %</th>\n",
       "      <th>Political and Violence Percentile</th>\n",
       "      <th>Probability of dying young</th>\n",
       "      <th>Rule of Law Percentile</th>\n",
       "      <th>Salaried workers %</th>\n",
       "      <th>GDP_growth</th>\n",
       "      <th>Inflation_annual</th>\n",
       "      <th>Liberal democracy index</th>\n",
       "      <th>...</th>\n",
       "      <th>Continent_America</th>\n",
       "      <th>Continent_Asia</th>\n",
       "      <th>Continent_Europe</th>\n",
       "      <th>Sub-region_Africa</th>\n",
       "      <th>Sub-region_Asia</th>\n",
       "      <th>Sub-region_Central America and Caribbean</th>\n",
       "      <th>Sub-region_European Union</th>\n",
       "      <th>Sub-region_North America</th>\n",
       "      <th>Sub-region_Rest of Europe</th>\n",
       "      <th>Sub-region_South America</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>759.0</td>\n",
       "      <td>11.33</td>\n",
       "      <td>14.90</td>\n",
       "      <td>3.7</td>\n",
       "      <td>24.52</td>\n",
       "      <td>67.41</td>\n",
       "      <td>2.40</td>\n",
       "      <td>15.31</td>\n",
       "      <td>0.164</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2938.0</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.649</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1128.0</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.649</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>265.0</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.649</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>156.0</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.649</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9451</th>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.00</td>\n",
       "      <td>34.00</td>\n",
       "      <td>7.7</td>\n",
       "      <td>45.40</td>\n",
       "      <td>68.04</td>\n",
       "      <td>2.01</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.670</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9452</th>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.00</td>\n",
       "      <td>34.00</td>\n",
       "      <td>7.7</td>\n",
       "      <td>45.40</td>\n",
       "      <td>68.04</td>\n",
       "      <td>2.01</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.670</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9453</th>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.00</td>\n",
       "      <td>34.00</td>\n",
       "      <td>7.7</td>\n",
       "      <td>45.40</td>\n",
       "      <td>68.04</td>\n",
       "      <td>2.01</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.670</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9454</th>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.00</td>\n",
       "      <td>34.00</td>\n",
       "      <td>7.7</td>\n",
       "      <td>45.40</td>\n",
       "      <td>68.04</td>\n",
       "      <td>2.01</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.670</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9455</th>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.00</td>\n",
       "      <td>34.00</td>\n",
       "      <td>7.7</td>\n",
       "      <td>45.40</td>\n",
       "      <td>68.04</td>\n",
       "      <td>2.01</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.670</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9096 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  Immigrant count  Unemployment %  \\\n",
       "0        1            759.0           11.33   \n",
       "1        1           2938.0            4.03   \n",
       "2        1           1128.0            4.03   \n",
       "3        1            265.0            4.03   \n",
       "4        1            156.0            4.03   \n",
       "...    ...              ...             ...   \n",
       "9451    17              NaN            7.00   \n",
       "9452    17              NaN            7.00   \n",
       "9453    17              NaN            7.00   \n",
       "9454    17              NaN            7.00   \n",
       "9455    17              NaN            7.00   \n",
       "\n",
       "      Political and Violence Percentile  Probability of dying young  \\\n",
       "0                                 14.90                         3.7   \n",
       "1                                 17.31                         5.1   \n",
       "2                                 17.31                         5.1   \n",
       "3                                 17.31                         5.1   \n",
       "4                                 17.31                         5.1   \n",
       "...                                 ...                         ...   \n",
       "9451                              34.00                         7.7   \n",
       "9452                              34.00                         7.7   \n",
       "9453                              34.00                         7.7   \n",
       "9454                              34.00                         7.7   \n",
       "9455                              34.00                         7.7   \n",
       "\n",
       "      Rule of Law Percentile  Salaried workers %  GDP_growth  \\\n",
       "0                      24.52               67.41        2.40   \n",
       "1                      25.96               44.47        9.13   \n",
       "2                      25.96               44.47        9.13   \n",
       "3                      25.96               44.47        9.13   \n",
       "4                      25.96               44.47        9.13   \n",
       "...                      ...                 ...         ...   \n",
       "9451                   45.40               68.04        2.01   \n",
       "9452                   45.40               68.04        2.01   \n",
       "9453                   45.40               68.04        2.01   \n",
       "9454                   45.40               68.04        2.01   \n",
       "9455                   45.40               68.04        2.01   \n",
       "\n",
       "      Inflation_annual  Liberal democracy index  ...  Continent_America  \\\n",
       "0                15.31                    0.164  ...                  0   \n",
       "1                 1.10                    0.649  ...                  1   \n",
       "2                 1.10                    0.649  ...                  1   \n",
       "3                 1.10                    0.649  ...                  1   \n",
       "4                 1.10                    0.649  ...                  1   \n",
       "...                ...                      ...  ...                ...   \n",
       "9451              4.00                    0.670  ...                  1   \n",
       "9452              4.00                    0.670  ...                  1   \n",
       "9453              4.00                    0.670  ...                  1   \n",
       "9454              4.00                    0.670  ...                  1   \n",
       "9455              4.00                    0.670  ...                  1   \n",
       "\n",
       "      Continent_Asia  Continent_Europe  Sub-region_Africa  Sub-region_Asia  \\\n",
       "0                  0                 0                  1                0   \n",
       "1                  0                 0                  0                0   \n",
       "2                  0                 0                  0                0   \n",
       "3                  0                 0                  0                0   \n",
       "4                  0                 0                  0                0   \n",
       "...              ...               ...                ...              ...   \n",
       "9451               0                 0                  0                0   \n",
       "9452               0                 0                  0                0   \n",
       "9453               0                 0                  0                0   \n",
       "9454               0                 0                  0                0   \n",
       "9455               0                 0                  0                0   \n",
       "\n",
       "      Sub-region_Central America and Caribbean  Sub-region_European Union  \\\n",
       "0                                            0                          0   \n",
       "1                                            0                          0   \n",
       "2                                            0                          0   \n",
       "3                                            0                          0   \n",
       "4                                            0                          0   \n",
       "...                                        ...                        ...   \n",
       "9451                                         0                          0   \n",
       "9452                                         0                          0   \n",
       "9453                                         0                          0   \n",
       "9454                                         0                          0   \n",
       "9455                                         0                          0   \n",
       "\n",
       "      Sub-region_North America  Sub-region_Rest of Europe  \\\n",
       "0                            0                          0   \n",
       "1                            0                          0   \n",
       "2                            0                          0   \n",
       "3                            0                          0   \n",
       "4                            0                          0   \n",
       "...                        ...                        ...   \n",
       "9451                         0                          0   \n",
       "9452                         0                          0   \n",
       "9453                         0                          0   \n",
       "9454                         0                          0   \n",
       "9455                         0                          0   \n",
       "\n",
       "      Sub-region_South America  \n",
       "0                            0  \n",
       "1                            1  \n",
       "2                            1  \n",
       "3                            1  \n",
       "4                            1  \n",
       "...                        ...  \n",
       "9451                         1  \n",
       "9452                         1  \n",
       "9453                         1  \n",
       "9454                         1  \n",
       "9455                         1  \n",
       "\n",
       "[9096 rows x 70 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hacer copia del df removiendo Senegal que presenta datos nulos para tasa de homicidios\n",
    "df_nonull = df_predicciones[df_predicciones['Nationality code'] != 'SEN']\n",
    "df_nonull_copy = df_nonull.copy()\n",
    "\n",
    "# Transformar Year a variable ordinal de 1 (2008) a 15 (2022)\n",
    "df_nonull_copy['Year'] = df_nonull_copy['Year'] - 2007\n",
    "\n",
    "# Generar variables dummies a partir de nuestras variables categóricas \"object\" (no ordinales)\n",
    "df_nonull_copy = pd.get_dummies(df_nonull_copy)\n",
    "\n",
    "# Convertir las variables dummies booleanas en \"int\"\n",
    "col_bool = df_nonull_copy.select_dtypes(include = ['bool']).columns\n",
    "df_nonull_copy[col_bool] = df_nonull_copy[col_bool].astype(int)\n",
    "\n",
    "# Verificar cambio\n",
    "df_nonull_copy.info()\n",
    "df_nonull_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar variables input y variable target \"Immigrant count\" de df_null (dataframe sin atos nulos)\n",
    "X = df_nonull_copy.drop(\"Immigrant count\", axis = 1) # variables predictoras\n",
    "y = df_nonull_copy[\"Immigrant count\"]  # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cagar PowerTransformers y modelo\n",
    "pt_X = joblib.load('../16 - Exports Modelos/agregados/power_transformer_X.pkl')\n",
    "pt_y = joblib.load('../16 - Exports Modelos/agregados/power_transformer_y.pkl')\n",
    "modelo_final = joblib.load('../16 - Exports Modelos/agregados/rn_trans_agg.pkl')\n",
    "\n",
    "# Transformar variables inputs\n",
    "X_trans = pt_X.transform(X)\n",
    "\n",
    "# Predecir\n",
    "y_pred_trans = modelo_final.predict(X_trans)\n",
    "\n",
    "# Transformación inversa de prediccicones para obtener escala normal\n",
    "y_pred = pt_y.inverse_transform(y_pred_trans.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intervalos de confianza**\n",
    "\n",
    "Adicionalmente, estimemos un intervalo de confianza del 90% para nuestras predicciones en base a nuestro modelo elegido. Para ello usaremos el método de Conformal Prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "# Hacer copia del df removiendo Senegal que presenta datos nulos para tasa de homicidios\n",
    "df_nonull = df_predicciones[df_predicciones['Nationality code'] != 'SEN']\n",
    "df_nonull_copy = df_nonull.copy()\n",
    "\n",
    "# Remover años 2023 y 2024 de target e inputs que poseen datos nulos (se incluyen para prediciones futuras)\n",
    "df_nonull_copy = df_nonull_copy[(df_nonull_copy['Year'] != 2023) & (df_nonull_copy['Year'] != 2024)]\n",
    "\n",
    "# Transformar Year a variable ordinal de 1 (2008) a 15 (2022)\n",
    "df_nonull_copy['Year'] = df_nonull_copy['Year'] - 2007\n",
    "\n",
    "# Generar variables dummies a partir de nuestras variables categóricas \"object\" (no ordinales)\n",
    "df_nonull_copy = pd.get_dummies(df_nonull_copy)\n",
    "\n",
    "# Convertir las variables dummies booleanas en \"int\"\n",
    "col_bool = df_nonull_copy.select_dtypes(include = ['bool']).columns\n",
    "df_nonull_copy[col_bool] = df_nonull_copy[col_bool].astype(int)\n",
    "\n",
    "# Separar target de inputs\n",
    "X = df_nonull_copy.drop(\"Immigrant count\", axis = 1) # variables predictoras\n",
    "y = df_nonull_copy[\"Immigrant count\"]  # Target\n",
    "\n",
    "# Separar entrenamiento y prueba para el bootstrap\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=58)  # separar datos en conjunto train y test en un 75% / 25%\n",
    "\n",
    "# Aplicar PowerTransformer a variables input y target de entrenamiento\n",
    "X_train_trans = pt_X.fit_transform(X_train)\n",
    "y_train_trans = pt_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Definir modelo con los mejores valores de parámetros (Nota: usar los mejores, pero hacer modificaciones para comparar metricas)\n",
    "rn_trans = MLPRegressor(activation='relu',\n",
    "                              alpha=0.01, \n",
    "                              batch_size=50, \n",
    "                              early_stopping=True, \n",
    "                              hidden_layer_sizes=(60), \n",
    "                              max_iter=200, \n",
    "                              solver='lbfgs')\n",
    "\n",
    "\n",
    "# MapieRegressor\n",
    "mapie = MapieRegressor(rn_trans, method=\"naive\")\n",
    "\n",
    "# Fit MapieRegressor en datos de entrenamiento\n",
    "mapie.fit(X_train_trans, y_train_trans)\n",
    "\n",
    "# Predecir intervalos en datos\n",
    "predictions = mapie.predict(X_trans, alpha=0.1)  # 90% intervalo de confianza\n",
    "\n",
    "# Obtener la tupla correspondiente a los intervalos\n",
    "y_test_pred_interval = predictions[1]\n",
    "\n",
    "# Extraer valores de intervalos\n",
    "y_pred_interval_lower_t = y_test_pred_interval[:, 0]\n",
    "y_pred_interval_upper_t = y_test_pred_interval[:, 1]\n",
    "\n",
    "# Transform inverse predictions and intervals\n",
    "y_pred_lower = pt_y.inverse_transform(y_pred_interval_lower_t.reshape(-1, 1)).flatten()\n",
    "y_pred_upper = pt_y.inverse_transform(y_pred_interval_upper_t.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Agregar predicicones e intervalos de conf. al dataframe y exportar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9096 entries, 0 to 9455\n",
      "Data columns (total 8 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   Year                 9096 non-null   int64 \n",
      " 1   Nationality code     9096 non-null   object\n",
      " 2   Sex                  9096 non-null   object\n",
      " 3   Age group            9096 non-null   object\n",
      " 4   Immigrant count      9000 non-null   Int64 \n",
      " 5   Predictions_rnn_agg  9096 non-null   int32 \n",
      " 6   Lower limit_agg      9096 non-null   int32 \n",
      " 7   Upper limit_agg      9096 non-null   int32 \n",
      "dtypes: Int64(1), int32(3), int64(1), object(3)\n",
      "memory usage: 541.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Nationality code</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age group</th>\n",
       "      <th>Immigrant count</th>\n",
       "      <th>Predictions_rnn_agg</th>\n",
       "      <th>Lower limit_agg</th>\n",
       "      <th>Upper limit_agg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>DZA</td>\n",
       "      <td>Both</td>\n",
       "      <td>0 - 14</td>\n",
       "      <td>759</td>\n",
       "      <td>761</td>\n",
       "      <td>709</td>\n",
       "      <td>1111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>PER</td>\n",
       "      <td>Males</td>\n",
       "      <td>35 - 44</td>\n",
       "      <td>2938</td>\n",
       "      <td>1693</td>\n",
       "      <td>1572</td>\n",
       "      <td>2422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>PER</td>\n",
       "      <td>Males</td>\n",
       "      <td>45 - 54</td>\n",
       "      <td>1128</td>\n",
       "      <td>769</td>\n",
       "      <td>576</td>\n",
       "      <td>907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>PER</td>\n",
       "      <td>Males</td>\n",
       "      <td>55 - 64</td>\n",
       "      <td>265</td>\n",
       "      <td>206</td>\n",
       "      <td>174</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>PER</td>\n",
       "      <td>Males</td>\n",
       "      <td>65+</td>\n",
       "      <td>156</td>\n",
       "      <td>164</td>\n",
       "      <td>138</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9451</th>\n",
       "      <td>2024</td>\n",
       "      <td>BRA</td>\n",
       "      <td>Males</td>\n",
       "      <td>35 - 44</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2391</td>\n",
       "      <td>1457</td>\n",
       "      <td>2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9452</th>\n",
       "      <td>2024</td>\n",
       "      <td>BRA</td>\n",
       "      <td>Males</td>\n",
       "      <td>45 - 54</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1496</td>\n",
       "      <td>724</td>\n",
       "      <td>1134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9453</th>\n",
       "      <td>2024</td>\n",
       "      <td>BRA</td>\n",
       "      <td>Males</td>\n",
       "      <td>55 - 64</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>720</td>\n",
       "      <td>357</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9454</th>\n",
       "      <td>2024</td>\n",
       "      <td>BRA</td>\n",
       "      <td>Males</td>\n",
       "      <td>65+</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>311</td>\n",
       "      <td>331</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9455</th>\n",
       "      <td>2024</td>\n",
       "      <td>BRA</td>\n",
       "      <td>Males</td>\n",
       "      <td>All</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>11861</td>\n",
       "      <td>7788</td>\n",
       "      <td>11626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9096 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year Nationality code    Sex Age group  Immigrant count  \\\n",
       "0     2008              DZA   Both    0 - 14              759   \n",
       "1     2008              PER  Males   35 - 44             2938   \n",
       "2     2008              PER  Males   45 - 54             1128   \n",
       "3     2008              PER  Males   55 - 64              265   \n",
       "4     2008              PER  Males       65+              156   \n",
       "...    ...              ...    ...       ...              ...   \n",
       "9451  2024              BRA  Males   35 - 44             <NA>   \n",
       "9452  2024              BRA  Males   45 - 54             <NA>   \n",
       "9453  2024              BRA  Males   55 - 64             <NA>   \n",
       "9454  2024              BRA  Males       65+             <NA>   \n",
       "9455  2024              BRA  Males       All             <NA>   \n",
       "\n",
       "      Predictions_rnn_agg  Lower limit_agg  Upper limit_agg  \n",
       "0                     761              709             1111  \n",
       "1                    1693             1572             2422  \n",
       "2                     769              576              907  \n",
       "3                     206              174              281  \n",
       "4                     164              138              224  \n",
       "...                   ...              ...              ...  \n",
       "9451                 2391             1457             2250  \n",
       "9452                 1496              724             1134  \n",
       "9453                  720              357              568  \n",
       "9454                  311              331              528  \n",
       "9455                11861             7788            11626  \n",
       "\n",
       "[9096 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hacer copia de dataframe inicial sin nulos y variables inputs que no necesitamos\n",
    "df_pred = df_nonull.iloc[:, :5].copy()\n",
    "\n",
    "# Agregar predicicones al dataframe\n",
    "df_pred['Predictions_rnn_agg'] = np.round(y_pred, 0).astype(int)\n",
    "df_pred['Immigrant count'] = df_pred['Immigrant count'].astype('Int64')\n",
    "df_pred['Lower limit_agg'] = np.round(y_pred_lower, 0).astype(int)\n",
    "df_pred['Upper limit_agg'] = np.round(y_pred_upper, 0).astype(int)\n",
    "\n",
    "df_pred.info()\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar prediccicones de modelo seleccionado para el conjunto de datos con agregados\n",
    "df_pred.to_csv(\"../17 - Prediciones/predicciones_rn_agg.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente link se puede ver la comparativa de las prediciones de los modelos con y sin agregados: https://public.tableau.com/app/profile/cristian.de.andrade.correia/viz/PrediccindeInmigrantesenEspaa/Dashboard1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

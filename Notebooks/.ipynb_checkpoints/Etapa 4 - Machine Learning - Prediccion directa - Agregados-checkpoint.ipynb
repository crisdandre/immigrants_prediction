{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETAPA 4: MODELOS DE MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# modelos lineales\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import HuberRegressor \n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV, ElasticNet, ElasticNetCV\n",
    "\n",
    "# modelos de arboles\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "#!pip install xgboost\n",
    "#pip install pydot\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Preparar Datos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9360 entries, 0 to 9359\n",
      "Data columns (total 28 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   Year                               9360 non-null   int64  \n",
      " 1   Nationality code                   9360 non-null   object \n",
      " 2   Sex                                9360 non-null   object \n",
      " 3   Age group                          9360 non-null   object \n",
      " 4   Immigrant count                    9360 non-null   int64  \n",
      " 5   Unemployment %                     9360 non-null   float64\n",
      " 6   Political and Violence Percentile  9360 non-null   float64\n",
      " 7   Probability of dying young         9360 non-null   float64\n",
      " 8   Rule of Law Percentile             9360 non-null   float64\n",
      " 9   Salaried workers %                 9360 non-null   float64\n",
      " 10  GDP_growth                         9360 non-null   float64\n",
      " 11  Inflation_annual                   9360 non-null   float64\n",
      " 12  Liberal democracy index            9360 non-null   float64\n",
      " 13  Continent                          9360 non-null   object \n",
      " 14  Sub-region                         9360 non-null   object \n",
      " 15  Health equality                    9360 non-null   float64\n",
      " 16  Judicial accountability            9360 non-null   float64\n",
      " 17  One-sided violence_deaths          9360 non-null   int64  \n",
      " 18  Non-state_deaths                   9360 non-null   int64  \n",
      " 19  Intrastate_deaths                  9360 non-null   int64  \n",
      " 20  Interstate_deaths                  9360 non-null   int64  \n",
      " 21  Number of residents                9360 non-null   int64  \n",
      " 22  Political regime                   9360 non-null   int64  \n",
      " 23  Homicide Rate                      9024 non-null   float64\n",
      " 24  Number of Turist                   9360 non-null   int64  \n",
      " 25  Spanish language                   9360 non-null   int64  \n",
      " 26  Restricciones_pandemia             9360 non-null   int64  \n",
      " 27  Año post_pandemia                  9360 non-null   int64  \n",
      "dtypes: float64(11), int64(12), object(5)\n",
      "memory usage: 2.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Nationality code</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age group</th>\n",
       "      <th>Immigrant count</th>\n",
       "      <th>Unemployment %</th>\n",
       "      <th>Political and Violence Percentile</th>\n",
       "      <th>Probability of dying young</th>\n",
       "      <th>Rule of Law Percentile</th>\n",
       "      <th>Salaried workers %</th>\n",
       "      <th>...</th>\n",
       "      <th>Non-state_deaths</th>\n",
       "      <th>Intrastate_deaths</th>\n",
       "      <th>Interstate_deaths</th>\n",
       "      <th>Number of residents</th>\n",
       "      <th>Political regime</th>\n",
       "      <th>Homicide Rate</th>\n",
       "      <th>Number of Turist</th>\n",
       "      <th>Spanish language</th>\n",
       "      <th>Restricciones_pandemia</th>\n",
       "      <th>Año post_pandemia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>DZA</td>\n",
       "      <td>Both</td>\n",
       "      <td>0 - 14</td>\n",
       "      <td>759</td>\n",
       "      <td>11.33</td>\n",
       "      <td>14.90</td>\n",
       "      <td>3.7</td>\n",
       "      <td>24.52</td>\n",
       "      <td>67.41</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>345</td>\n",
       "      <td>0</td>\n",
       "      <td>51922</td>\n",
       "      <td>3</td>\n",
       "      <td>0.95</td>\n",
       "      <td>44400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>PER</td>\n",
       "      <td>Males</td>\n",
       "      <td>35 - 44</td>\n",
       "      <td>2938</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>60185</td>\n",
       "      <td>7</td>\n",
       "      <td>5.27</td>\n",
       "      <td>44400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>PER</td>\n",
       "      <td>Males</td>\n",
       "      <td>45 - 54</td>\n",
       "      <td>1128</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>60185</td>\n",
       "      <td>7</td>\n",
       "      <td>5.27</td>\n",
       "      <td>44400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>PER</td>\n",
       "      <td>Males</td>\n",
       "      <td>55 - 64</td>\n",
       "      <td>265</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>60185</td>\n",
       "      <td>7</td>\n",
       "      <td>5.27</td>\n",
       "      <td>44400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>PER</td>\n",
       "      <td>Males</td>\n",
       "      <td>65+</td>\n",
       "      <td>156</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>60185</td>\n",
       "      <td>7</td>\n",
       "      <td>5.27</td>\n",
       "      <td>44400000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9355</th>\n",
       "      <td>2022</td>\n",
       "      <td>PAK</td>\n",
       "      <td>Males</td>\n",
       "      <td>55 - 64</td>\n",
       "      <td>330</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>670</td>\n",
       "      <td>0</td>\n",
       "      <td>68821</td>\n",
       "      <td>6</td>\n",
       "      <td>4.21</td>\n",
       "      <td>59310000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9356</th>\n",
       "      <td>2022</td>\n",
       "      <td>PAK</td>\n",
       "      <td>Females</td>\n",
       "      <td>55 - 64</td>\n",
       "      <td>146</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>670</td>\n",
       "      <td>0</td>\n",
       "      <td>31675</td>\n",
       "      <td>6</td>\n",
       "      <td>4.21</td>\n",
       "      <td>59310000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9357</th>\n",
       "      <td>2022</td>\n",
       "      <td>PAK</td>\n",
       "      <td>Both</td>\n",
       "      <td>65+</td>\n",
       "      <td>169</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>670</td>\n",
       "      <td>0</td>\n",
       "      <td>100496</td>\n",
       "      <td>6</td>\n",
       "      <td>4.21</td>\n",
       "      <td>59310000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9358</th>\n",
       "      <td>2022</td>\n",
       "      <td>PAK</td>\n",
       "      <td>Males</td>\n",
       "      <td>65+</td>\n",
       "      <td>99</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>670</td>\n",
       "      <td>0</td>\n",
       "      <td>68821</td>\n",
       "      <td>6</td>\n",
       "      <td>4.21</td>\n",
       "      <td>59310000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9359</th>\n",
       "      <td>2022</td>\n",
       "      <td>PAK</td>\n",
       "      <td>Females</td>\n",
       "      <td>65+</td>\n",
       "      <td>70</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>670</td>\n",
       "      <td>0</td>\n",
       "      <td>31675</td>\n",
       "      <td>6</td>\n",
       "      <td>4.21</td>\n",
       "      <td>59310000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9360 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year Nationality code      Sex Age group  Immigrant count  \\\n",
       "0     2008              DZA     Both    0 - 14              759   \n",
       "1     2008              PER    Males   35 - 44             2938   \n",
       "2     2008              PER    Males   45 - 54             1128   \n",
       "3     2008              PER    Males   55 - 64              265   \n",
       "4     2008              PER    Males       65+              156   \n",
       "...    ...              ...      ...       ...              ...   \n",
       "9355  2022              PAK    Males   55 - 64              330   \n",
       "9356  2022              PAK  Females   55 - 64              146   \n",
       "9357  2022              PAK     Both       65+              169   \n",
       "9358  2022              PAK    Males       65+               99   \n",
       "9359  2022              PAK  Females       65+               70   \n",
       "\n",
       "      Unemployment %  Political and Violence Percentile  \\\n",
       "0              11.33                              14.90   \n",
       "1               4.03                              17.31   \n",
       "2               4.03                              17.31   \n",
       "3               4.03                              17.31   \n",
       "4               4.03                              17.31   \n",
       "...              ...                                ...   \n",
       "9355            5.60                               6.60   \n",
       "9356            5.60                               6.60   \n",
       "9357            5.60                               6.60   \n",
       "9358            5.60                               6.60   \n",
       "9359            5.60                               6.60   \n",
       "\n",
       "      Probability of dying young  Rule of Law Percentile  Salaried workers %  \\\n",
       "0                            3.7                   24.52               67.41   \n",
       "1                            5.1                   25.96               44.47   \n",
       "2                            5.1                   25.96               44.47   \n",
       "3                            5.1                   25.96               44.47   \n",
       "4                            5.1                   25.96               44.47   \n",
       "...                          ...                     ...                 ...   \n",
       "9355                         5.8                   25.00               42.14   \n",
       "9356                         5.8                   25.00               42.14   \n",
       "9357                         5.8                   25.00               42.14   \n",
       "9358                         5.8                   25.00               42.14   \n",
       "9359                         5.8                   25.00               42.14   \n",
       "\n",
       "      ...  Non-state_deaths  Intrastate_deaths  Interstate_deaths  \\\n",
       "0     ...                 0                345                  0   \n",
       "1     ...                 0                 40                  0   \n",
       "2     ...                 0                 40                  0   \n",
       "3     ...                 0                 40                  0   \n",
       "4     ...                 0                 40                  0   \n",
       "...   ...               ...                ...                ...   \n",
       "9355  ...                 0                670                  0   \n",
       "9356  ...                 0                670                  0   \n",
       "9357  ...                 0                670                  0   \n",
       "9358  ...                 0                670                  0   \n",
       "9359  ...                 0                670                  0   \n",
       "\n",
       "     Number of residents Political regime  Homicide Rate  Number of Turist  \\\n",
       "0                  51922                3           0.95          44400000   \n",
       "1                  60185                7           5.27          44400000   \n",
       "2                  60185                7           5.27          44400000   \n",
       "3                  60185                7           5.27          44400000   \n",
       "4                  60185                7           5.27          44400000   \n",
       "...                  ...              ...            ...               ...   \n",
       "9355               68821                6           4.21          59310000   \n",
       "9356               31675                6           4.21          59310000   \n",
       "9357              100496                6           4.21          59310000   \n",
       "9358               68821                6           4.21          59310000   \n",
       "9359               31675                6           4.21          59310000   \n",
       "\n",
       "      Spanish language  Restricciones_pandemia  Año post_pandemia  \n",
       "0                    0                       0                  0  \n",
       "1                    1                       0                  0  \n",
       "2                    1                       0                  0  \n",
       "3                    1                       0                  0  \n",
       "4                    1                       0                  0  \n",
       "...                ...                     ...                ...  \n",
       "9355                 0                       0                  1  \n",
       "9356                 0                       0                  1  \n",
       "9357                 0                       0                  1  \n",
       "9358                 0                       0                  1  \n",
       "9359                 0                       0                  1  \n",
       "\n",
       "[9360 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar el dataset\n",
    "df = pd.read_csv(\"../13 - Exports (preprocesamiento)/inmigrantes_merge.csv\")\n",
    "\n",
    "df.info()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, evaluremos modelos que no aceptan datos nulos y, posteriormente los que sí los aceptan. Luego compararemos las distintas métricas juntándolas en dataframes para un mejor análásis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Modelos Que No Aceptan Datos Nulos*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de proceder, debemos remover a Senegal de la lista de de paises ya que tenemos datos nulos para la variable Tasa de Homidicidios, de manera que no haya conflicto con los modelos que evaluaremos. Además, haremos de la varaible \"Year\" una variable ordinal y el resto de variables categóricas a variables dummy (los regímenes políticos ya están en formato ordinal).\n",
    "\n",
    "En el caso de Year, simplemente restaremos 2007 a la columna entera, y para el resto de las variables objeto usaremos la funcion *.get_dummies()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5250 entries, 1 to 9359\n",
      "Data columns (total 68 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   Year                                      5250 non-null   int64  \n",
      " 1   Immigrant count                           5250 non-null   int64  \n",
      " 2   Unemployment %                            5250 non-null   float64\n",
      " 3   Political and Violence Percentile         5250 non-null   float64\n",
      " 4   Probability of dying young                5250 non-null   float64\n",
      " 5   Rule of Law Percentile                    5250 non-null   float64\n",
      " 6   Salaried workers %                        5250 non-null   float64\n",
      " 7   GDP_growth                                5250 non-null   float64\n",
      " 8   Inflation_annual                          5250 non-null   float64\n",
      " 9   Liberal democracy index                   5250 non-null   float64\n",
      " 10  Health equality                           5250 non-null   float64\n",
      " 11  Judicial accountability                   5250 non-null   float64\n",
      " 12  One-sided violence_deaths                 5250 non-null   int64  \n",
      " 13  Non-state_deaths                          5250 non-null   int64  \n",
      " 14  Intrastate_deaths                         5250 non-null   int64  \n",
      " 15  Interstate_deaths                         5250 non-null   int64  \n",
      " 16  Number of residents                       5250 non-null   int64  \n",
      " 17  Political regime                          5250 non-null   int64  \n",
      " 18  Homicide Rate                             5250 non-null   float64\n",
      " 19  Number of Turist                          5250 non-null   int64  \n",
      " 20  Spanish language                          5250 non-null   int64  \n",
      " 21  Restricciones_pandemia                    5250 non-null   int64  \n",
      " 22  Año post_pandemia                         5250 non-null   int64  \n",
      " 23  Nationality code_ARG                      5250 non-null   int32  \n",
      " 24  Nationality code_BGR                      5250 non-null   int32  \n",
      " 25  Nationality code_BRA                      5250 non-null   int32  \n",
      " 26  Nationality code_CHN                      5250 non-null   int32  \n",
      " 27  Nationality code_COL                      5250 non-null   int32  \n",
      " 28  Nationality code_CUB                      5250 non-null   int32  \n",
      " 29  Nationality code_DEU                      5250 non-null   int32  \n",
      " 30  Nationality code_DOM                      5250 non-null   int32  \n",
      " 31  Nationality code_DZA                      5250 non-null   int32  \n",
      " 32  Nationality code_ECU                      5250 non-null   int32  \n",
      " 33  Nationality code_FRA                      5250 non-null   int32  \n",
      " 34  Nationality code_GBR                      5250 non-null   int32  \n",
      " 35  Nationality code_HND                      5250 non-null   int32  \n",
      " 36  Nationality code_ITA                      5250 non-null   int32  \n",
      " 37  Nationality code_MAR                      5250 non-null   int32  \n",
      " 38  Nationality code_NIC                      5250 non-null   int32  \n",
      " 39  Nationality code_PAK                      5250 non-null   int32  \n",
      " 40  Nationality code_PER                      5250 non-null   int32  \n",
      " 41  Nationality code_PRT                      5250 non-null   int32  \n",
      " 42  Nationality code_PRY                      5250 non-null   int32  \n",
      " 43  Nationality code_ROU                      5250 non-null   int32  \n",
      " 44  Nationality code_RUS                      5250 non-null   int32  \n",
      " 45  Nationality code_UKR                      5250 non-null   int32  \n",
      " 46  Nationality code_USA                      5250 non-null   int32  \n",
      " 47  Nationality code_VEN                      5250 non-null   int32  \n",
      " 48  Sex_Females                               5250 non-null   int32  \n",
      " 49  Sex_Males                                 5250 non-null   int32  \n",
      " 50  Age group_0 - 14                          5250 non-null   int32  \n",
      " 51  Age group_15 - 24                         5250 non-null   int32  \n",
      " 52  Age group_25 - 34                         5250 non-null   int32  \n",
      " 53  Age group_35 - 44                         5250 non-null   int32  \n",
      " 54  Age group_45 - 54                         5250 non-null   int32  \n",
      " 55  Age group_55 - 64                         5250 non-null   int32  \n",
      " 56  Age group_65+                             5250 non-null   int32  \n",
      " 57  Continent_Africa                          5250 non-null   int32  \n",
      " 58  Continent_America                         5250 non-null   int32  \n",
      " 59  Continent_Asia                            5250 non-null   int32  \n",
      " 60  Continent_Europe                          5250 non-null   int32  \n",
      " 61  Sub-region_Africa                         5250 non-null   int32  \n",
      " 62  Sub-region_Asia                           5250 non-null   int32  \n",
      " 63  Sub-region_Central America and Caribbean  5250 non-null   int32  \n",
      " 64  Sub-region_European Union                 5250 non-null   int32  \n",
      " 65  Sub-region_North America                  5250 non-null   int32  \n",
      " 66  Sub-region_Rest of Europe                 5250 non-null   int32  \n",
      " 67  Sub-region_South America                  5250 non-null   int32  \n",
      "dtypes: float64(11), int32(45), int64(12)\n",
      "memory usage: 1.9 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Immigrant count</th>\n",
       "      <th>Unemployment %</th>\n",
       "      <th>Political and Violence Percentile</th>\n",
       "      <th>Probability of dying young</th>\n",
       "      <th>Rule of Law Percentile</th>\n",
       "      <th>Salaried workers %</th>\n",
       "      <th>GDP_growth</th>\n",
       "      <th>Inflation_annual</th>\n",
       "      <th>Liberal democracy index</th>\n",
       "      <th>...</th>\n",
       "      <th>Continent_America</th>\n",
       "      <th>Continent_Asia</th>\n",
       "      <th>Continent_Europe</th>\n",
       "      <th>Sub-region_Africa</th>\n",
       "      <th>Sub-region_Asia</th>\n",
       "      <th>Sub-region_Central America and Caribbean</th>\n",
       "      <th>Sub-region_European Union</th>\n",
       "      <th>Sub-region_North America</th>\n",
       "      <th>Sub-region_Rest of Europe</th>\n",
       "      <th>Sub-region_South America</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2938</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.649</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1128</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.649</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.649</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.649</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>4703</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.649</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9353</th>\n",
       "      <td>15</td>\n",
       "      <td>452</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>4.71</td>\n",
       "      <td>13.96</td>\n",
       "      <td>0.234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9355</th>\n",
       "      <td>15</td>\n",
       "      <td>330</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>4.71</td>\n",
       "      <td>13.96</td>\n",
       "      <td>0.234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9356</th>\n",
       "      <td>15</td>\n",
       "      <td>146</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>4.71</td>\n",
       "      <td>13.96</td>\n",
       "      <td>0.234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9358</th>\n",
       "      <td>15</td>\n",
       "      <td>99</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>4.71</td>\n",
       "      <td>13.96</td>\n",
       "      <td>0.234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9359</th>\n",
       "      <td>15</td>\n",
       "      <td>70</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>4.71</td>\n",
       "      <td>13.96</td>\n",
       "      <td>0.234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5250 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  Immigrant count  Unemployment %  \\\n",
       "1        1             2938            4.03   \n",
       "2        1             1128            4.03   \n",
       "3        1              265            4.03   \n",
       "4        1              156            4.03   \n",
       "8        1             4703            4.03   \n",
       "...    ...              ...             ...   \n",
       "9353    15              452            5.60   \n",
       "9355    15              330            5.60   \n",
       "9356    15              146            5.60   \n",
       "9358    15               99            5.60   \n",
       "9359    15               70            5.60   \n",
       "\n",
       "      Political and Violence Percentile  Probability of dying young  \\\n",
       "1                                 17.31                         5.1   \n",
       "2                                 17.31                         5.1   \n",
       "3                                 17.31                         5.1   \n",
       "4                                 17.31                         5.1   \n",
       "8                                 17.31                         5.1   \n",
       "...                                 ...                         ...   \n",
       "9353                               6.60                         5.8   \n",
       "9355                               6.60                         5.8   \n",
       "9356                               6.60                         5.8   \n",
       "9358                               6.60                         5.8   \n",
       "9359                               6.60                         5.8   \n",
       "\n",
       "      Rule of Law Percentile  Salaried workers %  GDP_growth  \\\n",
       "1                      25.96               44.47        9.13   \n",
       "2                      25.96               44.47        9.13   \n",
       "3                      25.96               44.47        9.13   \n",
       "4                      25.96               44.47        9.13   \n",
       "8                      25.96               44.47        9.13   \n",
       "...                      ...                 ...         ...   \n",
       "9353                   25.00               42.14        4.71   \n",
       "9355                   25.00               42.14        4.71   \n",
       "9356                   25.00               42.14        4.71   \n",
       "9358                   25.00               42.14        4.71   \n",
       "9359                   25.00               42.14        4.71   \n",
       "\n",
       "      Inflation_annual  Liberal democracy index  ...  Continent_America  \\\n",
       "1                 1.10                    0.649  ...                  1   \n",
       "2                 1.10                    0.649  ...                  1   \n",
       "3                 1.10                    0.649  ...                  1   \n",
       "4                 1.10                    0.649  ...                  1   \n",
       "8                 1.10                    0.649  ...                  1   \n",
       "...                ...                      ...  ...                ...   \n",
       "9353             13.96                    0.234  ...                  0   \n",
       "9355             13.96                    0.234  ...                  0   \n",
       "9356             13.96                    0.234  ...                  0   \n",
       "9358             13.96                    0.234  ...                  0   \n",
       "9359             13.96                    0.234  ...                  0   \n",
       "\n",
       "      Continent_Asia  Continent_Europe  Sub-region_Africa  Sub-region_Asia  \\\n",
       "1                  0                 0                  0                0   \n",
       "2                  0                 0                  0                0   \n",
       "3                  0                 0                  0                0   \n",
       "4                  0                 0                  0                0   \n",
       "8                  0                 0                  0                0   \n",
       "...              ...               ...                ...              ...   \n",
       "9353               1                 0                  0                1   \n",
       "9355               1                 0                  0                1   \n",
       "9356               1                 0                  0                1   \n",
       "9358               1                 0                  0                1   \n",
       "9359               1                 0                  0                1   \n",
       "\n",
       "      Sub-region_Central America and Caribbean  Sub-region_European Union  \\\n",
       "1                                            0                          0   \n",
       "2                                            0                          0   \n",
       "3                                            0                          0   \n",
       "4                                            0                          0   \n",
       "8                                            0                          0   \n",
       "...                                        ...                        ...   \n",
       "9353                                         0                          0   \n",
       "9355                                         0                          0   \n",
       "9356                                         0                          0   \n",
       "9358                                         0                          0   \n",
       "9359                                         0                          0   \n",
       "\n",
       "      Sub-region_North America  Sub-region_Rest of Europe  \\\n",
       "1                            0                          0   \n",
       "2                            0                          0   \n",
       "3                            0                          0   \n",
       "4                            0                          0   \n",
       "8                            0                          0   \n",
       "...                        ...                        ...   \n",
       "9353                         0                          0   \n",
       "9355                         0                          0   \n",
       "9356                         0                          0   \n",
       "9358                         0                          0   \n",
       "9359                         0                          0   \n",
       "\n",
       "      Sub-region_South America  \n",
       "1                            1  \n",
       "2                            1  \n",
       "3                            1  \n",
       "4                            1  \n",
       "8                            1  \n",
       "...                        ...  \n",
       "9353                         0  \n",
       "9355                         0  \n",
       "9356                         0  \n",
       "9358                         0  \n",
       "9359                         0  \n",
       "\n",
       "[5250 rows x 68 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removemos las categorías de agregados\n",
    "df_noagg = df[(df[\"Sex\"] != \"Both\") & (df[\"Age group\"] != \"All\")]\n",
    "\n",
    "# hacer copia del df removiendo Senegal que presenta datos nulos para tasa de homicidios\n",
    "df_nonull = df_noagg[df_noagg['Nationality code'] != 'SEN'].copy()\n",
    "\n",
    "# Transformar Year a variable ordinal de 1 (2008) a 15 (2022)\n",
    "df_nonull['Year'] = df_nonull['Year'] - 2007\n",
    "\n",
    "# Generar variables dummies a partir de nuestras variables categóricas \"object\" (no ordinales)\n",
    "df_nonull = pd.get_dummies(df_nonull)\n",
    "\n",
    "# Convertir las variables dummies booleanas en \"int\"\n",
    "col_bool = df_nonull.select_dtypes(include = ['bool']).columns\n",
    "df_nonull[col_bool] = df_nonull[col_bool].astype(int)\n",
    "\n",
    "# Verificar cambio\n",
    "df_nonull.info()\n",
    "df_nonull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separemos el conjunto train/test y escalemos los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar variables input y variable target \"Immigrant count\" de df_null (dataframe sin atos nulos)\n",
    "X = df_nonull.drop(\"Immigrant count\", axis = 1) # variables predictoras\n",
    "y = df_nonull[\"Immigrant count\"]  # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 58) # separar datos en conjunto train y test en un 75% / 25%\n",
    "scaler = MinMaxScaler() # definir scaler de datos \n",
    "X_train = scaler.fit_transform(X_train) # escalar los datos de entrenamiento\n",
    "X_test = scaler.fit_transform(X_test) # # escalar los datos de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresion Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 train: 0.52\n",
      "RMSE - train: 1129.0\n",
      "MAE - train: 621.0\n",
      "MAPE - train: 3.3\n",
      "\n",
      "R2 test: 0.514\n",
      "RMSE - test: 965.0\n",
      "MAE - test: 614.0\n",
      "MAPE - test: 2.59\n"
     ]
    }
   ],
   "source": [
    "model_lineal = LinearRegression() # definicion del modelo \n",
    "\n",
    "model_lineal.fit(X_train, y_train) # ajuste del modelo \n",
    "\n",
    "# Aplicar modelo sobre los datos de traint y test para predecir el target\n",
    "y_train_pred_lineal = model_lineal.predict(X_train)\n",
    "y_test_pred_lineal = model_lineal.predict(X_test)\n",
    "\n",
    "# Calcular métricas en conjunto train\n",
    "r2_train_lineal = np.round(r2_score(y_train, y_train_pred_lineal), 3)\n",
    "rmse_train_lineal = np.round(np.sqrt(mean_squared_error(y_train, y_train_pred_lineal)), 0)\n",
    "mae_train_lineal = np.round(mean_absolute_error(y_train, y_train_pred_lineal), 0)\n",
    "mape_train_lineal = np.round(mean_absolute_percentage_error(y_train, y_train_pred_lineal), 2)\n",
    "\n",
    "# Calcular métricas en conjunto test\n",
    "r2_test_lineal = np.round(r2_score(y_test, y_test_pred_lineal), 3)\n",
    "rmse_test_lineal = np.round(np.sqrt(mean_squared_error(y_test, y_test_pred_lineal)), 0)\n",
    "mae_test_lineal = np.round(mean_absolute_error(y_test, y_test_pred_lineal), 0)\n",
    "mape_test_lineal = np.round(mean_absolute_percentage_error(y_test, y_test_pred_lineal), 2)\n",
    "\n",
    "# Mostrar métricas\n",
    "print(\"R2 train:\", r2_train_lineal)\n",
    "print(\"RMSE - train:\", rmse_train_lineal)\n",
    "print(\"MAE - train:\", mae_train_lineal)\n",
    "print(\"MAPE - train:\", mape_train_lineal)\n",
    "print(\"\")\n",
    "print(\"R2 test:\", r2_test_lineal)\n",
    "print(\"RMSE - test:\", rmse_test_lineal)\n",
    "print(\"MAE - test:\", mae_test_lineal)\n",
    "print(\"MAPE - test:\", mape_test_lineal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>modelo_lineal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Year</td>\n",
       "      <td>-1.976253e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unemployment %</td>\n",
       "      <td>1.579405e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Political and Violence Percentile</td>\n",
       "      <td>1.181398e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Probability of dying young</td>\n",
       "      <td>3.645572e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rule of Law Percentile</td>\n",
       "      <td>-4.808757e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Salaried workers %</td>\n",
       "      <td>-9.804175e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GDP_growth</td>\n",
       "      <td>-6.954065e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Inflation_annual</td>\n",
       "      <td>1.611803e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Liberal democracy index</td>\n",
       "      <td>2.200988e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Health equality</td>\n",
       "      <td>5.464825e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Judicial accountability</td>\n",
       "      <td>8.417867e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>One-sided violence_deaths</td>\n",
       "      <td>7.472305e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Non-state_deaths</td>\n",
       "      <td>-2.837535e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Intrastate_deaths</td>\n",
       "      <td>7.885186e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Interstate_deaths</td>\n",
       "      <td>-5.487254e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Number of residents</td>\n",
       "      <td>4.304833e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Political regime</td>\n",
       "      <td>-1.247459e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Homicide Rate</td>\n",
       "      <td>-2.574804e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Number of Turist</td>\n",
       "      <td>4.174019e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Spanish language</td>\n",
       "      <td>-1.271705e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Variable  modelo_lineal\n",
       "0                                Year  -1.976253e+03\n",
       "1                      Unemployment %   1.579405e+03\n",
       "2   Political and Violence Percentile   1.181398e+03\n",
       "3          Probability of dying young   3.645572e+03\n",
       "4              Rule of Law Percentile  -4.808757e+03\n",
       "5                  Salaried workers %  -9.804175e+02\n",
       "6                          GDP_growth  -6.954065e+02\n",
       "7                    Inflation_annual   1.611803e+03\n",
       "8             Liberal democracy index   2.200988e+03\n",
       "9                     Health equality   5.464825e+02\n",
       "10            Judicial accountability   8.417867e+02\n",
       "11          One-sided violence_deaths   7.472305e+02\n",
       "12                   Non-state_deaths  -2.837535e+02\n",
       "13                  Intrastate_deaths   7.885186e+02\n",
       "14                  Interstate_deaths  -5.487254e+02\n",
       "15                Number of residents   4.304833e+03\n",
       "16                   Political regime  -1.247459e+02\n",
       "17                      Homicide Rate  -2.574804e+03\n",
       "18                   Number of Turist   4.174019e+03\n",
       "19                   Spanish language  -1.271705e+15"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observar Coeficientes de cada variable para cada modelo en un dataframe\n",
    "coefficients_lineal = pd.DataFrame({'Variable':df_nonull.drop([\"Immigrant count\"], axis=1, inplace=False).columns})\n",
    "coefficients_lineal['modelo_lineal']= model_lineal.coef_\n",
    "\n",
    "# Mostrar coeficientes\n",
    "coefficients_lineal.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresion lineal - Huber (ventaja: bajo efecto de outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 train: 0.293\n",
      "RMSE - train: 1370.0\n",
      "MAE - train: 526.0\n",
      "MAPE - train: 0.97\n",
      "\n",
      "R2 test: 0.339\n",
      "RMSE - test: 1125.0\n",
      "MAE - test: 493.0\n",
      "MAPE - test: 0.83\n"
     ]
    }
   ],
   "source": [
    "model_huber = HuberRegressor(epsilon=1.15, alpha = 0.05) # definicion del modelo \n",
    "\n",
    "model_huber.fit(X_train, y_train) # ajuste del modelo \n",
    "\n",
    "# Aplicar modelo sobre los datos de traint y test para predecir el target\n",
    "y_train_pred_huber = model_huber.predict(X_train)\n",
    "y_test_pred_huber = model_huber.predict(X_test)\n",
    "\n",
    "# Calcular métricas en conjunto train\n",
    "r2_train_huber = np.round(r2_score(y_train, y_train_pred_huber), 3)\n",
    "rmse_train_huber = np.round(np.sqrt(mean_squared_error(y_train, y_train_pred_huber)), 0)\n",
    "mae_train_huber = np.round(mean_absolute_error(y_train, y_train_pred_huber), 0)\n",
    "mape_train_huber = np.round(mean_absolute_percentage_error(y_train, y_train_pred_huber), 2)\n",
    "\n",
    "# Calcular métricas en conjunto test\n",
    "r2_test_huber = np.round(r2_score(y_test, y_test_pred_huber), 3)\n",
    "rmse_test_huber = np.round(np.sqrt(mean_squared_error(y_test, y_test_pred_huber)), 0)\n",
    "mae_test_huber = np.round(mean_absolute_error(y_test, y_test_pred_huber), 0)\n",
    "mape_test_huber = np.round(mean_absolute_percentage_error(y_test, y_test_pred_huber), 2)\n",
    "\n",
    "# Mostrar métricas\n",
    "print(\"R2 train:\", r2_train_huber)\n",
    "print(\"RMSE - train:\", rmse_train_huber)\n",
    "print(\"MAE - train:\", mae_train_huber)\n",
    "print(\"MAPE - train:\", mape_train_huber)\n",
    "print(\"\")\n",
    "print(\"R2 test:\", r2_test_huber)\n",
    "print(\"RMSE - test:\", rmse_test_huber)\n",
    "print(\"MAE - test:\", mae_test_huber)\n",
    "print(\"MAPE - test:\", mape_test_huber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>modelo_lineal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Year</td>\n",
       "      <td>49.189602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unemployment %</td>\n",
       "      <td>191.122568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Political and Violence Percentile</td>\n",
       "      <td>-52.315324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Probability of dying young</td>\n",
       "      <td>353.186116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rule of Law Percentile</td>\n",
       "      <td>-98.252585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Salaried workers %</td>\n",
       "      <td>-310.378187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GDP_growth</td>\n",
       "      <td>-229.849611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Inflation_annual</td>\n",
       "      <td>288.534681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Liberal democracy index</td>\n",
       "      <td>178.501573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Health equality</td>\n",
       "      <td>-152.139687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Judicial accountability</td>\n",
       "      <td>186.202057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>One-sided violence_deaths</td>\n",
       "      <td>282.168743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Non-state_deaths</td>\n",
       "      <td>58.787801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Intrastate_deaths</td>\n",
       "      <td>30.510497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Interstate_deaths</td>\n",
       "      <td>265.567030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Number of residents</td>\n",
       "      <td>978.981891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Political regime</td>\n",
       "      <td>-219.942969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Homicide Rate</td>\n",
       "      <td>-300.238769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Number of Turist</td>\n",
       "      <td>448.486175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Spanish language</td>\n",
       "      <td>-3.831069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Variable  modelo_lineal\n",
       "0                                Year      49.189602\n",
       "1                      Unemployment %     191.122568\n",
       "2   Political and Violence Percentile     -52.315324\n",
       "3          Probability of dying young     353.186116\n",
       "4              Rule of Law Percentile     -98.252585\n",
       "5                  Salaried workers %    -310.378187\n",
       "6                          GDP_growth    -229.849611\n",
       "7                    Inflation_annual     288.534681\n",
       "8             Liberal democracy index     178.501573\n",
       "9                     Health equality    -152.139687\n",
       "10            Judicial accountability     186.202057\n",
       "11          One-sided violence_deaths     282.168743\n",
       "12                   Non-state_deaths      58.787801\n",
       "13                  Intrastate_deaths      30.510497\n",
       "14                  Interstate_deaths     265.567030\n",
       "15                Number of residents     978.981891\n",
       "16                   Political regime    -219.942969\n",
       "17                      Homicide Rate    -300.238769\n",
       "18                   Number of Turist     448.486175\n",
       "19                   Spanish language      -3.831069"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observar Coeficientes de cada variable para cada modelo en un dataframe\n",
    "coefficients_huber = pd.DataFrame({'Variable':df_nonull.drop([\"Immigrant count\"], axis=1, inplace=False).columns})\n",
    "coefficients_huber['modelo_lineal']= model_huber.coef_\n",
    "\n",
    "# Mostrar coeficientes\n",
    "coefficients_huber.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresion lineal - RANSAC (ventaja: bueno para grandes outliers en \"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 train: -4.762\n",
      "RMSE - train: 3913.0\n",
      "MAE - train: 788.0\n",
      "MAPE - train: 0.82\n",
      "\n",
      "R2 test: -1.224\n",
      "RMSE - test: 2064.0\n",
      "MAE - test: 608.0\n",
      "MAPE - test: 0.72\n"
     ]
    }
   ],
   "source": [
    "model_ransac = RANSACRegressor(min_samples = 15) # definicion del modelo \n",
    "\n",
    "model_ransac.fit(X_train, y_train) # ajuste del modelo \n",
    "\n",
    "# Aplicar modelo sobre los datos de traint y test para predecir el target\n",
    "y_train_pred_ransac = model_ransac.predict(X_train)\n",
    "y_test_pred_ransac = model_ransac.predict(X_test)\n",
    "\n",
    "# Calcular métricas en conjunto train\n",
    "r2_train_ransac = np.round(r2_score(y_train, y_train_pred_ransac), 3)\n",
    "rmse_train_ransac = np.round(np.sqrt(mean_squared_error(y_train, y_train_pred_ransac)), 0)\n",
    "mae_train_ransac = np.round(mean_absolute_error(y_train, y_train_pred_ransac), 0)\n",
    "mape_train_ransac = np.round(mean_absolute_percentage_error(y_train, y_train_pred_ransac), 2)\n",
    "\n",
    "# Calcular métricas en conjunto test\n",
    "r2_test_ransac = np.round(r2_score(y_test, y_test_pred_ransac), 3)\n",
    "rmse_test_ransac = np.round(np.sqrt(mean_squared_error(y_test, y_test_pred_ransac)), 0)\n",
    "mae_test_ransac = np.round(mean_absolute_error(y_test, y_test_pred_ransac), 0)\n",
    "mape_test_ransac = np.round(mean_absolute_percentage_error(y_test, y_test_pred_ransac), 2)\n",
    "\n",
    "# Mostrar métricas\n",
    "print(\"R2 train:\", r2_train_ransac)\n",
    "print(\"RMSE - train:\", rmse_train_ransac)\n",
    "print(\"MAE - train:\", mae_train_ransac)\n",
    "print(\"MAPE - train:\", mape_train_ransac)\n",
    "print(\"\")\n",
    "print(\"R2 test:\", r2_test_ransac)\n",
    "print(\"RMSE - test:\", rmse_test_ransac)\n",
    "print(\"MAE - test:\", mae_test_ransac)\n",
    "print(\"MAPE - test:\", mape_test_ransac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresion lineal - TheilSen (ventaja: bueno para outliers pequeños tanto en \"X\" como en \"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 train: 0.264\n",
      "RMSE - train: 1399.0\n",
      "MAE - train: 633.0\n",
      "MAPE - train: 2.8\n",
      "\n",
      "R2 test: 0.264\n",
      "RMSE - test: 1188.0\n",
      "MAE - test: 606.0\n",
      "MAPE - test: 2.0\n"
     ]
    }
   ],
   "source": [
    "model_theilsen = TheilSenRegressor() # definicion del modelo \n",
    "\n",
    "model_theilsen.fit(X_train, y_train) # ajuste del modelo \n",
    "\n",
    "# Aplicar modelo sobre los datos de traint y test para predecir el target\n",
    "y_train_pred_theilsen = model_theilsen.predict(X_train)\n",
    "y_test_pred_theilsen = model_theilsen.predict(X_test)\n",
    "\n",
    "# Calcular métricas en conjunto train\n",
    "r2_train_theilsen = np.round(r2_score(y_train, y_train_pred_theilsen), 3)\n",
    "rmse_train_theilsen = np.round(np.sqrt(mean_squared_error(y_train, y_train_pred_theilsen)), 0)\n",
    "mae_train_theilsen = np.round(mean_absolute_error(y_train, y_train_pred_theilsen), 0)\n",
    "mape_train_theilsen = np.round(mean_absolute_percentage_error(y_train, y_train_pred_theilsen), 2)\n",
    "\n",
    "# Calcular métricas en conjunto test\n",
    "r2_test_theilsen = np.round(r2_score(y_test, y_test_pred_theilsen), 3)\n",
    "rmse_test_theilsen = np.round(np.sqrt(mean_squared_error(y_test, y_test_pred_theilsen)), 0)\n",
    "mae_test_theilsen = np.round(mean_absolute_error(y_test, y_test_pred_theilsen), 0)\n",
    "mape_test_theilsen = np.round(mean_absolute_percentage_error(y_test, y_test_pred_theilsen), 2)\n",
    "\n",
    "# Mostrar métricas\n",
    "print(\"R2 train:\", r2_train_theilsen)\n",
    "print(\"RMSE - train:\", rmse_train_theilsen)\n",
    "print(\"MAE - train:\", mae_train_theilsen)\n",
    "print(\"MAPE - train:\", mape_train_theilsen)\n",
    "print(\"\")\n",
    "print(\"R2 test:\", r2_test_theilsen)\n",
    "print(\"RMSE - test:\", rmse_test_theilsen)\n",
    "print(\"MAE - test:\", mae_test_theilsen)\n",
    "print(\"MAPE - test:\", mape_test_theilsen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelos lineales regularizados (Ridge, Lasso, E-Net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Buscra ALfa Optimo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alfa Optimo Ridge: 0.1\n",
      "Alfa Optimo Lasso: 0.2213522106249588\n",
      "Alfa Optimo E-Net: 0.2912699474431206\n"
     ]
    }
   ],
   "source": [
    "# Definir modelo Ridge y para Evaluar el valor del \"alpha\" óptimo\n",
    "ridgecv = RidgeCV()\n",
    "ridgecv.fit(X_train, y_train)\n",
    "print(\"Alfa Optimo Ridge:\", ridgecv.alpha_)\n",
    "\n",
    "# Definir modelo Lasso y para Evaluar el valor del \"alpha\" óptimo\n",
    "lassocv = LassoCV()\n",
    "lassocv.fit(X_train, y_train)\n",
    "print(\"Alfa Optimo Lasso:\", lassocv.alpha_)\n",
    "\n",
    "# Definir modelo E-Net y para Evaluar el valor del \"alpha\" óptimo\n",
    "enetcv = ElasticNetCV()\n",
    "enetcv.fit(X_train, y_train)\n",
    "print(\"Alfa Optimo E-Net:\", enetcv.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingresamos el valor de alpha en una variable\n",
    "alpha_opt_ridge = ridgecv.alpha_\n",
    "\n",
    "# Ingresamos el valor de alpha en una variable\n",
    "alpha_opt_lasso = lassocv.alpha_\n",
    "\n",
    "# Ingresamos el valor de alpha en una variable\n",
    "alpha_opt_enet = enetcv.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrenar modelo con Alfa optimo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir modelo Ridge con nuestro valor optimo de alpha, entrenar y predecir\n",
    "modelo_ridge = Ridge(alpha = alpha_opt_ridge)\n",
    "y_test_ridge = modelo_ridge.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "# Definir modelo Lasso con nuestro valor optimo de alpha, entrenar y predecir\n",
    "modelo_lasso = Lasso(alpha = alpha_opt_lasso)\n",
    "y_test_lasso = modelo_lasso.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "# Definir modelo E-Net con nuestro valor optimo de alpha, entrenar y predecir\n",
    "modelo_enet = ElasticNet(alpha = alpha_opt_enet)\n",
    "y_test_enet = modelo_enet.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>modelo_ridge</th>\n",
       "      <th>modelo_lasso</th>\n",
       "      <th>modelo_net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Year</td>\n",
       "      <td>-1934.147404</td>\n",
       "      <td>-1870.121708</td>\n",
       "      <td>308.146821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unemployment %</td>\n",
       "      <td>1505.991885</td>\n",
       "      <td>1370.396956</td>\n",
       "      <td>139.321300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Political and Violence Percentile</td>\n",
       "      <td>1135.577297</td>\n",
       "      <td>1065.273359</td>\n",
       "      <td>-92.489791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Probability of dying young</td>\n",
       "      <td>3435.317088</td>\n",
       "      <td>3216.512909</td>\n",
       "      <td>119.515290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rule of Law Percentile</td>\n",
       "      <td>-4685.771781</td>\n",
       "      <td>-4235.870745</td>\n",
       "      <td>16.718544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Sub-region_Central America and Caribbean</td>\n",
       "      <td>109.695126</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-139.274441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Sub-region_European Union</td>\n",
       "      <td>81.001137</td>\n",
       "      <td>4.236960</td>\n",
       "      <td>43.240084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Sub-region_North America</td>\n",
       "      <td>484.464010</td>\n",
       "      <td>1.975162</td>\n",
       "      <td>-55.615174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Sub-region_Rest of Europe</td>\n",
       "      <td>20.141710</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2.202235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Sub-region_South America</td>\n",
       "      <td>-524.239235</td>\n",
       "      <td>-510.506049</td>\n",
       "      <td>112.693280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Variable  modelo_ridge  modelo_lasso  \\\n",
       "0                                       Year  -1934.147404  -1870.121708   \n",
       "1                             Unemployment %   1505.991885   1370.396956   \n",
       "2          Political and Violence Percentile   1135.577297   1065.273359   \n",
       "3                 Probability of dying young   3435.317088   3216.512909   \n",
       "4                     Rule of Law Percentile  -4685.771781  -4235.870745   \n",
       "..                                       ...           ...           ...   \n",
       "62  Sub-region_Central America and Caribbean    109.695126     -0.000000   \n",
       "63                 Sub-region_European Union     81.001137      4.236960   \n",
       "64                  Sub-region_North America    484.464010      1.975162   \n",
       "65                 Sub-region_Rest of Europe     20.141710     -0.000000   \n",
       "66                  Sub-region_South America   -524.239235   -510.506049   \n",
       "\n",
       "    modelo_net  \n",
       "0   308.146821  \n",
       "1   139.321300  \n",
       "2   -92.489791  \n",
       "3   119.515290  \n",
       "4    16.718544  \n",
       "..         ...  \n",
       "62 -139.274441  \n",
       "63   43.240084  \n",
       "64  -55.615174  \n",
       "65    2.202235  \n",
       "66  112.693280  \n",
       "\n",
       "[67 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observar Coeficientes de cada variable para cada modelo en un dataframe\n",
    "coefficients = pd.DataFrame({'Variable':df_nonull.drop([\"Immigrant count\"], axis=1, inplace=False).columns})\n",
    "coefficients['modelo_ridge']= modelo_ridge.coef_\n",
    "coefficients['modelo_lasso']= modelo_lasso.coef_\n",
    "coefficients['modelo_net']= modelo_enet.coef_\n",
    "\n",
    "# Mostrar coeficientes\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluar y Comparar Métricas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 test - Ridge: 0.514\n",
      "RMSE test - Ridge: 965.0\n",
      "MAE test - Ridge: 611.0\n",
      "MAPE test - Ridge: 2.57\n"
     ]
    }
   ],
   "source": [
    "# Métricas en test - Ridge\n",
    "r2_test_ridge = np.round(r2_score(y_test, y_test_ridge), 3)\n",
    "rmse_test_ridge = np.round(np.sqrt(mean_squared_error(y_test, y_test_ridge)), 0)\n",
    "mae_test_ridge = np.round(mean_absolute_error(y_test, y_test_ridge), 0)\n",
    "mape_test_ridge = np.round(mean_absolute_percentage_error(y_test, y_test_ridge), 2)\n",
    "\n",
    "# Mostrar métricas - Ridge\n",
    "print(\"R2 test - Ridge:\", r2_test_ridge)\n",
    "print(\"RMSE test - Ridge:\", rmse_test_ridge)\n",
    "print(\"MAE test - Ridge:\", mae_test_ridge)\n",
    "print(\"MAPE test - Ridge:\", mape_test_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 test - Lasso: 0.516\n",
      "RMSE test - Lasso: 963.0\n",
      "MAE test - Lasso: 608.0\n",
      "MAPE test - Lasso: 2.54\n"
     ]
    }
   ],
   "source": [
    "# Métricas en test - Lasso\n",
    "r2_test_lasso = np.round(r2_score(y_test, y_test_lasso), 3)\n",
    "rmse_test_lasso = np.round(np.sqrt(mean_squared_error(y_test, y_test_lasso)), 0)\n",
    "mae_test_lasso = np.round(mean_absolute_error(y_test, y_test_lasso), 0)\n",
    "mape_test_lasso = np.round(mean_absolute_percentage_error(y_test, y_test_lasso), 2)\n",
    "\n",
    "# Mostrar métricas - Lasso\n",
    "print(\"R2 test - Lasso:\", r2_test_lasso)\n",
    "print(\"RMSE test - Lasso:\", rmse_test_lasso)\n",
    "print(\"MAE test - Lasso:\", mae_test_lasso)\n",
    "print(\"MAPE test - Lasso:\", mape_test_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 test - E-Net: 0.339\n",
      "RMSE test - E-Net: 1125.0\n",
      "MAE test - E-Net: 625.0\n",
      "MAPE test - E-Net: 2.36\n"
     ]
    }
   ],
   "source": [
    "# Métricas en test - E-Net\n",
    "r2_test_enet = np.round(r2_score(y_test, y_test_enet), 3)\n",
    "rmse_test_enet = np.round(np.sqrt(mean_squared_error(y_test, y_test_enet)), 0)\n",
    "mae_test_enet = np.round(mean_absolute_error(y_test, y_test_enet), 0)\n",
    "mape_test_enet = np.round(mean_absolute_percentage_error(y_test, y_test_enet), 2)\n",
    "\n",
    "# Mostrar métricas - E-Net\n",
    "print(\"R2 test - E-Net:\", r2_test_enet)\n",
    "print(\"RMSE test - E-Net:\", rmse_test_enet)\n",
    "print(\"MAE test - E-Net:\", mae_test_enet)\n",
    "print(\"MAPE test - E-Net:\", mape_test_enet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desicion Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'absolute_error', 'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 20}\n"
     ]
    }
   ],
   "source": [
    "# Definir diccionario de valores para parámetros \n",
    "params = {'max_depth': range(6,8), \n",
    "          'min_samples_leaf' : [1, 3, 4], \n",
    "          'min_samples_split': [20, 30], \n",
    "          \"criterion\" : [\"squared_error\", \"absolute_error\", \"poisson\"] \n",
    "          } \n",
    "\n",
    "# Definir modelo y aplicar combinaciones de parametros según el diccinario \n",
    "tree = DecisionTreeRegressor() \n",
    "tree_cv = GridSearchCV(tree, params, cv = 3, refit = True, scoring = \"neg_mean_squared_error\")\n",
    "\n",
    "# Entrenar modelo con cada combinación de parámetro \n",
    "tree_cv.fit(X_train, y_train) \n",
    "\n",
    "# Montrar los valores de los parámetros \n",
    "print(tree_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 - train: 0.69\n",
      "RMSE - train: 908.0\n",
      "MAE - train: 386.0\n",
      "MAPE - train: 0.59\n",
      "\n",
      "R2 - test: 0.548\n",
      "RMSE - test: 931.0\n",
      "MAE - test: 440.0\n",
      "MAPE - test: 0.68\n"
     ]
    }
   ],
   "source": [
    "# Definir modelo con los mejores valores de parámetros \n",
    "tree_best =  DecisionTreeRegressor(max_depth = 8, \n",
    "                                   min_samples_leaf = 2,\n",
    "                                   min_samples_split = 15, \n",
    "                                   criterion = 'tree_cv.best_params_['criterion']') \n",
    "\n",
    "# Entrenar con el conjunto de entrenamiento \n",
    "tree_best.fit(X_train, y_train) \n",
    "\n",
    "# Aplicar modelo sobre los datos de traint y test para predecir el target\n",
    "y_test_pred_tree = tree_best.predict(X_test) \n",
    "y_train_pred_tree = tree_best.predict(X_train) \n",
    "\n",
    "# Calcular métricas en conjunto train\n",
    "r2_train_tree = np.round(r2_score(y_train, y_train_pred_tree), 3)\n",
    "rmse_train_tree = np.round(np.sqrt(mean_squared_error(y_train, y_train_pred_tree)), 0)\n",
    "mae_train_tree = np.round(mean_absolute_error(y_train, y_train_pred_tree), 0)\n",
    "mape_train_tree = np.round(mean_absolute_percentage_error(y_train, y_train_pred_tree), 2)\n",
    "\n",
    "# Calcular métricas en conjunto test\n",
    "r2_test_tree = np.round(r2_score(y_test, y_test_pred_tree), 3)\n",
    "rmse_test_tree = np.round(np.sqrt(mean_squared_error(y_test, y_test_pred_tree)), 0)\n",
    "mae_test_tree = np.round(mean_absolute_error(y_test, y_test_pred_tree), 0)\n",
    "mape_test_tree = np.round(mean_absolute_percentage_error(y_test, y_test_pred_tree), 2)\n",
    "\n",
    "# Mostrar métricas\n",
    "print(\"R2 - train:\", r2_train_tree)\n",
    "print(\"RMSE - train:\", rmse_train_tree)\n",
    "print(\"MAE - train:\", mae_train_tree)\n",
    "print(\"MAPE - train:\", mape_train_tree)\n",
    "print(\"\")\n",
    "print(\"R2 - test:\", r2_test_tree)\n",
    "print(\"RMSE - test:\", rmse_test_tree)\n",
    "print(\"MAE - test:\", mae_test_tree)\n",
    "print(\"MAPE - test:\", mape_test_tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(criterion=&#x27;poisson&#x27;, max_depth=8, min_samples_leaf=2,\n",
       "                      min_samples_split=30)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(criterion=&#x27;poisson&#x27;, max_depth=8, min_samples_leaf=2,\n",
       "                      min_samples_split=30)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(criterion='poisson', max_depth=8, min_samples_leaf=2,\n",
       "                      min_samples_split=30)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir diccionario de valores para parámetros \n",
    "params = {'n_estimators': [100], \n",
    "\t      'criterion' : ['squared_error', 'friedman_mse', 'poisson'],\n",
    "          \"min_samples_split\": [30, 50, 70], \n",
    "          'min_samples_leaf' : [2, 3, 5],\n",
    "          \"max_depth\": [7, 8],\n",
    "          }\n",
    "\n",
    "# Definir modelo y aplicar combinaciones de parametros según el diccinario \n",
    "rf = RandomForestRegressor() \n",
    "rf_cv = GridSearchCV(rf, params, cv=3, scoring='neg_mean_squared_error').fit(X_train, y_train)\n",
    "\n",
    "# Motrar mejores valores para parámeros\n",
    "rf_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 - train: 0.791\n",
      "RMSE - train: 745.0\n",
      "MAE - train: 340.0\n",
      "MAPE - train: 0.72\n",
      "\n",
      "R2 - test: 0.754\n",
      "RMSE - test: 687.0\n",
      "MAE - test: 357.0\n",
      "MAPE - test: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Definir modelo con los mejores valores de parámetros (Nota: usar los mejores, pero hacer modificaciones para comparar metricas)\n",
    "rf_best = RandomForestRegressor(n_estimators = 100, \n",
    "                           max_depth = 8, \n",
    "                           criterion = 'poisson', \n",
    "                           min_samples_split = 20,  #se ajustó a 20 para mejorar resultados en test\n",
    "                           min_samples_leaf = 2,  \n",
    "                           )\n",
    "\n",
    "# Entrenar con el conjunto de entrenamiento \n",
    "rf_best.fit(X_train, y_train) \n",
    "\n",
    "# Aplicar modelo sobre los datos de traint y test para predecir el target\n",
    "y_train_pred_rf = rf_best.predict(X_train)\n",
    "y_test_pred_rf = rf_best.predict(X_test)\n",
    "\n",
    "# Calcular métricas en conjunto train\n",
    "r2_train_rf = np.round(r2_score(y_train, y_train_pred_rf), 3)\n",
    "rmse_train_rf = np.round(np.sqrt(mean_squared_error(y_train, y_train_pred_rf)), 0)\n",
    "mae_train_rf = np.round(mean_absolute_error(y_train, y_train_pred_rf), 0)\n",
    "mape_train_rf = np.round(mean_absolute_percentage_error(y_train, y_train_pred_rf), 2)\n",
    "\n",
    "# Calcular métricas en conjunto test\n",
    "r2_test_rf = np.round(r2_score(y_test, y_test_pred_rf), 3)\n",
    "rmse_test_rf = np.round(np.sqrt(mean_squared_error(y_test, y_test_pred_rf)), 0)\n",
    "mae_test_rf = np.round(mean_absolute_error(y_test, y_test_pred_rf), 0)\n",
    "mape_test_rf = np.round(mean_absolute_percentage_error(y_test, y_test_pred_rf), 2)\n",
    "\n",
    "# Mostrar métricas\n",
    "print(\"R2 - train:\", r2_train_rf)\n",
    "print(\"RMSE - train:\", rmse_train_rf)\n",
    "print(\"MAE - train:\", mae_train_rf)\n",
    "print(\"MAPE - train:\", mape_train_rf)\n",
    "print(\"\")\n",
    "print(\"R2 - test:\", r2_test_rf)\n",
    "print(\"RMSE - test:\", rmse_test_rf)\n",
    "print(\"MAE - test:\", mae_test_rf)\n",
    "print(\"MAPE - test:\", mape_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importancia relativa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Number of residents</td>\n",
       "      <td>0.340281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Age group_25 - 34</td>\n",
       "      <td>0.101193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GDP_growth</td>\n",
       "      <td>0.060511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Age group_65+</td>\n",
       "      <td>0.057411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Year</td>\n",
       "      <td>0.045674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Age group_55 - 64</td>\n",
       "      <td>0.045564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unemployment %</td>\n",
       "      <td>0.036155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Probability of dying young</td>\n",
       "      <td>0.036135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Number of Turist</td>\n",
       "      <td>0.032492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Non-state_deaths</td>\n",
       "      <td>0.030966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Salaried workers %</td>\n",
       "      <td>0.028310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Año post_pandemia</td>\n",
       "      <td>0.025117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Inflation_annual</td>\n",
       "      <td>0.021095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Age group_15 - 24</td>\n",
       "      <td>0.020494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Age group_45 - 54</td>\n",
       "      <td>0.018823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      variable  importancia relativa\n",
       "15         Number of residents              0.340281\n",
       "51           Age group_25 - 34              0.101193\n",
       "6                   GDP_growth              0.060511\n",
       "55               Age group_65+              0.057411\n",
       "0                         Year              0.045674\n",
       "54           Age group_55 - 64              0.045564\n",
       "1               Unemployment %              0.036155\n",
       "3   Probability of dying young              0.036135\n",
       "18            Number of Turist              0.032492\n",
       "12            Non-state_deaths              0.030966\n",
       "5           Salaried workers %              0.028310\n",
       "21           Año post_pandemia              0.025117\n",
       "7             Inflation_annual              0.021095\n",
       "50           Age group_15 - 24              0.020494\n",
       "53           Age group_45 - 54              0.018823"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimación de importancia relativa de variables en el modelo\n",
    "imp_rel_rf = rf_best.feature_importances_\n",
    "importancias = pd.DataFrame({\"variable\": X.columns, \"importancia relativa\": imp_rel_rf}) \\\n",
    ".sort_values(by='importancia relativa', ascending = False)\n",
    "importancias[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 11, 'weights': 'distance'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir diccionario de valores para parámetros \n",
    "params = {'n_neighbors': range(1,20),\n",
    "          'weights' : ['uniform', 'distance'],\n",
    "          }\n",
    "\n",
    "# Definir modelo y aplicar combinaciones de parametros según el diccinario entrenando el conjunto train\n",
    "knn = KNeighborsRegressor()\n",
    "knn_cv = GridSearchCV(knn, params, cv=3, scoring='neg_mean_squared_error').fit(X_train,y_train)\n",
    "\n",
    "knn_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 - train: 0.721\n",
      "RMSE - train: 861.0\n",
      "MAE - train: 376.0\n",
      "MAPE - train: 0.87\n",
      "\n",
      "R2 - test: 0.697\n",
      "RMSE - test: 762.0\n",
      "MAE - test: 380.0\n",
      "MAPE - test: 0.95\n"
     ]
    }
   ],
   "source": [
    "knn_best =  KNeighborsRegressor(n_neighbors = 11, weights = 'uniform', leaf_size=30, p = 1)\n",
    "\n",
    "knn_best.fit(X_train, y_train)\n",
    "\n",
    "# Obtener predicciones con conjunto de entrenamiento y prueba\n",
    "y_train_pred_knn = knn_best.predict(X_train)  \n",
    "y_test_pred_knn = knn_best.predict(X_test)  \n",
    "\n",
    "# Calcular métricas en conjunto train\n",
    "r2_train_knn = np.round(r2_score(y_train, y_train_pred_knn), 3)\n",
    "rmse_train_knn = np.round(np.sqrt(mean_squared_error(y_train, y_train_pred_knn)), 0)\n",
    "mae_train_knn = np.round(mean_absolute_error(y_train, y_train_pred_knn), 0)\n",
    "mape_train_knn = np.round(mean_absolute_percentage_error(y_train, y_train_pred_knn), 2)\n",
    "\n",
    "# Calcular métricas en conjunto train\n",
    "r2_test_knn = np.round(r2_score(y_test, y_test_pred_knn), 3)\n",
    "rmse_test_knn = np.round(np.sqrt(mean_squared_error(y_test, y_test_pred_knn)), 0)\n",
    "mae_test_knn = np.round(mean_absolute_error(y_test, y_test_pred_knn), 0)\n",
    "mape_test_knn = np.round(mean_absolute_percentage_error(y_test, y_test_pred_knn), 2)\n",
    "\n",
    "# Print metrics\n",
    "print(\"R2 - train:\", r2_train_knn)\n",
    "print(\"RMSE - train:\", rmse_train_knn)\n",
    "print(\"MAE - train:\", mae_train_knn)\n",
    "print(\"MAPE - train:\", mape_train_knn)\n",
    "print(\"\")\n",
    "print(\"R2 - test:\", r2_test_knn)\n",
    "print(\"RMSE - test:\", rmse_test_knn)\n",
    "print(\"MAE - test:\", mae_test_knn)\n",
    "print(\"MAPE - test:\", mape_test_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'tol': 0.0015}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir diccionario de valores para parámetros \n",
    "params = {'kernel': ['rbf', 'linear'],\n",
    "          'gamma': ['scale', 'auto'],\n",
    "          'C' : [1.0, 0.85, 0.75] ,\n",
    "          'max_iter': [-1, 100],\n",
    "          \"tol\" : [0.001, 0.002, 0.0015, 0.1, 0.2]\n",
    "          }\n",
    "\n",
    "# Definir modelo y aplicar combinaciones de parametros según el diccinario \n",
    "svr = SVR()\n",
    "svr_cv = GridSearchCV(svr, params, cv = 3, refit = True, scoring = 'neg_mean_squared_error') # elegir scoring deseano (r2, mae, mse, mape...)\n",
    "\n",
    "# Entrenar modelo con cada combinación de parámetro \n",
    "svr_cv.fit(X_train, y_train)\n",
    "\n",
    "# Motrar mejores valores para parámeros\n",
    "svr_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 - train: 0.055\n",
      "RMSE - train: 1585.0\n",
      "MAE - train: 620.0\n",
      "MAPE - train: 0.89\n",
      "\n",
      "R2 - test: 0.074\n",
      "RMSE - test: 1332.0\n",
      "MAE - test: 579.0\n",
      "MAPE - test: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Definir modelo con mejors parámetros\n",
    "svr_best = SVR(kernel = 'linear', \n",
    "               gamma = 'scale', \n",
    "               C = 1.0, \n",
    "               max_iter = -1, \n",
    "               tol = 0.0015\n",
    "               )\n",
    "\n",
    "# Enrenar con el conjunto de entrenamiento \n",
    "svr_best.fit(X_train, y_train) \n",
    "\n",
    "# Obtener predicciones con conjunto de entrenamiento y prueba\n",
    "y_train_pred_svr = svr_best.predict(X_train)  \n",
    "y_test_pred_svr = svr_best.predict(X_test)  \n",
    "\n",
    "# Calcular métricas en conjunto train\n",
    "r2_train_svr = np.round(r2_score(y_train, y_train_pred_svr), 3)\n",
    "rmse_train_svr = np.round(np.sqrt(mean_squared_error(y_train, y_train_pred_svr)), 0)\n",
    "mae_train_svr = np.round(mean_absolute_error(y_train, y_train_pred_svr), 0)\n",
    "mape_train_svr = np.round(mean_absolute_percentage_error(y_train, y_train_pred_svr), 2)\n",
    "\n",
    "# Calcular métricas en conjunto test\n",
    "r2_test_svr = np.round(r2_score(y_test, y_test_pred_svr), 3)\n",
    "rmse_test_svr = np.round(np.sqrt(mean_squared_error(y_test, y_test_pred_svr)), 0)\n",
    "mae_test_svr = np.round(mean_absolute_error(y_test, y_test_pred_svr), 0)\n",
    "mape_test_svr = np.round(mean_absolute_percentage_error(y_test, y_test_pred_svr), 2)\n",
    "\n",
    "# Mostrar métricas\n",
    "print(\"R2 - train:\", r2_train_svr)\n",
    "print(\"RMSE - train:\", rmse_train_svr)\n",
    "print(\"MAE - train:\", mae_train_svr)\n",
    "print(\"MAPE - train:\", mape_train_svr)\n",
    "print(\"\")\n",
    "print(\"R2 - test:\", r2_test_svr)\n",
    "print(\"RMSE - test:\", rmse_test_svr)\n",
    "print(\"MAE - test:\", mae_test_svr)\n",
    "print(\"MAPE - test:\", mape_test_svr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Red Neuronal Básica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtengamos primero un número de referencia en cuanto a el número de neuronas a usar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.575836902790225\n",
      "46.666666666666664\n"
     ]
    }
   ],
   "source": [
    "# Dos métodos para estimar numero de neuronas a usar\n",
    "print(np.sqrt(len(X.columns)*2))\n",
    "print(2/3 * len(X.columns) + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "54 fits failed out of a total of 486.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 749, in fit\n",
      "    return self._fit(X, y, incremental=False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 471, in _fit\n",
      "    self._fit_stochastic(\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 655, in _fit_stochastic\n",
      "    self._update_no_improvement_count(early_stopping, X_val, y_val)\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 704, in _update_no_improvement_count\n",
      "    self.validation_scores_.append(self._score(X_val, y_val))\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 1610, in _score\n",
      "    return r2_score(y, y_pred)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "                                          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 102, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [-1610738.58788195 -2658897.03858887  -778580.55850745 -1553084.17864298\n",
      " -2660283.27543785  -589736.19813803  -964552.17830727 -2661500.08308687\n",
      "  -733482.21337216 -1919649.45393209 -2657919.45763676  -638533.63121662\n",
      " -1543235.66227738 -2659045.83194876  -464325.5713223  -1040233.85377898\n",
      " -2657883.12829484  -508876.47663748 -2072238.88844136 -2671595.00810324\n",
      " -1009666.62781299 -1585806.49618084 -2659199.39853183  -518223.75234515\n",
      " -1122911.99042008 -2659749.67635449  -668332.92167156 -1623006.04573909\n",
      " -2658188.16601107  -790893.85388681 -1552384.80669537 -2659776.11370283\n",
      "  -673313.12924971 -1080740.37798938 -2659661.84717345  -544223.9882438\n",
      " -1898621.68697788 -2661744.91614569  -867629.31236857 -1573387.47867665\n",
      " -2661091.10581951  -461936.97086385 -1461326.75016488 -2659797.06718651\n",
      "  -656299.06234651 -2116995.98639824 -2661771.36215214  -560937.68848\n",
      " -1589625.73194087 -2670854.55335043 -1144004.51389655 -1358788.58033139\n",
      " -2669274.89112357  -547061.55375489 -1618221.17507473               nan\n",
      " -1377742.44856937 -1503066.0608073                nan -1378395.4405845\n",
      " -1541031.57589546               nan -1404775.55066805 -1821082.70692914\n",
      "               nan -1378029.07069179 -1524799.13788441               nan\n",
      " -1379834.44993213 -1549322.2991066                nan -1398364.04835354\n",
      " -2019576.20491459               nan -1378270.45571351 -1567685.84849158\n",
      "               nan -1379520.12403022 -1467479.66647616               nan\n",
      " -1382450.19631906 -1616017.74979686               nan -1379952.14169032\n",
      " -1533125.17145325               nan -1378946.7239756  -1542644.97898924\n",
      "               nan -1376250.23973002 -1813304.45435722               nan\n",
      " -1379694.31295439 -1522984.90823056               nan -1379800.19867864\n",
      " -1525285.87550623               nan -1380034.21560132 -2018271.34204615\n",
      "               nan -1378004.6449985  -1566440.32832724               nan\n",
      " -1378899.90096165 -1463646.76380172               nan -1378453.18171967\n",
      " -3380025.06069114 -2666236.44513228 -2390768.61858107 -2740537.01072422\n",
      " -2664336.16860457 -2553590.84758687 -3380639.32077109 -2656965.09820935\n",
      " -2660162.54861785 -3499424.45300258 -2664668.82423133 -2657217.54540474\n",
      " -3042433.33806116 -2660881.03255847 -1675778.24837036 -3502298.80411526\n",
      " -2659152.37141299 -1817790.86882264 -3558319.35619584 -2665651.16112632\n",
      " -2395477.2348695  -3194273.79232378 -2671855.04737516 -1910121.32227097\n",
      " -3559791.46203055 -2655691.79931062 -2080019.94493478 -3380408.96097579\n",
      " -2657773.68211178 -2658331.60076169 -2743283.95922528 -2659357.04687276\n",
      " -1927751.54207436 -3380480.35495435 -2660449.56504419 -2659988.95044547\n",
      " -3500105.24873669 -2664015.85956532 -2600474.28152823 -3044041.89373774\n",
      " -2663814.20190626 -1751851.98786905 -3501744.41511077 -2670604.33944891\n",
      " -2051082.54081444 -3557637.83856411 -2677597.05357461 -2506390.49155083\n",
      " -3194169.76309231 -2660161.35961981 -1880131.31843176 -3560837.93934285\n",
      " -2662351.23721292 -2113880.34835436]\n",
      "  warnings.warn(\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 0.01,\n",
       " 'batch_size': 50,\n",
       " 'early_stopping': True,\n",
       " 'hidden_layer_sizes': 44,\n",
       " 'max_iter': 200,\n",
       " 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir diccionario de valores para parámetros \n",
    "params = {'max_iter': [200],\n",
    "          'hidden_layer_sizes':[11, 44, (44, 11)], # Si se quiere usar dos capas de neuronas, se usa una tupla\n",
    "          'batch_size': [30, 50, 70],\n",
    "          'activation': ['relu', 'identity', 'tanh'],\n",
    "          'alpha': [0.1, 0.01],\n",
    "          'early_stopping' : [True],\n",
    "          'solver' : ['adam', 'sgd', 'lbfgs']}\n",
    "\n",
    "# Definir modelo y aplicar combinaciones de parametros según el diccinario \n",
    "rn = MLPRegressor()\n",
    "rn_cv = GridSearchCV(rn, param_grid = params, cv = 3, scoring='neg_mean_squared_error', verbose=True, n_jobs = -1)\n",
    "\n",
    "# Entrenar modelo con cada combinación de parámetro \n",
    "rn_cv.fit(X_train, y_train)\n",
    "\n",
    "# Motrar mejores valores para parámeros\n",
    "rn_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "nombre = 'rnn_best_noagg.sav'\n",
    "#pickle.dump(rn_best, open(nombre, 'wb'))\n",
    "\n",
    "# Load the model from the file\n",
    "rn_best = pickle.load(open(nombre, 'rb'))\n",
    "#result = loaded_model.score(X, y)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 - train: 0.968\n",
      "RMSE - train: 290.0\n",
      "MAE - train: 188.0\n",
      "MAPE - train: 0.57\n",
      "\n",
      "R2 - test: 0.911\n",
      "MAE - test: 242.0\n"
     ]
    }
   ],
   "source": [
    "# hacer un RN con los mejores parametros obtenidos y entrenar\n",
    "rn_best = MLPRegressor(activation = 'relu',\n",
    "                          alpha = 0.01, \n",
    "                          batch_size= 50, \n",
    "                          early_stopping = True, \n",
    "                          hidden_layer_sizes = 60, \n",
    "                          max_iter = 200, \n",
    "                          solver = 'lbfgs',\n",
    "                          )\n",
    "\n",
    "# Entrenar con el conjunto de entrenamiento \n",
    "rn_best.fit(X_train, y_train)\n",
    "\n",
    "# Aplicar modelo sobre los datos de traint y test para predecir el target\n",
    "y_test_pred_rn = rn_best.predict(X_test) \n",
    "y_train_pred_rn = rn_best.predict(X_train) \n",
    "\n",
    "# Calculo de metricas en train\n",
    "r2_train_rn = np.round(r2_score(y_train, y_train_pred_rn), 3)\n",
    "rmse_train_rn = np.round(np.sqrt(mean_squared_error(y_train, y_train_pred_rn)), 0)\n",
    "mae_train_rn = np.round(mean_absolute_error(y_train, y_train_pred_rn), 0)\n",
    "mape_train_rn = np.round(mean_absolute_percentage_error(y_train, y_train_pred_rn), 2)\n",
    "\n",
    "# Calculo de metricas en test\n",
    "r2_test_rn = np.round(r2_score(y_test, y_test_pred_rn), 3)\n",
    "# rmse_test_rn = np.round(np.sqrt(mean_squared_error(y_test, y_test_pred_rn)), 0) \n",
    "mae_test_rn = np.round(mean_absolute_error(y_test, y_test_pred_rn), 0)\n",
    "# mape_test_rn = np.round(mean_absolute_percentage_error(y_test, y_test_pred_rn), 2)  \n",
    "\n",
    "# Mostrar métricas\n",
    "print(\"R2 - train:\", r2_train_rn)\n",
    "print(\"RMSE - train:\", rmse_train_rn)\n",
    "print(\"MAE - train:\", mae_train_rn)\n",
    "print(\"MAPE - train:\", mape_train_rn)\n",
    "print(\"\")\n",
    "print(\"R2 - test:\", r2_test_rn)\n",
    "# print(\"RMSE - test:\", rmse_test_rn)\n",
    "print(\"MAE - test:\", mae_test_rn)\n",
    "# print(\"MAPE - test:\", mape_test_rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Modelos Que Aceptan Datos Nulos*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora evalueremos los datos con dos modelos que aceptan datos nulos (Hist Gradient Boosting y XGBoost), por lo que haremos una copia del conunto de datos con todos los países y, al igual que antes, haremos de la variable \"Year\" una variable ordinal y el resto de variable categóricas a variables *dummy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5460 entries, 1 to 9359\n",
      "Data columns (total 69 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   Year                                      5460 non-null   int64  \n",
      " 1   Immigrant count                           5460 non-null   int64  \n",
      " 2   Unemployment %                            5460 non-null   float64\n",
      " 3   Political and Violence Percentile         5460 non-null   float64\n",
      " 4   Probability of dying young                5460 non-null   float64\n",
      " 5   Rule of Law Percentile                    5460 non-null   float64\n",
      " 6   Salaried workers %                        5460 non-null   float64\n",
      " 7   GDP_growth                                5460 non-null   float64\n",
      " 8   Inflation_annual                          5460 non-null   float64\n",
      " 9   Liberal democracy index                   5460 non-null   float64\n",
      " 10  Health equality                           5460 non-null   float64\n",
      " 11  Judicial accountability                   5460 non-null   float64\n",
      " 12  One-sided violence_deaths                 5460 non-null   int64  \n",
      " 13  Non-state_deaths                          5460 non-null   int64  \n",
      " 14  Intrastate_deaths                         5460 non-null   int64  \n",
      " 15  Interstate_deaths                         5460 non-null   int64  \n",
      " 16  Number of residents                       5460 non-null   int64  \n",
      " 17  Political regime                          5460 non-null   int64  \n",
      " 18  Homicide Rate                             5264 non-null   float64\n",
      " 19  Number of Turist                          5460 non-null   int64  \n",
      " 20  Spanish language                          5460 non-null   int64  \n",
      " 21  Restricciones_pandemia                    5460 non-null   int64  \n",
      " 22  Año post_pandemia                         5460 non-null   int64  \n",
      " 23  Nationality code_ARG                      5460 non-null   int32  \n",
      " 24  Nationality code_BGR                      5460 non-null   int32  \n",
      " 25  Nationality code_BRA                      5460 non-null   int32  \n",
      " 26  Nationality code_CHN                      5460 non-null   int32  \n",
      " 27  Nationality code_COL                      5460 non-null   int32  \n",
      " 28  Nationality code_CUB                      5460 non-null   int32  \n",
      " 29  Nationality code_DEU                      5460 non-null   int32  \n",
      " 30  Nationality code_DOM                      5460 non-null   int32  \n",
      " 31  Nationality code_DZA                      5460 non-null   int32  \n",
      " 32  Nationality code_ECU                      5460 non-null   int32  \n",
      " 33  Nationality code_FRA                      5460 non-null   int32  \n",
      " 34  Nationality code_GBR                      5460 non-null   int32  \n",
      " 35  Nationality code_HND                      5460 non-null   int32  \n",
      " 36  Nationality code_ITA                      5460 non-null   int32  \n",
      " 37  Nationality code_MAR                      5460 non-null   int32  \n",
      " 38  Nationality code_NIC                      5460 non-null   int32  \n",
      " 39  Nationality code_PAK                      5460 non-null   int32  \n",
      " 40  Nationality code_PER                      5460 non-null   int32  \n",
      " 41  Nationality code_PRT                      5460 non-null   int32  \n",
      " 42  Nationality code_PRY                      5460 non-null   int32  \n",
      " 43  Nationality code_ROU                      5460 non-null   int32  \n",
      " 44  Nationality code_RUS                      5460 non-null   int32  \n",
      " 45  Nationality code_SEN                      5460 non-null   int32  \n",
      " 46  Nationality code_UKR                      5460 non-null   int32  \n",
      " 47  Nationality code_USA                      5460 non-null   int32  \n",
      " 48  Nationality code_VEN                      5460 non-null   int32  \n",
      " 49  Sex_Females                               5460 non-null   int32  \n",
      " 50  Sex_Males                                 5460 non-null   int32  \n",
      " 51  Age group_0 - 14                          5460 non-null   int32  \n",
      " 52  Age group_15 - 24                         5460 non-null   int32  \n",
      " 53  Age group_25 - 34                         5460 non-null   int32  \n",
      " 54  Age group_35 - 44                         5460 non-null   int32  \n",
      " 55  Age group_45 - 54                         5460 non-null   int32  \n",
      " 56  Age group_55 - 64                         5460 non-null   int32  \n",
      " 57  Age group_65+                             5460 non-null   int32  \n",
      " 58  Continent_Africa                          5460 non-null   int32  \n",
      " 59  Continent_America                         5460 non-null   int32  \n",
      " 60  Continent_Asia                            5460 non-null   int32  \n",
      " 61  Continent_Europe                          5460 non-null   int32  \n",
      " 62  Sub-region_Africa                         5460 non-null   int32  \n",
      " 63  Sub-region_Asia                           5460 non-null   int32  \n",
      " 64  Sub-region_Central America and Caribbean  5460 non-null   int32  \n",
      " 65  Sub-region_European Union                 5460 non-null   int32  \n",
      " 66  Sub-region_North America                  5460 non-null   int32  \n",
      " 67  Sub-region_Rest of Europe                 5460 non-null   int32  \n",
      " 68  Sub-region_South America                  5460 non-null   int32  \n",
      "dtypes: float64(11), int32(46), int64(12)\n",
      "memory usage: 2.0 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Immigrant count</th>\n",
       "      <th>Unemployment %</th>\n",
       "      <th>Political and Violence Percentile</th>\n",
       "      <th>Probability of dying young</th>\n",
       "      <th>Rule of Law Percentile</th>\n",
       "      <th>Salaried workers %</th>\n",
       "      <th>GDP_growth</th>\n",
       "      <th>Inflation_annual</th>\n",
       "      <th>Liberal democracy index</th>\n",
       "      <th>...</th>\n",
       "      <th>Continent_America</th>\n",
       "      <th>Continent_Asia</th>\n",
       "      <th>Continent_Europe</th>\n",
       "      <th>Sub-region_Africa</th>\n",
       "      <th>Sub-region_Asia</th>\n",
       "      <th>Sub-region_Central America and Caribbean</th>\n",
       "      <th>Sub-region_European Union</th>\n",
       "      <th>Sub-region_North America</th>\n",
       "      <th>Sub-region_Rest of Europe</th>\n",
       "      <th>Sub-region_South America</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2938</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.649</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1128</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.649</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.649</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.649</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>4703</td>\n",
       "      <td>4.03</td>\n",
       "      <td>17.31</td>\n",
       "      <td>5.1</td>\n",
       "      <td>25.96</td>\n",
       "      <td>44.47</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.649</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9353</th>\n",
       "      <td>15</td>\n",
       "      <td>452</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>4.71</td>\n",
       "      <td>13.96</td>\n",
       "      <td>0.234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9355</th>\n",
       "      <td>15</td>\n",
       "      <td>330</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>4.71</td>\n",
       "      <td>13.96</td>\n",
       "      <td>0.234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9356</th>\n",
       "      <td>15</td>\n",
       "      <td>146</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>4.71</td>\n",
       "      <td>13.96</td>\n",
       "      <td>0.234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9358</th>\n",
       "      <td>15</td>\n",
       "      <td>99</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>4.71</td>\n",
       "      <td>13.96</td>\n",
       "      <td>0.234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9359</th>\n",
       "      <td>15</td>\n",
       "      <td>70</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6.60</td>\n",
       "      <td>5.8</td>\n",
       "      <td>25.00</td>\n",
       "      <td>42.14</td>\n",
       "      <td>4.71</td>\n",
       "      <td>13.96</td>\n",
       "      <td>0.234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5460 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  Immigrant count  Unemployment %  \\\n",
       "1        1             2938            4.03   \n",
       "2        1             1128            4.03   \n",
       "3        1              265            4.03   \n",
       "4        1              156            4.03   \n",
       "8        1             4703            4.03   \n",
       "...    ...              ...             ...   \n",
       "9353    15              452            5.60   \n",
       "9355    15              330            5.60   \n",
       "9356    15              146            5.60   \n",
       "9358    15               99            5.60   \n",
       "9359    15               70            5.60   \n",
       "\n",
       "      Political and Violence Percentile  Probability of dying young  \\\n",
       "1                                 17.31                         5.1   \n",
       "2                                 17.31                         5.1   \n",
       "3                                 17.31                         5.1   \n",
       "4                                 17.31                         5.1   \n",
       "8                                 17.31                         5.1   \n",
       "...                                 ...                         ...   \n",
       "9353                               6.60                         5.8   \n",
       "9355                               6.60                         5.8   \n",
       "9356                               6.60                         5.8   \n",
       "9358                               6.60                         5.8   \n",
       "9359                               6.60                         5.8   \n",
       "\n",
       "      Rule of Law Percentile  Salaried workers %  GDP_growth  \\\n",
       "1                      25.96               44.47        9.13   \n",
       "2                      25.96               44.47        9.13   \n",
       "3                      25.96               44.47        9.13   \n",
       "4                      25.96               44.47        9.13   \n",
       "8                      25.96               44.47        9.13   \n",
       "...                      ...                 ...         ...   \n",
       "9353                   25.00               42.14        4.71   \n",
       "9355                   25.00               42.14        4.71   \n",
       "9356                   25.00               42.14        4.71   \n",
       "9358                   25.00               42.14        4.71   \n",
       "9359                   25.00               42.14        4.71   \n",
       "\n",
       "      Inflation_annual  Liberal democracy index  ...  Continent_America  \\\n",
       "1                 1.10                    0.649  ...                  1   \n",
       "2                 1.10                    0.649  ...                  1   \n",
       "3                 1.10                    0.649  ...                  1   \n",
       "4                 1.10                    0.649  ...                  1   \n",
       "8                 1.10                    0.649  ...                  1   \n",
       "...                ...                      ...  ...                ...   \n",
       "9353             13.96                    0.234  ...                  0   \n",
       "9355             13.96                    0.234  ...                  0   \n",
       "9356             13.96                    0.234  ...                  0   \n",
       "9358             13.96                    0.234  ...                  0   \n",
       "9359             13.96                    0.234  ...                  0   \n",
       "\n",
       "      Continent_Asia  Continent_Europe  Sub-region_Africa  Sub-region_Asia  \\\n",
       "1                  0                 0                  0                0   \n",
       "2                  0                 0                  0                0   \n",
       "3                  0                 0                  0                0   \n",
       "4                  0                 0                  0                0   \n",
       "8                  0                 0                  0                0   \n",
       "...              ...               ...                ...              ...   \n",
       "9353               1                 0                  0                1   \n",
       "9355               1                 0                  0                1   \n",
       "9356               1                 0                  0                1   \n",
       "9358               1                 0                  0                1   \n",
       "9359               1                 0                  0                1   \n",
       "\n",
       "      Sub-region_Central America and Caribbean  Sub-region_European Union  \\\n",
       "1                                            0                          0   \n",
       "2                                            0                          0   \n",
       "3                                            0                          0   \n",
       "4                                            0                          0   \n",
       "8                                            0                          0   \n",
       "...                                        ...                        ...   \n",
       "9353                                         0                          0   \n",
       "9355                                         0                          0   \n",
       "9356                                         0                          0   \n",
       "9358                                         0                          0   \n",
       "9359                                         0                          0   \n",
       "\n",
       "      Sub-region_North America  Sub-region_Rest of Europe  \\\n",
       "1                            0                          0   \n",
       "2                            0                          0   \n",
       "3                            0                          0   \n",
       "4                            0                          0   \n",
       "8                            0                          0   \n",
       "...                        ...                        ...   \n",
       "9353                         0                          0   \n",
       "9355                         0                          0   \n",
       "9356                         0                          0   \n",
       "9358                         0                          0   \n",
       "9359                         0                          0   \n",
       "\n",
       "      Sub-region_South America  \n",
       "1                            1  \n",
       "2                            1  \n",
       "3                            1  \n",
       "4                            1  \n",
       "8                            1  \n",
       "...                        ...  \n",
       "9353                         0  \n",
       "9355                         0  \n",
       "9356                         0  \n",
       "9358                         0  \n",
       "9359                         0  \n",
       "\n",
       "[5460 rows x 69 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hacer copia del df_noagg\n",
    "df_copy = df_noagg.copy()\n",
    "\n",
    "# Transformar Year a variable ordinal de 1 (2008) a 15 (2022)\n",
    "df_copy['Year'] = df_copy['Year'] - 2007\n",
    "\n",
    "# Generar variables dummies a partir de nuestras variables categóricas \"object\" (no ordinales)\n",
    "df_copy = pd.get_dummies(df_copy)\n",
    "\n",
    "# Convertir las variables dummies booleanas en \"int\"\n",
    "col_bool = df_copy.select_dtypes(include = ['bool']).columns\n",
    "df_copy[col_bool] = df_copy[col_bool].astype(int)\n",
    "\n",
    "# Verificar cambio\n",
    "df_copy.info()\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separemos el conjunto train/test y escalemos los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar variables input y variable target \"Immigrant count\" de df_copy\n",
    "X = df_copy.drop(\"Immigrant count\", axis = 1) # variables predictoras\n",
    "y = df_copy[\"Immigrant count\"]  # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 58) # separar datos en conjunto train y test en un 75% / 25%\n",
    "scaler = MinMaxScaler() # definir scaler de datos \n",
    "X_train = scaler.fit_transform(X_train) # escalar los datos de entrenamiento\n",
    "X_test = scaler.fit_transform(X_test) # # escalar los datos de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hist Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "108 fits failed out of a total of 324.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "108 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py\", line 353, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of HistGradientBoostingRegressor must be a str among {'quantile', 'squared_error', 'absolute_error', 'poisson'} or an instance of 'sklearn._loss.loss.BaseLoss'. Got 'gamma' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\ProgramFiles\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [ -5254158.8937066   -4390963.00554829  -3985693.17818779\n",
      "  -5168145.8171197   -4299578.48543939  -3894190.96239888\n",
      "                nan                nan                nan\n",
      "                nan                nan                nan\n",
      " -34185088.36565981 -21225849.9553362   -4488720.48824894\n",
      " -33579811.66007066 -21076162.05724657  -5161241.90553651\n",
      " -10369886.50031281 -10966510.50017865 -11529539.10337436\n",
      " -10582192.03169888 -10972074.08833781 -11534323.95698428\n",
      "                nan                nan                nan\n",
      "                nan                nan                nan\n",
      "  -9256528.30140574  -9362759.3062009   -9165684.36981735\n",
      "  -9244602.83143982  -9322770.57564213  -9234372.22849301\n",
      "  -4895173.12757906  -4256081.30635853  -3914437.78752085\n",
      "  -4732582.09665527  -4282199.29241672  -4004954.46495573\n",
      "                nan                nan                nan\n",
      "                nan                nan                nan\n",
      " -34551355.08046547 -30866518.43605746  -4648890.37457023\n",
      " -33855256.95459896 -30190465.98594813  -5161206.48317103\n",
      " -10722189.10087235 -11020440.74411567 -11546702.89044576\n",
      " -10825837.61068233 -11096246.40355499 -11534539.75868252\n",
      "                nan                nan                nan\n",
      "                nan                nan                nan\n",
      "  -9257943.08513038  -9365658.02557595  -9160726.74766324\n",
      "  -9235677.31087947  -9327338.92542152  -9236197.88181915\n",
      "  -4916293.24322191  -4196095.51518371  -3954172.58539311\n",
      "  -5008145.29647914  -4169848.82621236  -3810224.61092249\n",
      "                nan                nan                nan\n",
      "                nan                nan                nan\n",
      " -34544053.6168785  -31389259.49707364  -4656204.01024773\n",
      " -33812639.38029661 -30199726.68965024  -5151099.17850898\n",
      " -10832446.86178133 -11151700.27563695 -11674132.71523669\n",
      " -11018473.50224838 -11206973.16110575 -11664560.25425392\n",
      "                nan                nan                nan\n",
      "                nan                nan                nan\n",
      "  -9252818.10109129  -9367072.06018922  -9165439.7459473\n",
      "  -9231952.56253368  -9326318.60904643  -9235321.19045814]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HistGradientBoostingRegressor(l2_regularization=0.3, max_depth=8, max_iter=120,\n",
       "                              min_samples_leaf=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingRegressor(l2_regularization=0.3, max_depth=8, max_iter=120,\n",
       "                              min_samples_leaf=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "HistGradientBoostingRegressor(l2_regularization=0.3, max_depth=8, max_iter=120,\n",
       "                              min_samples_leaf=5)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir diccionario de valores para parámetros \n",
    "params = {'max_iter': [120], \n",
    "\t      'loss' : ['squared_error', 'gamma', 'poisson'],\n",
    "          \"learning_rate\": [0.1, 0.01], \n",
    "          'min_samples_leaf' : [2, 3, 5],\n",
    "          \"max_depth\": [7, 8],\n",
    "          'l2_regularization' : [0.0, 0.1, 0.3] #usar si se tienen muchas variables\n",
    "          }\n",
    "\n",
    "# Definir modelo y aplicar combinaciones de parametros según el diccinario \n",
    "hgb = HistGradientBoostingRegressor() \n",
    "hgb_cv = GridSearchCV(hgb, params, cv=3, scoring='neg_mean_squared_error').fit(X_train, y_train)\n",
    "\n",
    "hgb_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 - train: 0.986\n",
      "RMSE - train: 194.0\n",
      "MAE - train: 109.0\n",
      "MAPE - train: 0.23\n",
      "\n",
      "R2 - test: 0.944\n",
      "RMSE - test: 328.0\n",
      "MAE - test: 164.0\n",
      "MAPE - test: 0.29\n"
     ]
    }
   ],
   "source": [
    "# Definir modelo con los mejores valores de parámetros (Nota: usar los mejores, pero hacer modificaciones para comparar metricas)\n",
    "hgb_best = HistGradientBoostingRegressor(\n",
    "                           max_iter = 120, \n",
    "                           max_depth = 8,\n",
    "                           loss = 'poisson', \n",
    "                           learning_rate = 0.1, \n",
    "                           min_samples_leaf = 30,\n",
    "                           max_leaf_nodes = 35,\n",
    "                        #  l2_regularization = 0.3,  \n",
    "                        #  max_features = 1.0, \n",
    "                           )\n",
    "\n",
    "# Entrenar con el conjunto de entrenamiento \n",
    "hgb_best.fit(X_train, y_train) \n",
    "\n",
    "# Aplicar modelo sobre los datos de traint y test para predecir el target\n",
    "y_train_pred_hgb = hgb_best.predict(X_train)\n",
    "y_test_pred_hgb = hgb_best.predict(X_test)\n",
    "\n",
    "# Calculo de metricas en train\n",
    "r2_train_hgb = np.round(r2_score(y_train, y_train_pred_hgb), 3)\n",
    "rmse_train_hgb = np.round(np.sqrt(mean_squared_error(y_train, y_train_pred_hgb)), 0)\n",
    "mae_train_hgb = np.round(mean_absolute_error(y_train, y_train_pred_hgb), 0)\n",
    "mape_train_hgb = np.round(mean_absolute_percentage_error(y_train, y_train_pred_hgb), 2)\n",
    "\n",
    "# Calculo de metricas en train\n",
    "r2_test_hgb = np.round(r2_score(y_test, y_test_pred_hgb), 3)\n",
    "rmse_test_hgb = np.round(np.sqrt(mean_squared_error(y_test, y_test_pred_hgb)), 0)\n",
    "mae_test_hgb = np.round(mean_absolute_error(y_test, y_test_pred_hgb), 0)\n",
    "mape_test_hgb = np.round(mean_absolute_percentage_error(y_test, y_test_pred_hgb), 2)\n",
    "\n",
    "# Mostrar métricas\n",
    "print(\"R2 - train:\", r2_train_hgb)\n",
    "print(\"RMSE - train:\", rmse_train_hgb)\n",
    "print(\"MAE - train:\", mae_train_hgb)\n",
    "print(\"MAPE - train:\", mape_train_hgb)\n",
    "print('')\n",
    "print(\"R2 - test:\", r2_test_hgb)\n",
    "print(\"RMSE - test:\", rmse_test_hgb)\n",
    "print(\"MAE - test:\", mae_test_hgb)\n",
    "print(\"MAPE - test:\", mape_test_hgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_mean</th>\n",
       "      <th>importance_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Number of residents</td>\n",
       "      <td>0.801210</td>\n",
       "      <td>0.032408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Age group_25 - 34</td>\n",
       "      <td>0.181767</td>\n",
       "      <td>0.015105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Age group_65+</td>\n",
       "      <td>0.176840</td>\n",
       "      <td>0.032718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unemployment %</td>\n",
       "      <td>0.172097</td>\n",
       "      <td>0.019792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Year</td>\n",
       "      <td>0.164157</td>\n",
       "      <td>0.005495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Age group_55 - 64</td>\n",
       "      <td>0.137300</td>\n",
       "      <td>0.025216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Number of Turist</td>\n",
       "      <td>0.116007</td>\n",
       "      <td>0.009195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Salaried workers %</td>\n",
       "      <td>0.105001</td>\n",
       "      <td>0.011724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Age group_15 - 24</td>\n",
       "      <td>0.079220</td>\n",
       "      <td>0.005736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Age group_45 - 54</td>\n",
       "      <td>0.047552</td>\n",
       "      <td>0.008120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Political and Violence Percentile</td>\n",
       "      <td>0.044562</td>\n",
       "      <td>0.005909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rule of Law Percentile</td>\n",
       "      <td>0.036592</td>\n",
       "      <td>0.004898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GDP_growth</td>\n",
       "      <td>0.030710</td>\n",
       "      <td>0.001034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Homicide Rate</td>\n",
       "      <td>0.027920</td>\n",
       "      <td>0.004045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Inflation_annual</td>\n",
       "      <td>0.025444</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              feature  importance_mean  importance_std\n",
       "15                Number of residents         0.801210        0.032408\n",
       "52                  Age group_25 - 34         0.181767        0.015105\n",
       "56                      Age group_65+         0.176840        0.032718\n",
       "1                      Unemployment %         0.172097        0.019792\n",
       "0                                Year         0.164157        0.005495\n",
       "55                  Age group_55 - 64         0.137300        0.025216\n",
       "18                   Number of Turist         0.116007        0.009195\n",
       "5                  Salaried workers %         0.105001        0.011724\n",
       "51                  Age group_15 - 24         0.079220        0.005736\n",
       "54                  Age group_45 - 54         0.047552        0.008120\n",
       "2   Political and Violence Percentile         0.044562        0.005909\n",
       "4              Rule of Law Percentile         0.036592        0.004898\n",
       "6                          GDP_growth         0.030710        0.001034\n",
       "17                      Homicide Rate         0.027920        0.004045\n",
       "7                    Inflation_annual         0.025444        0.001900"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importancia por permutaciones\n",
    "importancias_permu = permutation_importance(hgb_best, X_train, y_train, n_repeats=10, random_state=58)\n",
    "\n",
    "# Importancias en dataframe\n",
    "importances_hgb = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance_mean': importancias_permu.importances_mean,\n",
    "    'importance_std': importancias_permu.importances_std\n",
    "}).sort_values(by='importance_mean', ascending=False)\n",
    "\n",
    "importances_hgb.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTA: USAR QUANTILES EN EL hgb PARA ESTIMAR INTERVALO DE CONFIANZA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:29:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:29:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:29:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:03] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:06] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:07] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:07] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:08] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:09] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:09] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:12] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:14] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:15] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:15] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:16] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:16] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Cristian De Andrade\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [08:30:19] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_depth\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'booster': 'dart',\n",
       " 'eval_metric': 'rmse',\n",
       " 'learning_rate': 0.3,\n",
       " 'max_depth': 7,\n",
       " 'n_estimators': 200,\n",
       " 'objective': 'reg:squarederror'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir diccionario de valores para parámetros \n",
    "params = {'objective' : ['reg:squarederror', 'reg:squaredlogerror'], # seleccionar 2 como max, reg:squarederror es el default\n",
    "          'eval_metric' : ['rmse'],   # rmsle disminuye efecto de outliers\n",
    "          'booster' : [\"gbtree\", \"gblinear\", \"dart\"], # gbtree (default) y dart estan basados en arboles\n",
    "          'n_estimators': [200],\n",
    "          'max_depth': [7, 9], # dependiendo de la dimensionalidad de los datos, usar valores de profundidad menor\n",
    "          \"learning_rate\" : [0.1, 0.3, 0.05], \n",
    "       #   \"colsample_bytree\" : [1, 0.7], # porcentaje de variables a usar (buen parametro para cuando se tiene una gran cantidad de variables)\n",
    "          }\n",
    "\n",
    "# Definir modelo y aplicar combinaciones de parametros según el diccinario \n",
    "xgb = XGBRegressor()\n",
    "xgb_cv = GridSearchCV(xgb, params, cv=3, scoring = 'neg_mean_squared_error') # elegir scoring deseano (r2, mae, mse, mape...)\n",
    "\n",
    "# Entrenar modelo con cada combinación de parámetro \n",
    "xgb_cv.fit(X_train,y_train)\n",
    "\n",
    "# Motrar mejores valores para parámeros\n",
    "xgb_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 - train: 0.979\n",
      "RMSE - train: 237.0\n",
      "MAE - train: 124.0\n",
      "MAPE - train: 0.56\n",
      "\n",
      "R2 - test: 0.908\n",
      "RMSE - test: 420.0\n",
      "MAE - test: 234.0\n",
      "MAPE - test: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Definir modelo con los mejores valores de parámetros (Nota: usar los mejores, pero hacer modificaciones al comparar metricas)\n",
    "xgb_best = XGBRegressor(objective = 'reg:squarederror', \n",
    "                        eval_metric = 'rmse',\n",
    "                        booster = 'dart',\n",
    "                        n_estimators = 200,\n",
    "                        max_depth = 7,\n",
    "                        #alpha = 0.05, \n",
    "                        learning_rate = 0.3,\n",
    "                        min_child_weight = 30, \n",
    "                      #  colsample_bytree = 0.8,\n",
    "                    )\n",
    "\n",
    "# Entrenar modelo con el conjunto de entrenamiento \n",
    "xgb_best.fit(X_train, y_train)\n",
    "\n",
    "# Aplicar modelo sobre los datos de traint y test para predecir el target\n",
    "y_train_pred_xgb = xgb_best.predict(X_train) \n",
    "y_test_pred_xgb = xgb_best.predict(X_test) \n",
    "\n",
    "\n",
    "# Calculate metrics for train set\n",
    "r2_train_xgb = np.round(r2_score(y_train, y_train_pred_xgb), 3)\n",
    "rmse_train_xgb = np.round(np.sqrt(mean_squared_error(y_train, y_train_pred_xgb)), 0)\n",
    "mae_train_xgb = np.round(mean_absolute_error(y_train, y_train_pred_xgb), 0)\n",
    "mape_train_xgb = np.round(mean_absolute_percentage_error(y_train, y_train_pred_xgb), 2)\n",
    "\n",
    "# Calculate metrics for test set\n",
    "r2_test_xgb = np.round(r2_score(y_test, y_test_pred_xgb), 3)\n",
    "rmse_test_xgb = np.round(np.sqrt(mean_squared_error(y_test, y_test_pred_xgb)), 0)\n",
    "mae_test_xgb = np.round(mean_absolute_error(y_test, y_test_pred_xgb), 0)\n",
    "mape_test_xgb = np.round(mean_absolute_percentage_error(y_test, y_test_pred_xgb), 2)\n",
    "\n",
    "# Print metrics\n",
    "print(\"R2 - train:\", r2_train_xgb)\n",
    "print(\"RMSE - train:\", rmse_train_xgb)\n",
    "print(\"MAE - train:\", mae_train_xgb)\n",
    "print(\"MAPE - train:\", mape_train_xgb)\n",
    "print(\"\")\n",
    "print(\"R2 - test:\", r2_test_xgb)\n",
    "print(\"RMSE - test:\", rmse_test_xgb)\n",
    "print(\"MAE - test:\", mae_test_xgb)\n",
    "print(\"MAPE - test:\", mape_test_xgb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Comparar Modelos*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juntemos los resultados todos los modelos en un dataframe por tipo de métrica, ordenando por el mejor valor en el conjunto test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>R² train</th>\n",
       "      <th>R² test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HGB</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Red Neuronal</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lineal - Lasso</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lineal</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lineal - Ridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lineal - Huber</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lineal - E-Net</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lineal - Theilsen</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lineal - RANSAC</td>\n",
       "      <td>-4.762</td>\n",
       "      <td>-1.224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Modelo  R² train  R² test\n",
       "12                HGB     0.986    0.944\n",
       "11       Red Neuronal     0.968    0.911\n",
       "13            XGBoost     0.979    0.908\n",
       "8       Random Forest     0.791    0.754\n",
       "9                 KNN     0.721    0.697\n",
       "7       Decision Tree     0.690    0.548\n",
       "5      Lineal - Lasso       NaN    0.516\n",
       "0              Lineal     0.520    0.514\n",
       "4      Lineal - Ridge       NaN    0.514\n",
       "1      Lineal - Huber     0.293    0.339\n",
       "6      Lineal - E-Net       NaN    0.339\n",
       "3   Lineal - Theilsen     0.264    0.264\n",
       "10                SVR     0.055    0.074\n",
       "2     Lineal - RANSAC    -4.762   -1.224"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Juntar en un dataframe los datos\n",
    "modelos_r2 = pd.DataFrame({\n",
    "    'Modelo' : ['Lineal', 'Lineal - Huber', 'Lineal - RANSAC', 'Lineal - Theilsen', 'Lineal - Ridge', 'Lineal - Lasso', 'Lineal - E-Net', 'Decision Tree', 'Random Forest', 'KNN', 'SVR', 'Red Neuronal', 'HGB', 'XGBoost'],\n",
    "    'R² train' : [r2_train_lineal, r2_train_huber, r2_train_ransac, r2_train_theilsen, np.nan, np.nan, np.nan, r2_train_tree, r2_train_rf, r2_train_knn, r2_train_svr, r2_train_rn, r2_train_hgb, r2_train_xgb],\n",
    "    'R² test' : [r2_test_lineal, r2_test_huber, r2_test_ransac, r2_test_theilsen, r2_test_ridge, r2_test_lasso, r2_test_enet, r2_test_tree, r2_test_rf, r2_test_knn, r2_test_svr, r2_test_rn, r2_test_hgb, r2_test_xgb],\n",
    "})\n",
    "\n",
    "# Ordenar de forma descendente por R² test\n",
    "modelos_r2.sort_values(by = 'R² test', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>RSME train</th>\n",
       "      <th>RSME test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HGB</td>\n",
       "      <td>194.0</td>\n",
       "      <td>328.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>237.0</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>745.0</td>\n",
       "      <td>687.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNN</td>\n",
       "      <td>861.0</td>\n",
       "      <td>762.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>908.0</td>\n",
       "      <td>931.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lineal - Lasso</td>\n",
       "      <td>NaN</td>\n",
       "      <td>963.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lineal</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>965.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lineal - Ridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>965.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lineal - Huber</td>\n",
       "      <td>1370.0</td>\n",
       "      <td>1125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lineal - E-Net</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lineal - Theilsen</td>\n",
       "      <td>1399.0</td>\n",
       "      <td>1188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVR</td>\n",
       "      <td>1585.0</td>\n",
       "      <td>1332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lineal - RANSAC</td>\n",
       "      <td>3913.0</td>\n",
       "      <td>2064.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Red Neuronal</td>\n",
       "      <td>290.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Modelo  RSME train  RSME test\n",
       "12                HGB       194.0      328.0\n",
       "13            XGBoost       237.0      420.0\n",
       "8       Random Forest       745.0      687.0\n",
       "9                 KNN       861.0      762.0\n",
       "7       Decision Tree       908.0      931.0\n",
       "5      Lineal - Lasso         NaN      963.0\n",
       "0              Lineal      1129.0      965.0\n",
       "4      Lineal - Ridge         NaN      965.0\n",
       "1      Lineal - Huber      1370.0     1125.0\n",
       "6      Lineal - E-Net         NaN     1125.0\n",
       "3   Lineal - Theilsen      1399.0     1188.0\n",
       "10                SVR      1585.0     1332.0\n",
       "2     Lineal - RANSAC      3913.0     2064.0\n",
       "11       Red Neuronal       290.0        NaN"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Juntar en un dataframe los datos\n",
    "modelos_rsme = pd.DataFrame({\n",
    "    'Modelo' : ['Lineal', 'Lineal - Huber', 'Lineal - RANSAC', 'Lineal - Theilsen', 'Lineal - Ridge', 'Lineal - Lasso', 'Lineal - E-Net', 'Decision Tree', 'Random Forest', 'KNN','SVR', 'Red Neuronal', 'HGB', 'XGBoost'],\n",
    "    'RSME train' : [rmse_train_lineal, rmse_train_huber, rmse_train_ransac, rmse_train_theilsen, np.nan, np.nan, np.nan, rmse_train_tree, rmse_train_rf, rmse_train_knn, rmse_train_svr, rmse_train_rn, rmse_train_hgb, rmse_train_xgb],\n",
    "    'RSME test' : [rmse_test_lineal, rmse_test_huber, rmse_test_ransac, rmse_test_theilsen, rmse_test_ridge, rmse_test_lasso, rmse_test_enet, rmse_test_tree, rmse_test_rf, rmse_test_knn, rmse_test_svr, np.nan, rmse_test_hgb, rmse_test_xgb],\n",
    "    })\n",
    "\n",
    "# Ordenar de forma ascendente por RSME test\n",
    "modelos_rsme.sort_values(by = 'RSME test', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>MAE train</th>\n",
       "      <th>MAE test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HGB</td>\n",
       "      <td>109.0</td>\n",
       "      <td>164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>124.0</td>\n",
       "      <td>234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Red Neuronal</td>\n",
       "      <td>188.0</td>\n",
       "      <td>242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>340.0</td>\n",
       "      <td>357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNN</td>\n",
       "      <td>376.0</td>\n",
       "      <td>380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>386.0</td>\n",
       "      <td>440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lineal - Huber</td>\n",
       "      <td>526.0</td>\n",
       "      <td>493.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVR</td>\n",
       "      <td>620.0</td>\n",
       "      <td>579.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lineal - Theilsen</td>\n",
       "      <td>633.0</td>\n",
       "      <td>606.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lineal - RANSAC</td>\n",
       "      <td>788.0</td>\n",
       "      <td>608.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lineal - Lasso</td>\n",
       "      <td>NaN</td>\n",
       "      <td>608.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lineal - Ridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>611.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lineal</td>\n",
       "      <td>621.0</td>\n",
       "      <td>614.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lineal - E-Net</td>\n",
       "      <td>NaN</td>\n",
       "      <td>625.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Modelo  MAE train  MAE test\n",
       "12                HGB      109.0     164.0\n",
       "13            XGBoost      124.0     234.0\n",
       "11       Red Neuronal      188.0     242.0\n",
       "8       Random Forest      340.0     357.0\n",
       "9                 KNN      376.0     380.0\n",
       "7       Decision Tree      386.0     440.0\n",
       "1      Lineal - Huber      526.0     493.0\n",
       "10                SVR      620.0     579.0\n",
       "3   Lineal - Theilsen      633.0     606.0\n",
       "2     Lineal - RANSAC      788.0     608.0\n",
       "5      Lineal - Lasso        NaN     608.0\n",
       "4      Lineal - Ridge        NaN     611.0\n",
       "0              Lineal      621.0     614.0\n",
       "6      Lineal - E-Net        NaN     625.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Juntar en un dataframe los datos\n",
    "modelos_mae = pd.DataFrame({\n",
    "    'Modelo' : ['Lineal', 'Lineal - Huber', 'Lineal - RANSAC', 'Lineal - Theilsen', 'Lineal - Ridge', 'Lineal - Lasso', 'Lineal - E-Net', 'Decision Tree', 'Random Forest', 'KNN', 'SVR', 'Red Neuronal', 'HGB', 'XGBoost'],\n",
    "    'MAE train' : [mae_train_lineal, mae_train_huber, mae_train_ransac, mae_train_theilsen, np.nan, np.nan, np.nan, mae_train_tree, mae_train_rf, mae_train_knn, mae_train_svr, mae_train_rn, mae_train_hgb, mae_train_xgb],\n",
    "    'MAE test' : [mae_test_lineal, mae_test_huber, mae_test_ransac, mae_test_theilsen, mae_test_ridge, mae_test_lasso, mae_test_enet, mae_test_tree, mae_test_rf, mae_test_knn, mae_test_svr, mae_test_rn, mae_test_hgb, mae_test_xgb],\n",
    "})\n",
    "\n",
    "# Ordenar de forma descendente por MAE test\n",
    "modelos_mae.sort_values(by = 'MAE test', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>MAPE train</th>\n",
       "      <th>MAPE test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HGB</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lineal - RANSAC</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lineal - Huber</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lineal - Theilsen</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lineal - E-Net</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lineal - Lasso</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lineal - Ridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lineal</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Red Neuronal</td>\n",
       "      <td>0.57</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Modelo  MAPE train  MAPE test\n",
       "12                HGB        0.23       0.29\n",
       "7       Decision Tree        0.59       0.68\n",
       "2     Lineal - RANSAC        0.82       0.72\n",
       "8       Random Forest        0.72       0.77\n",
       "13            XGBoost        0.56       0.80\n",
       "1      Lineal - Huber        0.97       0.83\n",
       "10                SVR        0.89       0.89\n",
       "9                 KNN        0.87       0.95\n",
       "3   Lineal - Theilsen        2.80       2.00\n",
       "6      Lineal - E-Net         NaN       2.36\n",
       "5      Lineal - Lasso         NaN       2.54\n",
       "4      Lineal - Ridge         NaN       2.57\n",
       "0              Lineal        3.30       2.59\n",
       "11       Red Neuronal        0.57        NaN"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Juntar en un dataframe los datos\n",
    "modelos_mape = pd.DataFrame({\n",
    "    'Modelo' : ['Lineal', 'Lineal - Huber', 'Lineal - RANSAC', 'Lineal - Theilsen', 'Lineal - Ridge', 'Lineal - Lasso', 'Lineal - E-Net', 'Decision Tree', 'Random Forest', 'KNN', 'SVR', 'Red Neuronal', 'HGB', 'XGBoost'],\n",
    "    'MAPE train' : [mape_train_lineal, mape_train_huber, mape_train_ransac, mape_train_theilsen, np.nan, np.nan, np.nan, mape_train_tree, mape_train_rf, mape_train_knn, mape_train_svr, mape_train_rn, mape_train_hgb, mape_train_xgb],\n",
    "    'MAPE test' : [mape_test_lineal, mape_test_huber, mape_test_ransac, mape_test_theilsen, mape_test_ridge, mape_test_lasso, mape_test_enet, mape_test_tree, mape_test_rf, mape_test_knn, mape_test_svr, np.nan, mape_test_hgb, mape_test_xgb],\n",
    "})\n",
    "\n",
    "# Ordenar de forma ascendente por MAPE test\n",
    "modelos_mape.sort_values(by = 'MAPE test', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar tablas comparativas de metricas\n",
    "modelos_r2.to_csv(\"../16 - Exports Modelos/sin agregados/metrics_r2_noagg.csv\", index = False)\n",
    "modelos_rsme.to_csv(\"../16 - Exports Modelos/sin agregados/metrics_rsme_noagg.csv\", index = False)\n",
    "modelos_mae.to_csv(\"../16 - Exports Modelos/sin agregados/metrics_mae_noagg.csv\", index = False)\n",
    "modelos_mape.to_csv(\"../16 - Exports Modelos/sin agregados/metrics_mape_noagg.csv\", index = False)\n",
    "\n",
    "# Exportar modelo HGB seleccionado\n",
    "with open(\"../16 - Exports Modelos/sin agregados/hgb_best_noagg.sav\", 'wb') as file:\n",
    "    pickle.dump(hgb_best, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
